<?xml version='1.0'?>
<DISCUSSIONS>
  <DISCUSSION>
    <ID>1021</ID>
    <LECTURE>06 Jan. 01-Introduction Questions</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>ZOH eqvivalent of plant</SUBJECT>
        <MESSAGE>the ZOH equivalent of the plant is x(k+1) = ax(k) + b u(k) it is not understood as to what is meant by ZOH equivalent of the plant </MESSAGE>
        <SUBJECT>Re: ZOH eqvivalent of plant</SUBJECT>
        <MESSAGE> The word zero refers to the degree of the polynomial. In this method, the value of the variable sampled is held constant during the entire interval. Constant is a zero degree polynomial.&lt;br /&gt;&lt;br /&gt;There are also higher order holds. For example, if you use the value of the variable at past two sampling instants and extrapolate them, you get a first order hold. Similarly, second order hold, etc.&lt;br /&gt;&lt;br /&gt;Zero order hold is the easiest to implement. It is the most popular in applications. Any error by the result of this approximation is overcome by reducing the sampling interval. This approach has worked well. It is also the simplest to implement.&lt;br /&gt;&lt;br /&gt;In this course, we will use only Zero Order Hold.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: ZOH eqvivalent of plant</SUBJECT>
        <MESSAGE>In Zero Order Hold, what we do is, we usually assume a particular quantity to be constant for a small period of time, i.e., say from t=0 to t=sampling time.
While deriving the general form x(k+1) = ax(k) + b u(k), as you have mentioned, we make an approximation taking that u(k) is constant from kth sample to (k+1)th sample. This is in fact the zero order hold, as u know. This issue is dealt in the next lecture.</MESSAGE>
        <SUBJECT>Re: ZOH eqvivalent of plant</SUBJECT>
        <MESSAGE>ZOH equivalent of the plant is the expression in discrete or deviation variables which describes the plant similar to differential equation in continuous time domain. </MESSAGE>
        <SUBJECT>Re: ZOH eqvivalent of plant</SUBJECT>
        <MESSAGE>ZOH stands for Zero Order Hold. In the given plant, data wont be available between samples i.e. if the controller takes readings only 10 times a second, then it wont be able to give outputs for instants between say t=0.1 and t=0.2. But the real system is continuous so it must be given some value at all instants. One way is to maintain the same value till the next value arrives i.e. from t=0.1 to t=0.2 the value of the output wont change. This is Zero Order Hold. The equation given above is based on ZOH (x at t=k+1 depends only on values of u and x and t=k. It does not depend on values in between or even the values of x at t=k+1)</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Zero Order Hold</SUBJECT>
        <MESSAGE>During A/D conversion, we use sample and hold between two time instances. &lt;br /&gt;Is this the reason for using ZOH during D/A conversion ?&lt;br /&gt;Is the order of hold during D/A conversion independent of A/D conversion ?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Zero Order Hold</SUBJECT>
        <MESSAGE>I believe D/A is independent of the A/D conversion order, it rather depends on the method of conversion employed by the D/A converter.&lt;br /&gt;&lt;br /&gt;1. Digital number to Analog Value - Resistance Ladder type converter&lt;br /&gt;2. PWM to Analog Value using Low Pass Filters.&lt;br /&gt;&lt;br /&gt;Wikipedia talks of some D/A converters that are of interpolating type.&lt;br /&gt;&lt;br /&gt;http://en.wikipedia.org/wiki/Digital-to-analog_converter#DAC_types&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Zero Order Hold</SUBJECT>
        <MESSAGE>I don't think that is the reason for ZOH. The main reason would be to bridge the gap between continuous and digital. Continuous needs a value all the time, thus due to lack of value between the intervals, ZOH is implemented.&lt;br /&gt; Also I believe, D/A and A/D need not be dependent.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Zero Order Hold</SUBJECT>
        <MESSAGE>zoh also known as sample and hold are used for analog to digital conversion and not for D/A the polynomial is zeroth order hence it is called zeroth order polynomial </MESSAGE>
        <SUBJECT>Re: Zero Order Hold</SUBJECT>
        <MESSAGE>What Prasanna says is correct. The objective of the hold operation is to assign a value to the variable at every instant of the sampling interval, so that the operations that require a value at every instant proceed smoothly.&lt;br /&gt;&lt;br /&gt;Yes, A/D and D/A operations are independent.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Zero Order Hold</SUBJECT>
        <MESSAGE>ZOH is not equivalent to sample and hold, because, sample and hold does not mean ZOH. For example, in sample and hold, one may use first order hold. </MESSAGE>
        <SUBJECT>Re: Zero Order Hold</SUBJECT>
        <MESSAGE>As far as I know, in D to A conversion, since we don't get the information till the next sampling instant, we hold that value. In fact, if we use 1st Order hold (may be I am wrong with the terminology),  we never know if the reading in the next sample is going to be greater than the present one or lesser. So, it is not possible to interpolate using a curve. So in DA or AD, as we don't know the value at next instant, we use only 1st order hold.
 
I don't think if the order or interpolation of AD or DA conversion are dependent over each other. (May be I am wrong)</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Time taken to listen to the lecture</SUBJECT>
        <MESSAGE>Sir, it took me nearly 1hour 50minutes to go through the entire 1hour 13minute lecture.&lt;br /&gt;All I did was make notes, am I doing something wrong or they are supposed to take that much time ?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Time taken to listen to the lecture</SUBJECT>
        <MESSAGE>It is perfectly fine. On some topics, you will take more time and on some you take less. This is possible while going through a recorded lecture. This is not necessarily possible in a live lecture: although you may have many questions, you may feel shy to ask them. The teacher may go at a pace faster than what you can cope up with. When you go through video lectures, you can decide your speed. If the topic that is covered is already known to you, you can skip those topics.&lt;br /&gt;&lt;br /&gt;Thus, video lectures allow you to choose a speed comfortable to you. The only thing missing in the video lecture is the interaction. We are attempting to bridge that gap through offline, Moodle based, interaction.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Time taken to listen to the lecture</SUBJECT>
        <MESSAGE>It took me almost the same time too. I think it is not a problem because, in class lectures, you don't get time to brood over an aspect as the class will be running.</MESSAGE>
        <SUBJECT>Re: Time taken to listen to the lecture</SUBJECT>
        <MESSAGE>Ya actually me too.</MESSAGE>
        <SUBJECT>Re: Time taken to listen to the lecture</SUBJECT>
        <MESSAGE>I too have the same problem </MESSAGE>
        <SUBJECT>Re: Time taken to listen to the lecture</SUBJECT>
        <MESSAGE>I also took that much time. 
I'm having trouble skipping forward and backward in VLC. Does anyone know a better media player?</MESSAGE>
        <SUBJECT>Re: Time taken to listen to the lecture</SUBJECT>
        <MESSAGE>i agree time required is more than the actual telecast time of the lecture </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Deviation Variables</SUBJECT>
        <MESSAGE>One of the first things that we do while modeling is write the equations in terms of deviation variables. Now it doesn't seem necessary, but rather preferred. What if the system isn't stable(but linear), will such a system dealt differently?&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Deviation Variables</SUBJECT>
        <MESSAGE>Working with deviational quantities results in variables that have small values. This allows the variables to be compared with zero. Thus, working with deviational quantities is useful even when the system is linear.&lt;br /&gt;&lt;br /&gt;This also enables low (first) order approximation, without introducing too much error. Most systems are nonlinear and hence we need to worry about this aspect as well. This is particularly important because we do not have good theories to handle nonlinear systems directly.&lt;br /&gt;&lt;br /&gt;We follow the deviational approach even for unstable systems. The inverted pendulum example given in the textbook is unstable. We can control this system also about an equilibrium point.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Deviation Variables</SUBJECT>
        <MESSAGE>It is necessary to use deviation variables for digital control. Even a system which is not stable has a differential equation so it can be expressed in the deviation variable form. </MESSAGE>
        <SUBJECT>Re: Deviation Variables</SUBJECT>
        <MESSAGE>deviation variables are used for linearization around the stable point so in my view the system should be dealt differently </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>TTL Noise Margin</SUBJECT>
        <MESSAGE>Sir,
In the lecture you have stated that, the signal is considered low if the voltage is 2V. What would be taken i the intermediate state i.e., between 0.8V to 2V?

Moreover, how can they handle the drift, suppose say, in gyros the linearly time varying bias?</MESSAGE>
        <SUBJECT>Re: TTL Noise Margin</SUBJECT>
        <MESSAGE>Below 2V it is treated as low signal</MESSAGE>
        <SUBJECT>Re: TTL Noise Margin</SUBJECT>
        <MESSAGE>The result is unpredictable. It could be low or high, depending on the implementation. Within the setup time, the voltage should stabilise to either below 0.8V or above 2V. </MESSAGE>
        <SUBJECT>Re: TTL Noise Margin</SUBJECT>
        <MESSAGE>And how does the bias is corrected in digital systems? Is it just similar to the noise margin?
I think if we know the pattern of the bias variation, we can correct it, but what if we don't know the pattern?</MESSAGE>
        <SUBJECT>Re: TTL Noise Margin</SUBJECT>
        <MESSAGE>&lt;p&gt;For voltage ranges between the specified levels, the output can't be gauranteed. In your case (0.8V to 2V) the&#160;output would be &lt;strong&gt;probably&lt;/strong&gt; be '0', but you can't gaurantee that. &lt;/p&gt;</MESSAGE>
        <SUBJECT>Re: TTL Noise Margin</SUBJECT>
        <MESSAGE>&lt;p&gt;Same rules apply for the bias. As long as the bias is varying between 0-0.8V it will be always interpreted as a '0'. I guess that is what sir meant. But your question is kind of not relevent here. You are talking about gyro bias. Now this can't be dealt directly as a digital signal, right? So it has to&#160;be processed&#160;through ADC, which unfortunately doesn't take care neither of high frequency noises nor of the slow moving biases.&lt;/p&gt;</MESSAGE>
        <SUBJECT>Re: TTL Noise Margin</SUBJECT>
        <MESSAGE> I think it will be indeterminate. I too have the same doubt. </MESSAGE>
        <SUBJECT>Re: TTL Noise Margin</SUBJECT>
        <MESSAGE>signal is low if it is less than 2.4 v and 2v is due to the noise margin </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Whats the advantage of a Digital Feeback</SUBJECT>
        <MESSAGE>In the last example of mixed Analogue and Digital system, i'm not able to understand the advantage of sampling the input, converting to digital, processing and then converting back to analogue. Wouldn't it be better to use some device like a governor?</MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1168</ID>
    <LECTURE>10 Jan 11 - Doubts on Lecture 2</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>Recursive Solution to State Space Equation</SUBJECT>
        <MESSAGE>I had understood the procedure given in the slides to solve the state space equation recursively, but when I was trying it out on my own before seeing the procedure in the slides, I came up with a different method, but the answer was not matching. Can you help me in finding the mistake that I was doing?

x(n+1)    =    Ax(n)      +       Bu(n)
x(n)      =    Ax(n-1)    +       Bu(n-1)
x(n-1)    =    Ax(n-2)    +       Bu(n-2)
  .              .                 .
  .              .                 .
  .              .                 .
x(1)      =    Ax(0)      +       Bu(0)
________________________________________
x(n+1)+ (sum k from 1 to n)A*x(k) = 
(sum k from 1 to n)A*x(k) +  Ax(0) + B(sum k from 0 to n)u(k)
thus I got,
x(k+1) = (A-I)*(sum k from 1 to n)x(k) + B*(sum k fro 0 to n)(u(k)

why is th difference seen in answer given in lecture and this procedure? Am I going wrong anywhere?</MESSAGE>
        <SUBJECT>Re: Recursive Solution to State Space Equation</SUBJECT>
        <MESSAGE>It should come out to the same. Can someone work it out? Check out also the slides towards the end of Lecture 3. </MESSAGE>
        <SUBJECT>Re: Recursive Solution to State Space Equation</SUBJECT>
        <MESSAGE>i think the summation should be from zero to n-1 </MESSAGE>
        <SUBJECT>Re: Recursive Solution to State Space Equation</SUBJECT>
        <MESSAGE>&lt;p&gt;Your solution is in terms of x(k)&#160;, but in the slides its in terms of x(0).&lt;/p&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>State SPace solution with Delay </SUBJECT>
        <MESSAGE>The B0 and B1 as per the slides i got this way, can u please tell me if they are correct?
B0 = G* integral from (0 to Ts-D) { exp(Ft) }
B1 = G* integral from (Ts-D to Ts) { exp(Ft) }

Are these correct?</MESSAGE>
        <SUBJECT>Re: State SPace solution with Delay </SUBJECT>
        <MESSAGE>Please see equations 2.50 in the textbook, on page 28 and problem 2.5(a). It will be helpful to read the textbook also side by side. You should also consider solving the problems given at the end of each chapter. </MESSAGE>
        <SUBJECT>Re: State SPace solution with Delay </SUBJECT>
        <MESSAGE>B0 = integral from (0 to Ts-D) exp(Ft) G dt&lt;br /&gt;B1 = exp(F(Ts-D)) integral from (0 to D) exp(Ft) G dt&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>How does Time Delay system in sampled system becomes finite dimensional from infinite dimensional in continuous time systems </SUBJECT>
        <MESSAGE>it is not clearly understood as to how the continuous-time system with time delay is infinite dimensional and what makes the sampled data system finite dimensional. </MESSAGE>
        <SUBJECT>Re: How does Time Delay system in sampled system becomes finite dimensional from infinite dimensional in continuous time systems </SUBJECT>
        <MESSAGE>Once delay is added, the eigenvalues become continuous and hence infinite. As a result, time delay systems are known as infinite dimensional systems. This is in a nutshell the reason for the nomenclature. It is beyond the scope of this course to discuss this aspect further.&lt;br /&gt;&lt;br /&gt;Such a system is made finite dimensional by restricting our attention to only a few sampling points.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>variation of time delay vis a vis sampling period</SUBJECT>
        <MESSAGE>what is the physical significance of time delay less than sampling period and how is it different from time delay more than sampling period? </MESSAGE>
        <SUBJECT>Re: variation of time delay vis a vis sampling period</SUBJECT>
        <MESSAGE>in the case of presence of delay, your system does not know the change in input that you have given to the system till it reaches the site of action. This time taken to reach the site is called delay.

let us say, our delay is 0.3 sec and sampling time is 1 sec. say we gave a unit input at t=0. so, the system will not know that there was an input given to it until the end of 0.3s and after that it "realizes" that there is an input given to it and acts accordingly.

say if the delay is 1.3 seconds instead. In that case, at the first sample it assumes that there is no input given. say in the next sample, i give an input of say 2 units. for t=1 to 2 seconds, till 1.3 seconds, the input is still 0, and at t=1.3 seconds, it realizes the unit input and acts for 1 second. in the next sample, after t=2.3 seconds, it assumes the input of 2units....
basically, it is like your system realizes a change in input only after the delay is over. </MESSAGE>
        <SUBJECT>Re: variation of time delay vis a vis sampling period</SUBJECT>
        <MESSAGE> The reply given by Yadati is good. &lt;br /&gt;&lt;br /&gt;To further add: it is precisely because of this reason, a discretised system has at least one sample time delay. This will be discussed further soon in this course.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: variation of time delay vis a vis sampling period</SUBJECT>
        <MESSAGE>&lt;p&gt;If delay is&#160;more than Ts, we would have to spilt the solution&#160;in&#160;every 2nd or&#160;3rd&#160;or 4th or&#160;... iteration. For example if D=4Ts+d ( d&amp;lt;Ts),&#160;we would have to split the solution every 5th iteration.&#160;&#160;&#160;&lt;/p&gt;</MESSAGE>
        <SUBJECT>Re: variation of time delay vis a vis sampling period</SUBJECT>
        <MESSAGE>In cases where the sampling is slower than the system i.e, low sampling frequency D&amp;gt;Ts, when sampling is faster than system D&amp;lt;Ts </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Time delay solutions</SUBJECT>
        <MESSAGE>can anyone please post the expressions for B0 and B1 in the case of time delay &lt; sampling time and 
the entire expression of the solution for state space when time delay is more than the sampling time?
if it is too long, we may discuss in class as well.</MESSAGE>
        <SUBJECT>Re: Time delay solutions</SUBJECT>
        <MESSAGE>The expression is easy to derive. I have discussed for the case of 2Ts &amp;gt; delay &amp;gt; Ts. I suggest that you repeat this exercise for 3Ts &amp;gt; delay &amp;gt; 2Ts. Keep repeating this, until you get the expression yourself. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>About process delay</SUBJECT>
        <MESSAGE>&lt;p&gt;The question is about the process delay. We saw that if there is a process delay of 'D', we split the solution of the difference equation so that u(n) is constant for each interval. &lt;/p&gt;
&lt;p&gt;&#160;&#160;&#160;&#160; Now as far as I understand that this problem comes due to time lag between u(n) and the x(n+1). Can we take care of this by writing x(n+1) in terms of x(n+1+D), so that we don't have to split the solution?&lt;/p&gt;</MESSAGE>
        <SUBJECT>Re: About process delay</SUBJECT>
        <MESSAGE>This may be mathematically true, but physical implementation, say on a micro controller this doesn't make any sense as we are sampling for every Ts seconds. 
Suppose say at t=0, we are giving input as given in slides.... in your case, physically it means you are giving input at t=D seconds, anyhow it takes the same time D to reach the system.
Thus, I don't think if it is physically valid. Hope I could deliver what I actually wanted to deliver.</MESSAGE>
        <SUBJECT>Re: About process delay</SUBJECT>
        <MESSAGE>X(n+1) is the (n+1)th sample instance, you can not change it&#160;since sampling of all (input, output) are synchronize.&#160;</MESSAGE>
        <SUBJECT>Re: About process delay</SUBJECT>
        <MESSAGE>I think we can only have x(n), x(n+1), x(n+2).... i.e in multiples of Ts. Therefore i don't think x(n+1+D) is possible, at least for D&amp;lt;Ts </MESSAGE>
        <SUBJECT>Re: About process delay</SUBJECT>
        <MESSAGE>I would say that i posed the question wrongly, x(n+1+D) is invalid, because D is in seconds, where as n is&#160;not. What i mean is shifting your sampling sequence by D.</MESSAGE>
        <SUBJECT>Re: About process delay</SUBJECT>
        <MESSAGE>i dont think that will make any difference as the basic principal is that at any given instant, the response depends on the input some time D before. And because there is a delay, at any given instant, the response will depend on more than on previous input. So, however we write the expression, because there is a delay, the basic characteristic of the equation (its dependence on two prev inputs) cannot change.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Time delay</SUBJECT>
        <MESSAGE>Are there any examples of varying time delay?&lt;br /&gt;If there are how are they dealt with?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Time delay</SUBJECT>
        <MESSAGE>&lt;p&gt;I believe that if you have a time varying delay, It can be dealt by modelling it. If you know how 'D' varies with time then you dont have a problem.&lt;/p&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Impulse input</SUBJECT>
        <MESSAGE>If an impulse input is given in between two sampling intervals will it affect the output? </MESSAGE>
        <SUBJECT>Re: Impulse input</SUBJECT>
        <MESSAGE>This can be dealt the same way we dealt with 'D' (delay in input). We split it in two parts,&#160;one&#160;before the Impulse&#160;input, and one after.&#160;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Time Delay in Real Situations</SUBJECT>
        <MESSAGE>Where do we encounter Time Delay problems in real life? i.e. in the case of the water flow example, if we place the sensor and controller at the same location, or very close to each other, the time for the effect to propagate will be zero or very close to zero. 
  What is the significance of putting the control valve and sensor at different points, separated by a considerable distance?</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>problem 2.3</SUBJECT>
        <MESSAGE>In problem 2.3 I do not understand why u1(t) = u2(t) = 0 is given,I mean where this condition is useful to solve the problem? </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1208</ID>
    <LECTURE>13 Jan 11 - Doubts on Lecture 3</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>Questions of Lecture 3 may be posted here </MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>1. Any examples for non - causal systems?
2. What is th physical significance in writing 
u( n )* g( n ) = g( n ) * u( n ) ??</MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>what is the meaning of system externally stable is it same as BIBO stable.</MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>1.Anticipatory controller or feedforward controller
2.this means that it obeys commutative law.
for matrix A*B not always equal B*A you can say it does not obey commutative law. 

</MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>I have a doubt that if poles of system lies on the unit circle then what will be the nature of stability , whether it will be unstable or marginally stable? </MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>1. Systems that play back music or video (CD, iPod, MP3, dvd) don't just display a sound or scene based on what was stored up to that sound, they look into the &amp;quot;future&amp;quot; (digital information about sounds or scenes that are coming up) and incorporate that information into the display. This is non-causal but common.&lt;br /&gt;&lt;br /&gt;2. The physical meaning of this commutative property is that if two systems are cascaded in series and give an output, then the output of whole system remains same even if the systems are interchanged by each other. &lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>one pole on unit circle one can say system is marginally stable.</MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>LAPLACE vs Z TRANSFORM&lt;br /&gt;In Laplace transform, BIBO stability implies poles on left half of origin, where as in z-transform, BIBO stability implies (for causal) z&amp;lt;a, inside the circle of radius a. Now, can we find a relation between z transform and Laplace transform so that we could explain how one condition transforms into another? </MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE> A perfect first order hold can be considered as a noncausal system.
&lt;p&gt;(&lt;span class="edited"&gt;Edited by &lt;a href="http://moodle.iitb.ac.in/user/view.php?id=8266&amp;course=1557"&gt;Moudgalya Kannan. &lt;/a&gt; - original submission Wednesday, 12 January 2011, 11:32 PM&lt;/span&gt;)&lt;/p&gt;</MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>The output of a system with impulse response function h(n), when excited by an input u(n) = the output of a system with impulse response function u(n) excited by an input h(n) </MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>Non causal systems are predictive. As a result, is difficult to give examples from control systems. Easier to give from image processing, in which, the independent variable is position and not time. </MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>The answers given by Pranjal are correct. </MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE> The nomenclature of &amp;quot;externally stable&amp;quot; systems is not popular. It is introduced to distinguish it from &amp;quot;internal stability&amp;quot;, which will be discussed later in the course.&lt;br /&gt;&lt;br /&gt;BIBO and external stability mean the same thing in my nomenclature.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE> Although many people call it as a marginally stable system, in this course, we call it as an unstable system. This is because such a system will be unstable for the smallest model-plant mismatch.&lt;br /&gt;&lt;br /&gt;If a system has a pole ON the unit circle, it is possible to excite it with a bounded input signal and produce an unbounded output signal. An example of this is a step input to a system with a pole at z=1. Equivalently, it is equivalent to giving a step input to a continuous system with a pole at the origin. Such a system is not BIBO stable.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE> Yes, it is possible. It is discussed in Chapter 8 of this book. Tustin approximation does this precisely.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE> Z transform of a discrete time state space system does not explains the state of the system before n=0 and at the time of transition at n=0. It is not understood as to how rewriting state equation with additional term of del(n+1)xo makes it valid for n=0 </MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>In the lecture, while explaining causal systems, you mentioned that if g(n) not equal to 0 for n&lt;0 that means it is anticipating an input.
I&#8217;m not able to understand how this is possible in real life? How can a system know that an input is about to arrive? Also, how will it be able to know what the nature of the input will be like (impulse, step)?
</MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>The case of a CD player is different from usual systems. In a CD player, all the data of future instants is available on the CD, so the controller only has to read it, not anticipate it. Same is true about image processing applications. Are there any examples in situations where there is no prior data, and the system could receive any input?</MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>I am not aware of any &amp;quot;physical&amp;quot; system that is noncausal. Possibly, computing systems can be made to &amp;quot;predict&amp;quot;. An example of this could be AI systems, AI based diagnostic systems, to be more precise. These rely heavily on past data and models built using them.&lt;br /&gt;&lt;br /&gt;We will not deal with them in this course. Let us not spend too much time on this topic.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>That is precisely what I am also saying. If g(n) ~= 0 for n&amp;lt;0, there will be problems. So, in this course, we will assume that g(n)=0 for n&amp;lt;0.&lt;br /&gt;&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>I have never understood what Laplace transforms do...&lt;br /&gt;Say for example, integration gives area under the curve, differentiation gives slope/rate of change, etc.&lt;br /&gt;&lt;br /&gt;and how are they related to Frequency domain. (why does replacing z with i*omega make it response to sine of omea*t )&lt;br /&gt; &lt;br /&gt;&lt;br /&gt;Z-transform seem to make sense as a mathematical tool to replace lot of computation but is that all or do they too have some other significance ?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE> Although we will not be discussing the definition of Laplace Transform in this course, it will become clear through Z-transforms.&lt;br /&gt;&lt;br /&gt;There are many uses of Z-transforms. Please do read the textbook along with my lectures to get an answer for this question. If you do not read the textbook, you are getting only about 50-75% of the course!&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>Here g( n ) and u( n ) are impulse response and inputs respectively. Had they both been transfer functions, we could have said that it signifies cascading. But, here that is not the case. I was just wondering if there was any significance in writing
g( n ) * u( n ) = u( n ) * g( n )</MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>I have already answered this. Please see the Forum. </MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>laplace transforms converts differntial equation into a simple algebric equation which is much easier to solve. its role can be compared to what a log does to make multiplication specially the long one's into simpler algebric calculations </MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>Unable to understand the concept of absolute convergence </MESSAGE>
        <SUBJECT>Re: Questions of Lecture 3 may be posted here</SUBJECT>
        <MESSAGE>By absolute convergence, I mean that the sum of absolute quantities should converge. This has some benefits: 1. It allows us to work with complex quantities. 2. It allows the region of convergence to be on one side of a circle. </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1311</ID>
    <LECTURE>20 Jan - Doubts on lecture 4</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>class4 Q</SUBJECT>
        <MESSAGE>What are the advantages of DTFT over Z transform?</MESSAGE>
        <SUBJECT>Re: class4 Q</SUBJECT>
        <MESSAGE>DTFT is a special case of Z transform it is used to convert discrete time signal into continuous frequency signal.(ie from Z domain to S domain) where as the motivation behind Z-transform is the ease of solving difference equation ie convolution of two discrete time signals gets reduced to the product of two algebric equations. </MESSAGE>
        <SUBJECT>Re: class4 Q</SUBJECT>
        <MESSAGE> Fourier transform is a tool used to decompose an aperiodic input into a combination of periodic inputs. DTFT is FT in discrete time.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: class4 Q</SUBJECT>
        <MESSAGE> While Z-transform of a growing function (or unstable system) can exist, the DTFT cannot exist. &lt;br /&gt;&lt;br /&gt;DTFT gives frequency information directly. As a resut, concepts such as filtering, low pass filters, etc. can be understood easily using DTFT. It is not possible to do this through Z-transform only.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: class4 Q</SUBJECT>
        <MESSAGE>DTFT gives us frequency response, which Z transform is unable to do. Z transform is used because it makes calculation easy. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>class4 Q</SUBJECT>
        <MESSAGE>What is the reason that BIBO stability is not required for Z transform?</MESSAGE>
        <SUBJECT>Re: class4 Q</SUBJECT>
        <MESSAGE>Z transform is defined so as to reperesent the infinite sum in a compact way. if the sequence that is Z transformed is growing ie unbounded then we can handle it by choosing z to be sufficiently large say z&amp;gt;|a| where a can be the outermost pole location. However in case of DTFT we substitute z=e^jw and hence the ROC gets constrained to a unit circle and hence the absolute convergence becomes restrictive for the fourier transform. this is the reason BIBO stability is not required for Z transform.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: class4 Q</SUBJECT>
        <MESSAGE>BIBO stability is required. But unbounded inputs can be handled by defining limitations on values of z. </MESSAGE>
        <SUBJECT>Re: class4 Q</SUBJECT>
        <MESSAGE>The answer by Amit is perfectly correct. Please also see the book. </MESSAGE>
        <SUBJECT>Re: class4 Q</SUBJECT>
        <MESSAGE>What do you mean by BIBO stability is required? For what? Even unstable transfer functions and unbounded functions can have Z-transforms. &lt;br /&gt;&lt;br /&gt;If there is a growing function, make z^n grow at a larger rate and divide the given function by z^n. By this process we make the RATIO of the function to z^n decay. Thus we ensure the convergence of the sum.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Fourier Series in complex form</SUBJECT>
        <MESSAGE>&lt;div style="text-align: left;"&gt;fourier series in complex form is represented by f(x)= summation (n from -infinity to infinity) Cn e^jnx. Ref equation 5.19 page 120 of the book it is not understood how the addit&lt;span style="font-style: italic;"&gt;ional term of 2 pie F0 has come.&lt;/span&gt; &lt;/div&gt;</MESSAGE>
        <SUBJECT>Re: Fourier Series in complex form</SUBJECT>
        <MESSAGE>omega is substituted as 2*pi*f </MESSAGE>
        <SUBJECT>Re: Fourier Series in complex form</SUBJECT>
        <MESSAGE>for periodic signal additional term of 2 pie/Tp comes in the picture, where Tp is fundamental period of the signal.</MESSAGE>
        <SUBJECT>Re: Fourier Series in complex form</SUBJECT>
        <MESSAGE>I think 2*pi*F0 can be replaced by omega to get our familiar expression. e^jwt </MESSAGE>
        <SUBJECT>Re: Fourier Series in complex form</SUBJECT>
        <MESSAGE>the expression you've given isn't complete. fourier series in complex form also has &lt;font color="red"&gt;w&lt;/font&gt; in it i.e. it is f(x) = summation (n from -infinty to infinity) Cn e^j&lt;font color="red"&gt;w&lt;/font&gt;nx.&lt;br&gt;&lt;br&gt;

This jwnx can be written as j(2pif)nx</MESSAGE>
        <SUBJECT>Re: Fourier Series in complex form</SUBJECT>
        <MESSAGE>The answers given by others are correct. This comes from the definition of Fourier series. When w is substituted as 2*pi*f, you get the expression given in equation 5.19. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Inverse Discrete FT</SUBJECT>
        <MESSAGE>In slide 26, integration is used to get inverse Fourier transform i.e. u(m) from U(e^jw). I could not understand how integration can be used. </MESSAGE>
        <SUBJECT>Re: Inverse Discrete FT</SUBJECT>
        <MESSAGE>This is given in the book Pg. no. 125</MESSAGE>
        <SUBJECT>Re: Inverse Discrete FT</SUBJECT>
        <MESSAGE>Please note that w is a continuous variable. As a result, one can integrate. </MESSAGE>
        <SUBJECT>Re: Inverse Discrete FT</SUBJECT>
        <MESSAGE>to get the answere to this question you need to study fourier integrals. fourier integral in complex form has a double integral. the inner integral is the inverse fourier transform. </MESSAGE>
        <SUBJECT>Re: Inverse Discrete FT</SUBJECT>
        <MESSAGE>The integral appears while calculating the fourier coefficients. The derivation is given in the book on pg 125 and pg 120</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>In slide 23, y(n) =e^jwn|G(e^jw)|e^jfi = |G(e^jwn)|e^j(wn+fi),  How expo.n comes inside mod?</SUBJECT>
        <MESSAGE>In slide 23,
y(n) =e^jwn|G(e^jw)|e^jfi = |G(e^jwn)|e^j(wn+fi)
How expo.n comes inside mod?</MESSAGE>
        <SUBJECT>Re: In slide 23, y(n) =e^jwn|G(e^jw)|e^jfi = |G(e^jwn)|e^j(wn+fi),  How expo.n comes inside mod?</SUBJECT>
        <MESSAGE>This is a mistake. It is just a notation, however. In other words, it should be G(e^jw) only. </MESSAGE>
        <SUBJECT>Re: In slide 23, y(n) =e^jwn|G(e^jw)|e^jfi = |G(e^jwn)|e^j(wn+fi),  How expo.n comes inside mod?</SUBJECT>
        <MESSAGE>this is representation of DTFT ie G(jw). </MESSAGE>
        <SUBJECT>Re: In slide 23, y(n) =e^jwn|G(e^jw)|e^jfi = |G(e^jwn)|e^j(wn+fi),  How expo.n comes inside mod?</SUBJECT>
        <MESSAGE>It has been corrected in the book. See page 124. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Differentiation in Z domian</SUBJECT>
        <MESSAGE>
&lt;div class="posting"&gt;In slide no 10, using differentiation, we were able to find the z transform of n1[n]. But what about the region of convergence? Does it remain the same? If so how? &lt;/div&gt; </MESSAGE>
        <SUBJECT>Re: Differentiation in Z domian</SUBJECT>
        <MESSAGE>&lt;br /&gt;the region of convergence ROC is |z|&amp;gt;|a| this remains same as that of Z transform of 1[n] unit step. this is because the poles are repeated but they are still inside the circle with radius a. (note here the value of a is 1). Similary for n^21[n] the ROC is again |z|&amp;gt;|a|, however there are three reapeated poles all at a. For the stable systems the ROC lies outside the circle with radius a. </MESSAGE>
        <SUBJECT>Re: Differentiation in Z domian</SUBJECT>
        <MESSAGE>I believe, although never written explicitly, for z transforms of all real functions there is a condition that |z| is always greater that its largest pole (root of the denominator polynomial)&lt;br /&gt;&lt;br /&gt;So, before differentiating the condition was |z| &amp;gt; a. After differentiation the same condition holds.&lt;br /&gt;&lt;br /&gt;But is there an example where this fails ?&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Differentiation in Z domian</SUBJECT>
        <MESSAGE>I have the same doubt</MESSAGE>
        <SUBJECT>Re: Differentiation in Z domian</SUBJECT>
        <MESSAGE>The condition for convergence can be explicitly calculated. Write down the series and check for convergence. You may wish to use the ratio test. For example, see problem 4.7 in the textbook. </MESSAGE>
        <SUBJECT>Re: Differentiation in Z domian</SUBJECT>
        <MESSAGE>As far as I know, it has to remain the same.
Because, when we define the Z transform, we have z to lie in a region for convergence.
By the definition of differentiation, differentiation can be performed only in the domain of the function.
Thus, the region has to be the same.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide no 6</SUBJECT>
        <MESSAGE>In slide no 6  it mentioned that it valid for |Z|&gt;3

G(Z)/Z  = Z/(Z+3)+ Z/(Z-1)    |Z| &gt;3

I could not understand why it should not be |z|&gt;1.</MESSAGE>
        <SUBJECT>Re: slide no 6</SUBJECT>
        <MESSAGE>circle of radius 3 is bigger than the circle of radius 1 and because the ROC is outside the circle hence we take the outermost pole as the outer limit beyond which the series will be convergent </MESSAGE>
        <SUBJECT>Re: slide no 6</SUBJECT>
        <MESSAGE>Amit's answer is correct. Please also see pages 71-72 of the text. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Frequency response with delay</SUBJECT>
        <MESSAGE>How are the frequency responses dealt when there is a delay? Is it that they introduce an extra phase lag, or there is some other way in which they are dealt?</MESSAGE>
        <SUBJECT>Re: Frequency response with delay</SUBJECT>
        <MESSAGE>Delay will be in powers of z^{-1} only. This is due to the ZOH equivalent approach.&lt;br /&gt;&lt;br /&gt;Recall the discretisation method for delayed systems: see page 27 and problem no. 2.5 in page 29 of the textbook.&lt;br /&gt;&lt;br /&gt;How to handle transfer functions in powers of z^{-1} will be explained from Chapter 9 of the textbook onwards.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>FFT of Moving average filter</SUBJECT>
        <MESSAGE>I solved the question as follows :&lt;br /&gt;&lt;br /&gt;y(n) = 1/3 [ u(n+1) + u(n) + u(n-1) ]&lt;br /&gt;Using shifting theorem,&lt;br /&gt;&lt;br /&gt;Y(n) = 1/3 [z*U(n) + U(n) + (1/z) U(n) ]&lt;br /&gt;&lt;br /&gt;Y(n) / U(n) = 1/3 [z + 1 + z^-1 ]&lt;br /&gt;&lt;br /&gt;Now replace z by e^jw.&lt;br /&gt;&lt;br /&gt;I could not understand the solution in the slides. How could the impulse response be calculated by simply comparing L.H.S and R.H.S , in particular&lt;br /&gt;&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: FFT of Moving average filter</SUBJECT>
        <MESSAGE>this method is also fine ,here we can write,
transfer function as G(e^jw)=Y(Z)/U(Z) at Z=e^jw</MESSAGE>
        <SUBJECT>Re: FFT of Moving average filter</SUBJECT>
        <MESSAGE>i think its ok as the second expression in the slide is the general expression. It has been expanded and compared with the final result already available to us. 

Physically speaking, from the result, we see that the output and any instant depends on the inputs at three instant - (n-1) (n) and (n+1). And by superposition principle, the output will be the superposition of the individual responses.  

P.S - Whenever a post involves terms like (n), choose "Plain Text Format" from the format drop-down menu to avoid the thumbs down icon</MESSAGE>
        <SUBJECT>Re: FFT of Moving average filter</SUBJECT>
        <MESSAGE>This is not what the question is about. He wants to know how to get the expressions for g(0), g(-1), etc. </MESSAGE>
        <SUBJECT>Re: FFT of Moving average filter</SUBJECT>
        <MESSAGE>I guess that you are talking about slide 27. Expand the second equation from n=-infty to n=+infty. Then, match the first and second equations term by term. You will obtain the expressions for g(-1), g(0) and g(1), as given in the slides. For all other n, g(n)=0. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Absolute convergence</SUBJECT>
        <MESSAGE>Why absolute convergence becomes restrictive in case of Fourier transforms? If absolute convergence is not possible then how to check for mean square convergence?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Absolute convergence</SUBJECT>
        <MESSAGE>The emphasis is on &amp;quot;Fourier Transforms&amp;quot; and not on &amp;quot;absolute&amp;quot;.&lt;br /&gt;&lt;br /&gt;This is because, for Fourier Transforms, we insist on |z|=1. On the other hand, z can take a much larger set of values in the case of Z-transform. As z is restricted to a much smaller set, we say that the Fourier Transforms are more restrictive.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Absolute convergence</SUBJECT>
        <MESSAGE>This could be because fourier transforms are basically employed to break down an aperiodic signal into sin and cosine and the coeficients of fourier can have negative values. </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1346</ID>
    <LECTURE>04 - Questions on Quiz</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>Solution to question 4</SUBJECT>
        <MESSAGE>Can some one post solution to question 4 please?

Here is the question : 
     An LTI system with discrete time transfer function z/(z-0.5) is excited by the input u( n ) given by sin(wn)*1( n ). Get the expression for    y( n ).
Write down all the steps. No need to simplify though.</MESSAGE>
        <SUBJECT>Re: Solution to question 4</SUBJECT>
        <MESSAGE>You should simply apply the principle behind sine testing: there is a change in amplitude and phase, as a function of frequency.&lt;br /&gt;&lt;br /&gt;Everyone should try to calculate it. Asking others to post the solution is not ok.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Solution to question 4</SUBJECT>
        <MESSAGE>Sir
What I did was from the given Z transform of the transfer function, I found the impulse response to be g( n ) = (0.5)^n 1( n )
From there I put u( n )=( e^(iwn)-e^(-iwn) )/2 i.e., the sin(wn) and used convolution integral.
I received a comment saying that "Can't hope to get a crisp, elegant answer quickly by this approach"
I din't get a better method for this problem. So, I asked for the right method.</MESSAGE>
        <SUBJECT>Re: Solution to question 4</SUBJECT>
        <MESSAGE>Yes, I agree with this comment from Satyakant. Please see my earlier post - that approach should be used. </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1376</ID>
    <LECTURE>27 Jan. - 05. Please post your questions here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>moving average</SUBJECT>
        <MESSAGE>can we model the noise entering through feedback loop in system, likewise we model external disturbance in system ?&lt;br /&gt;what is difference between moving average &amp;amp; average ?
</MESSAGE>
        <SUBJECT>Re: moving average</SUBJECT>
        <MESSAGE>noise being a stochastic process can be modelled irrespective of its point of entry into the system but here we are interested in modelling the plant and thus are interested in G(z) and H(z) seperately.&lt;br /&gt;average implies mean of a set of number&lt;br /&gt;but if we have a set of very large number then we can divide it into convenient subsets and then take average of this subset, next we shift this subset forward and again take its average. finally we plot connecting all these average points. the variation of this plot is called moving average. Moving average is used in time series data to sort out short term fluctuations and highlight long term trends (wikipedia).&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: moving average</SUBJECT>
        <MESSAGE>1.I think you are talking about the plant with controller, but then also answer is yes. 
2.Moving average-Given a series of numbers and a fixed subset size, the moving average can be obtained by first taking the average of the first subset. The fixed subset size is then shifted forward, creating a new subset of numbers, which is averaged. This process is repeated over the entire data series.
Average-Average of a data set is a measure of the "middle" value of the data set.</MESSAGE>
        <SUBJECT>Re: moving average</SUBJECT>
        <MESSAGE>Yes, it is possible to model the noise. One way to do this is to model it as white noise driven transfer function. We also call this as identification. It is typically taught in an identification course. This topic is covered in detail in Chapter 6 of the textbook. </MESSAGE>
        <SUBJECT>Re: moving average</SUBJECT>
        <MESSAGE>Moving average of a set of data could be calculated by first taking the average of the some definite number of set and then continue the calculation of average in a loop by adding one value at each loop.

While the average is total values of the data divided by the total numbers.</MESSAGE>
        <SUBJECT>Re: moving average</SUBJECT>
        <MESSAGE>I think it can be modelled likewise because we did not consider location of the noise source while modelling.&lt;br /&gt;Moving average and average have the same function - i.e to find the average of a set of values. Moving average is used when the number of values is too high to calculate the average in one go. The values are divided into subsets and the average of each subset is calculated and the final average is obtained from the average of these subsets.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>DTFT &amp; DFT</SUBJECT>
        <MESSAGE>What is difference between DTFT and DFT?&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: DTFT &amp; DFT</SUBJECT>
        <MESSAGE>If input is discrete, the Fourier transform becomes a DTFT.
If it is periodic, the Fourier transform becomes a Fourier series.
If it is both, the Fourier transform becomes a DFT.</MESSAGE>
        <SUBJECT>Re: DTFT &amp; DFT</SUBJECT>
        <MESSAGE>DFT is discrete in time and frequency but DTFT is discrete in only time and is continuous in frequency.&lt;br /&gt;if you got discrete time signal say after sampling and you want to decompose it to find out different frequencie(ie discrete) you would be using DFT to get the sum of sines with diferrent amplitudes and frequecy.&lt;br /&gt;however for the same discrete time signal if you use DTFT then you would get continuous signal which would contain only one frequecy (which though would be the result of various freq contained in that signal as explained by fourier series)&lt;br /&gt;in real world we use DFT for calculations.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: DTFT &amp; DFT</SUBJECT>
        <MESSAGE>we can say that DFT is the sampled version of DTFT
</MESSAGE>
        <SUBJECT>Re: DTFT &amp; DFT</SUBJECT>
        <MESSAGE>we can say that DFT is the sampled version of DTFT
</MESSAGE>
        <SUBJECT>Re: DTFT &amp; DFT</SUBJECT>
        <MESSAGE>The reply by Prafulla is not quite correct. </MESSAGE>
        <SUBJECT>Re: DTFT &amp; DFT</SUBJECT>
        <MESSAGE>The reply given by Jagdish is partly correct. &lt;br /&gt;&lt;br /&gt;We sample the DTFT first. This results in the time domain signal becoming periodic. As it is periodic, take the central portion or the fundamental component. Thus you no longer have an infinite integral to get back the time domain function g(n) but only a sum of finite number of components.&lt;br /&gt;&lt;br /&gt;This topic is discussed in Section 5.5 of the textbook.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: DTFT &amp; DFT</SUBJECT>
        <MESSAGE>In DTFT freq is constant whereas in DFT freq become discrete.</MESSAGE>
        <SUBJECT>Re: DTFT &amp; DFT</SUBJECT>
        <MESSAGE>I don't know. I think they both are the same. I am curious to know the answer...</MESSAGE>
        <SUBJECT>Re: DTFT &amp; DFT</SUBJECT>
        <MESSAGE>DFT is discrete in both time &amp; frequency domain 
x[n] &lt;=&gt; X[k]
x[n] &lt;=&gt; X[w] 
 
DTFT is discrete only in time domain </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>In slide 28, Will akkXk term get repeat?</SUBJECT>
        <MESSAGE>In slide 28,
dQ/dxk= (Ax)k + (A^Tx)k;
Will akkXk term get repeat?
</MESSAGE>
        <SUBJECT>Re: In slide 28, Will akkXk term get repeat?</SUBJECT>
        <MESSAGE>no term will get repeated because all other term in the matrix are zero and only kth row of matrix (Ax) and kth row of Matrix (A^Tx) remains which gets added up this is because you are differentiating with xk and so any term not having xk will be zero. </MESSAGE>
        <SUBJECT>Re: In slide 28, Will akkXk term get repeat?</SUBJECT>
        <MESSAGE>But center term is common in both row as well as column.</MESSAGE>
        <SUBJECT>Re: In slide 28, Will akkXk term get repeat?</SUBJECT>
        <MESSAGE>Yes, it will come twice. It comes twice. It is present in each of the two terms on the right hand side. But it does not create any problem. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>z transform of white noise</SUBJECT>
        <MESSAGE>If we can take Z transform of bounded as well as unbounded signals why cant we take Z transform of white noise?</MESSAGE>
        <SUBJECT>Re: z transform of white noise</SUBJECT>
        <MESSAGE>z transform is used to make convolution of two infinite discrete time sequence simpler.also z transform exists if the series/ sequence converges. z transform of white noise does not exist because it is stationary stochastic process which means that if white noise could be represented by a sequence then its values will independant and identical as time progresses which means that it will never converge. but varience of these values exists(although the mean of white noise is zero) and is given by the autocovarience function ACF which is an impulse function and it is well known that the z transform of impulse function exists. &lt;br /&gt;&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: z transform of white noise</SUBJECT>
        <MESSAGE>noise is undeterministic signals &#160;
</MESSAGE>
        <SUBJECT>Re: z transform of white noise</SUBJECT>
        <MESSAGE>z transform is defined as summation of u(k)z^(-k) right?
This u(k) is always unpredictable. It is not an LTI system. So , I think that is the reason why we can't take Z transform for white noise.</MESSAGE>
        <SUBJECT>Re: z transform of white noise</SUBJECT>
        <MESSAGE>For z transform the function has to be defined properly(deterministic), but white noise is not a deterministic quantity. It can only be defined as a stochastic process. </MESSAGE>
        <SUBJECT>Re: z transform of white noise</SUBJECT>
        <MESSAGE> The answers given by the others are pretty close. The reason is that you need a definite form to evaluate the Z-transform. &lt;br /&gt;&lt;br /&gt;White noise is actually a pretty difficult concept. The noise at any point should not be correlated with the noise at any other point. It is difficult to model this and hence naturally, not possible to evaluate Z-transform of it. Correlation, however, converts it into a quantity that can easily be handled.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: z transform of white noise</SUBJECT>
        <MESSAGE>I think we can take the Z transform of white noise but not the Fourier transform.

I am not clear with why Fourier transform we cannot use. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Mixed notation</SUBJECT>
        <MESSAGE>If we use mixed notation output y(n)is combination of Z and n term,how to remove Z terms? </MESSAGE>
        <SUBJECT>Re: Mixed notation</SUBJECT>
        <MESSAGE>Mixed notation as the implied by the word is only a notation in which the transfer function is in Z domain and the variables in time domain in some books this is called operator notation.however when you see mixed notation you should realize that you are looking at the time domain notation of the equation which is y(n) = g(n)*u(n)+h(n) * zeta(n).&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Mixed notation</SUBJECT>
        <MESSAGE>Yes, what Amit has written is correct. The mixed notation is used in the place of convolution. </MESSAGE>
        <SUBJECT>Re: Mixed notation</SUBJECT>
        <MESSAGE>I think it is just a notation and the z and n terms are not used together in the equation, so no problem of removing z terms </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>output of ZOH</SUBJECT>
        <MESSAGE>the output of ZOH is a staircase waveform, which implies output contains more than one frequency. from the Bode plot of ZOH it is clear that it behaves like a low pass filter but its cutoff frequency is well beyond the sampling frequency/nyquist frequency.&lt;br /&gt;the question is do we employ digital filter after ZOH to get fundamental frequency and if yes what are those filters?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: output of ZOH</SUBJECT>
        <MESSAGE>Please note that the ZOH is the procedure to reconstruct. We do NOT recover the continuous signal from the discrete signal through frequency domain techniques. The frequency domain method is used only for analysis. Please also note that the frequency domain method is an approximate method only, as the transfer function method only works for linear time invariant systems. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>ARMA process</SUBJECT>
        <MESSAGE>in ARMA process its not clear as how autoregressive process is equal to moving average process to begin with and it is not explained in the book also. </MESSAGE>
        <SUBJECT>Re: ARMA process</SUBJECT>
        <MESSAGE>Given a time series of data v(n), the ARMA model is a tool for understanding and, perhaps, predicting future values in this series. The model consists of two parts, an autoregressive (AR) part and a moving average (MA) part.
ARMA is appropriate when a system is a function of a series of unobserved shocks (the MA part) as well as its own behavior.</MESSAGE>
        <SUBJECT>Re: ARMA process</SUBJECT>
        <MESSAGE>No, Prafulla's answer is not to the point. </MESSAGE>
        <SUBJECT>Re: ARMA process</SUBJECT>
        <MESSAGE>Where do I say that AR process is equal to MA process? These two are quite different. Can you please explain why you have this confusion? Perhaps we should address this confusion. </MESSAGE>
        <SUBJECT>Re: ARMA process</SUBJECT>
        <MESSAGE>&lt;div style="text-align: left;"&gt;The equation 6.70 page 178 in the book is used in the video lecture does LHS of this equation is AR and RHS of this equation MA, because we substitute p and q = 0 subsequently and say the left over equation is MA and AR respectively. this part is not understood.&lt;br /&gt; &lt;/div&gt;</MESSAGE>
        <SUBJECT>Re: ARMA process</SUBJECT>
        <MESSAGE>Even i am unable to connect the v dependence on its previous value and weighted average of white noise and finally relating two of them i.e., moving average and weighted average. </MESSAGE>
        <SUBJECT>Re: ARMA process</SUBJECT>
        <MESSAGE>ARMA process models the noise as both auto regressive and moving average. &lt;br /&gt;v( n ) is autoregressive and C( n ) is moving average.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>neglecting white noise</SUBJECT>
        <MESSAGE>we have used regression equation and least square estimation for finding the model parameters. it is not understood that why did we choose to model white noise if in the end we were going to neglect it in least square estimation. </MESSAGE>
        <SUBJECT>Re: neglecting white noise</SUBJECT>
        <MESSAGE>In LS we neglect the white noise to estimate the error.estimate. Error:
~ Z(k)=Z(k) - ^ Z(k)</MESSAGE>
        <SUBJECT>Re: neglecting white noise</SUBJECT>
        <MESSAGE>As mentioned in the lecture and in the book, if the difference between the model and the data is only white noise, that is the best we can achieve. Subject to this condition, we model the system and obtain the parameters in the least squares approach. </MESSAGE>
        <SUBJECT>Re: neglecting white noise</SUBJECT>
        <MESSAGE>As far as I know, we actually did not neglect that &#926;(k). We are estimating Z(k) such that, the effect of we assuming &#926;(k)to be negligible, is not seen by minimizing Z_tilda_transpose*W*Z_tilda function, which involves the &#926;(k) term too.</MESSAGE>
        <SUBJECT>Re: neglecting white noise</SUBJECT>
        <MESSAGE> We don't neglect noise, we just assume that the theta estimated is good enough to model the noise. &lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: neglecting white noise</SUBJECT>
        <MESSAGE> A small correction to what Prasanna has written. Substitute the last word, &amp;quot;noise&amp;quot; with &amp;quot;system&amp;quot;. The word system includes everything, noise as well. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>White Noise</SUBJECT>
        <MESSAGE>In white noise, when each value at each instant is independent of one another, how can we assure that they have constant mean and standard deviation?
Like say,
 at t=0, it is 3 =&amp;gt; mean is 3
 at t=1, it is 7 =&amp;gt; mean is 5
 at t=2, it is -2=&amp;gt; mean is 4

here we don't find constant mean. What I suppose to ask is, how does computer or any micro-controller simulate random noise? It never knows when I am going to stop the simulation. How can it assure the mean and standard deviation?

To put the question in simpler terms, how is the white noise generated? </MESSAGE>
        <SUBJECT>Re: White Noise</SUBJECT>
        <MESSAGE>i think the concept of white noise is valid only for large data sets i.e. when we have a huge sample of data, if it is white noise, we will find its mean to be zero, and its standard deviation will be some constant value i.e. a truly random process.

regarding white noise generation, this page might give some insight: http://www.maxim-ic.com/app-notes/index.mvp/id/3469</MESSAGE>
        <SUBJECT>Re: White Noise</SUBJECT>
        <MESSAGE>Mean for white noise is actually the average of large number of samples. You cant take just a sample or a two. Mean makes sense only when N is large. The reason for N being large is that the white noise has a large number of frequencies. If the noise was not white or colored), then you would probably get the desired mean for smaller number of N. Let me give you an example. Suppose that the frequency of the noise is zero, which implies the noise is basically a constant bias. So in this case the mean can be found out using N = 1. &lt;br /&gt; Its impossible to generate white noise ideally(limited frequency range). We can just go closer and closer the white noise. </MESSAGE>
        <SUBJECT>Re: White Noise</SUBJECT>
        <MESSAGE>What Tim and Prasanna have written are quite correct. You need a large number of samples for this idea to work. As an example, consider the tossing of a fair coin and that there are only two outcomes: head or tails. If you throw the coin a large number of times, each outcome will come half the time. But the answer could be different if you do this experiment less number of times.&lt;br /&gt;&lt;br /&gt;Random number is one popular way to create white noise. In computer simulations, we use pseudo random number generators.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: White Noise</SUBJECT>
        <MESSAGE>in white noise the mean is zero. to give you the example of white noise lec-6 is recorded with white noise you can hear that while playing it. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Parameter k in slide 23</SUBJECT>
        <MESSAGE>I'm not able to understand the utility of the parameter k in slide 23.
  what i inferred is that we use k when we are trying to find the transfer function concurrently, as the experiment is progressing as against the other case when all the data is with us before hand. is this understanding right? 
  also, what is moving window that was mentioned in the video?</MESSAGE>
        <SUBJECT>Re: Parameter k in slide 23</SUBJECT>
        <MESSAGE>yeah! i have a similar doubt regarding that "k" parameter. What is that "only one set of experimental data" referring to? What I interpret is we perform same experiment many times, but we get different values due to the different values of noise at each point of time. But how is it related with "k" which I think it is, as Tim says as, the experiment progresses, they are the readings with respect to time.</MESSAGE>
        <SUBJECT>Re: Parameter k in slide 23</SUBJECT>
        <MESSAGE>The argument is required if the model will change as a function of time, indicated by the parameter k. You can take a batch of data, up to the time k and do the estimation. When you do this again at some other time, this integer k will change. </MESSAGE>
        <SUBJECT>Re: Parameter k in slide 23</SUBJECT>
        <MESSAGE>your understanding i think is correct </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Detection of aliasing</SUBJECT>
        <MESSAGE>According to first few slides, you can determine if the input signal is aliased. But as I see it is not possible to determine this. For example if the input signal is unknown, we can't say for sure, whether it represents a true signal or an aliased signal of a much higher signal. </MESSAGE>
        <SUBJECT>Re: Detection of aliasing</SUBJECT>
        <MESSAGE>Domain knowledge is required for deciding the max frequency of the signal. Once max ferq. is decided we can use filter to avoid aliasing.</MESSAGE>
        <SUBJECT>Re: Detection of aliasing</SUBJECT>
        <MESSAGE>What Prafulla says is quite correct. </MESSAGE>
        <SUBJECT>Re: Detection of aliasing</SUBJECT>
        <MESSAGE>here we are talking about reconstruction using fourier transform if the input signal is unknown then we do the fourier transform DTFT to get the band of frequencies (in case the band is infinite then we neglect the higher freq using band pass filter) we take the principle part and from there we invert it to get the reconstructed signal. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>In Slide 21..matix equation</SUBJECT>
        <MESSAGE>Regarding to this matrix expression, on page 161 in the book it is given that the number of rows in the matrix equation should be greater than or equal to N+1,&lt;br /&gt;but it should be less than or equal to N+1 because max. range of b(N) is N+1?&lt;br /&gt;
</MESSAGE>
        <SUBJECT>Re: In Slide 21..matix equation</SUBJECT>
        <MESSAGE>No, it should be greater than or equal to N+1.&lt;br /&gt;&lt;br /&gt;Suppose that you have to determine two unknowns through least squares estimate. How many measurements should you take? Is this 2 or more? Or is it 2 or less?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: In Slide 21..matix equation</SUBJECT>
        <MESSAGE>Since there are N+1 unknowns, u need N+1 rows minimum, otherwise we will get a singular matrix.</MESSAGE>
        <SUBJECT>Re: In Slide 21..matix equation</SUBJECT>
        <MESSAGE>i think the book is correct.&lt;br /&gt;&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>ACF</SUBJECT>
        <MESSAGE>I am not able to understand the role of ACF </MESSAGE>
        <SUBJECT>Re: ACF</SUBJECT>
        <MESSAGE>are you asking auto covarience function or auto corelation function both are given by ACF. auto covarience function denotes the covarience of a signal against a time shifted version of itself. where as auto corelation function cross correlation of signal with itself, used to find repeated patterns </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Sampling rate</SUBJECT>
        <MESSAGE>How does the adjacent curves overlap if the sampling rate is low (aliasing)? </MESSAGE>
        <SUBJECT>Re: Sampling rate</SUBJECT>
        <MESSAGE>If Ts is low then Fs is large and exceeds B. Therefore there is overlapping </MESSAGE>
        <SUBJECT>Re: Sampling rate</SUBJECT>
        <MESSAGE>if sampling freq Fs is less than B then as seen in the graph the curve overlap this is because the bandwidth will be more than sampling frequency and hence would lead to Aliasing. To avoid that Fs has to be more than B and according to shanons sampling theorem should be 2Fmax where Fmax </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1393</ID>
    <LECTURE>31 Jan. - 06. Please post your questions here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>Analogy with frequency response?</SUBJECT>
        <MESSAGE>1. We, in plotting the Nyquist plots, observe the open loop response by mathematically substituting z = exp^(jw)
Is there any analogy with frequency response, where we do the same (May be some thing like, the gain amplification, etc)?

2. If we have a closed loop where in feedback we have another proportional controller, along with what was discussed in the class,do we need to consider loop gain or just the forward loop transfer function?</MESSAGE>
        <SUBJECT>Re: Analogy with frequency response?</SUBJECT>
        <MESSAGE>1.Denominator of G(z) and 1+KG(z) are same,also we consider C1 to be unit circle, therefore we put z=exp(jw).
In defining DTFT we put z=exp(jw)
2. I didnt understand your second Q. clearly but if anything is in feedback path we need to consider its T.F. also.</MESSAGE>
        <SUBJECT>Re: Analogy with frequency response?</SUBJECT>
        <MESSAGE>In continuous time control also we do the substitution s=jw to arrive at frequency response. Mathematically, it turns out to be that way.&lt;br /&gt;&lt;br /&gt;In a similar way, the frequency response in discrete time domain is obtained by substituting z=e^{jw}. &lt;br /&gt;&lt;br /&gt;So, there is no difference at all in the way the frequency response is arrived at, whether it is the continuous time or discrete time. The mathematical procedure is the same. The interpretation also is IDENTICAL.&lt;br /&gt;&lt;br /&gt;Now, the second question:&lt;br /&gt;&lt;br /&gt;Please note that the stability is determined by the zeros of the characteristic equation. So, if there are two controllers K1 and K2 and if the plant is G, the ch. equation is 1+K1K2G=0. So, to answer your question, we need to take the return difference.&lt;br /&gt;&lt;br /&gt;Please go back to the derivation of the procedure followed in Nyquist plot, starting from the stability arguments of a closed loop system.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Analogy with frequency response?</SUBJECT>
        <MESSAGE>in freqency response we substitute jw instead of s where as in this case we substitute e^jw in place of z. the mapping of s-plane and z-plane is a unit circle describe by z=e^sh.&lt;br /&gt;we need to consider loop gain.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Analogy with frequency response?</SUBJECT>
        <MESSAGE> I believe that by putting $$z = exp(j\omega)$$ we are just restricting the values of z to lie on the unit circle, thats it. I don't think it is analogous to frequency response, because we put the value of $$\omega = 90^\circ$$, $$0^\circ$$ etc. </MESSAGE>
        <SUBJECT>Re: Analogy with frequency response?</SUBJECT>
        <MESSAGE>The Nyquist and the frequency response plots are just the mathematical manipulations to check the stability of the system and the way we approach the problem in both the cases are almost similar concept except that the substitutions are different.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Counting no. of encirclement</SUBJECT>
        <MESSAGE>While counting no. of encirclement of origin we consider phasor from origin to infinity, can we consider any angle to construct phasor?  </MESSAGE>
        <SUBJECT>Re: Counting no. of encirclement</SUBJECT>
        <MESSAGE>Yes, any angle is ok. It should start at the origin and go to infinity. </MESSAGE>
        <SUBJECT>Re: Counting no. of encirclement</SUBJECT>
        <MESSAGE> angle can be determined by taking any point on the curve and the line joining the origin and that point will make angle with the positive real axis. </MESSAGE>
        <SUBJECT>Re: Counting no. of encirclement</SUBJECT>
        <MESSAGE>Yes. I think we can consider any angle as the Nyquist plot is symmetric </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Stability margins</SUBJECT>
        <MESSAGE>Can we say stability margins are kept to handled modelling errors (modelling approximations)?</MESSAGE>
        <SUBJECT>Re: Stability margins</SUBJECT>
        <MESSAGE>Although this is the main reason, this is not the only reason. We should also allow for &amp;quot;changes&amp;quot; that may happen in the future. </MESSAGE>
        <SUBJECT>Re: Stability margins</SUBJECT>
        <MESSAGE>yes stability margins are kept to handle modelling errors because determination of the exact model is expensive and time consuming hence the need for statistical identification which is covered in the last lecture. also margins are required to cater for the variations in response to varying input. </MESSAGE>
        <SUBJECT>Re: Stability margins</SUBJECT>
        <MESSAGE>yes it does take care of that but basically it give the degree of relative stability; in other words, they tell how far the given system is from the instability region</MESSAGE>
        <SUBJECT>Re: Stability margins</SUBJECT>
        <MESSAGE>Yes, modelling errors. Also, as the book mentions, the transfer function itself may vary due to wear and tear - causing the behaviour of the system to change. </MESSAGE>
        <SUBJECT>Re: Stability margins</SUBJECT>
        <MESSAGE> Yes, because it is very difficult to model the system exactly, also the disturbances cannot be completely modelled. Gain margin and Phase margins also indicate stability of the system. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Number of poles and zeros</SUBJECT>
        <MESSAGE> Consider $$1/(z*(z-1))$$, Can you say that it has two poles 0,1 and two zeros at $$\infty$$? If so, then every function will have same number of poles and zeros, no matter what the t/f is. Right?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Number of poles and zeros</SUBJECT>
        <MESSAGE>yes, we can say that.The no poles  at (finite value + at infinite)  are alway equal to no of Zeros( at  finite value and at infinity).</MESSAGE>
        <SUBJECT>Re: Number of poles and zeros</SUBJECT>
        <MESSAGE>What Surinder says is correct. If the zeros include those at infinity, then the number of poles = number of zeros. The reason for this is the definition of zeros at infinity:&lt;br /&gt;&lt;br /&gt;number of zeros at infinity = number of poles - number of finite zeros. </MESSAGE>
        <SUBJECT>Re: Number of poles and zeros</SUBJECT>
        <MESSAGE>
&lt;div style="text-align: center;"&gt;In my view there are two poles and no zeros and in this case the degree of denominator is more than the degree of numerator. assuming that poles and zeros at infinity do not affect the response what you say might be correct.&lt;br /&gt; &lt;/div&gt;</MESSAGE>
        <SUBJECT>Re: Number of poles and zeros</SUBJECT>
        <MESSAGE>One can either consider a pole at 0 or zero at infinity. But we are interested in finite poles and zeros.</MESSAGE>
        <SUBJECT>Re: Number of poles and zeros</SUBJECT>
        <MESSAGE>Yes. But it is the finite poles/zeros which affect the system.</MESSAGE>
        <SUBJECT>Re: Number of poles and zeros</SUBJECT>
        <MESSAGE>Zeros at infinity do not affect system response. Mathematically the statement is right but physically zero at infinity has no significance. </MESSAGE>
        <SUBJECT>Re: Number of poles and zeros</SUBJECT>
        <MESSAGE>True, this we can think by considering the root locus plot where we assume that all the poles goes to zero so if there are no or less zeros than the poles the root locus plot will go to infinity which precisely on the presumption that zero exist at infinity. The vice versa is also true considering poles are less than zeros.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Feed forward controller</SUBJECT>
        <MESSAGE>1) In feed forward controller, it is mentioned in the book that , if G is minimum phase then its inverse is stable and then controller can be implemented and vice-versa. Please explain?&lt;br /&gt;2) Any example of feed forward control used in industrial applications?&lt;br /&gt;
</MESSAGE>
        <SUBJECT>Re: Feed forward controller</SUBJECT>
        <MESSAGE>A minimum phase system has its poles and zeros inside the unit circle. Naturally, its inverse will be stable. As feed forward controller is based on the inverse, this statement is made.&lt;br /&gt;&lt;br /&gt;Gain scheduling is a case of feed forward control. The industry generally uses a combination of feed forward and feedback control.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Feed forward controller</SUBJECT>
        <MESSAGE> G minimum phase means that no zero lies on the right hand side of the open loop. the zero of the open loop is the pole of the closed loop as explained in the video thus no pole lies on the RHS of the closed loop hence the system is stable.Now if we apply the same analogy to discrete system this means that no zero lies &lt;span style="color: rgb(255, 0, 0);"&gt;on or outside&lt;/span&gt; the unit circle&lt;br /&gt;
&lt;p&gt;(&lt;span class="edited"&gt;Edited by &lt;a href="http://moodle.iitb.ac.in/user/view.php?id=8266&amp;course=1557"&gt;Moudgalya Kannan. &lt;/a&gt; - original submission Sunday, 30 January 2011, 11:20 PM&lt;/span&gt;)&lt;/p&gt;</MESSAGE>
        <SUBJECT>Re: Feed forward controller</SUBJECT>
        <MESSAGE>A linear, time-invariant system is said to be minimum-phase if the system and its inverse are causal and stable. A discrete-time system with rational transfer function H(z) can only satisfy causality and stability requirements if all of its poles are inside the unit circle. However, we are free to choose whether the zeros of the system are inside or outside the unit circle. A system is minimum-phase if all its zeros are also inside the unit circle.
it is very difficult to apply only feedforward controller so industry normaly prefer feedback+feedforward controller</MESSAGE>
        <SUBJECT>Re: Feed forward controller</SUBJECT>
        <MESSAGE>I don't know the answer for the 1st question.
But, for the 2nd one, feed forward control can be used as a disturbance rejection technique.

For example, in the last semester, we did temperature control of an apparatus CE - 103, where there is a fan and a vane at two ends of a cylindrical tube and we have heater which heats the air drawn by the fan. Obviously the vane opening affects the system dynamics. We implemented feed forward controller to this by taking feedback from the vane opening and found a gain value such that the opening of the vane does not affect the steady state value of temperature.

In this experiment, the vane opening can be taken as a disturbance and thus, feed forward controller is acting as if it was a disturbance rejection technique. </MESSAGE>
        <SUBJECT>Re: Feed forward controller</SUBJECT>
        <MESSAGE>We feed forward control in controls lab for a thermal setup (CE103). The disturbance in the air flow rate( because of change in vane position) was taken care of by feedforward.&lt;br /&gt;&lt;br /&gt;In &lt;a title="Control theory" href="http://en.wikipedia.org/wiki/Control_theory"&gt;control theory&lt;/a&gt; and &lt;a title="Signal processing" href="http://en.wikipedia.org/wiki/Signal_processing"&gt;signal processing&lt;/a&gt;, a &lt;a title="LTI system theory" href="http://en.wikipedia.org/wiki/LTI_system_theory"&gt;linear, time-invariant&lt;/a&gt; system is said to be &lt;b&gt;minimum-phase&lt;/b&gt; if the system and its &lt;a title="Inverse" href="http://en.wikipedia.org/wiki/Inverse"&gt;inverse&lt;/a&gt; are &lt;a title="Causal system" href="http://en.wikipedia.org/wiki/Causal_system"&gt;causal&lt;/a&gt; and &lt;a title="BIBO stability" href="http://en.wikipedia.org/wiki/BIBO_stability"&gt;stable&lt;/a&gt; (wikipedia). From eqn 7.2 we require F to be inverse of G for disturbance rejection, therefore G should be minimum phase&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>pole on the imaginary axis </SUBJECT>
        <MESSAGE>if the open loop GH pole lies on the imaginary axis then how do we define the stability of the closed loop pole in terms of number of encirclement ?&lt;br /&gt;(&lt;span style="color: rgb(153, 0, 0);"&gt;note: if there are n pole in the right half of s plane of GH (open loop) then the encirclement of -1+0j in counter clockwise direction is n times&lt;/span&gt;&lt;br style="color: rgb(153, 0, 0);" /&gt;&lt;span style="color: rgb(153, 0, 0);"&gt;also if there are no poles of GH(open loop) in the right half of s plane then the net encirclement is zero&lt;/span&gt;)&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: pole on the imaginary axis </SUBJECT>
        <MESSAGE>Depending on the way the indentation is done on the unit circle, the pole on the unit circle is taken as either stable or unstable and the encirclement criterion determined. Please do the problem 7.2 on page 299 to understand this.&lt;br /&gt;&lt;br /&gt;The stability criterion, however, is the same, irrespective of the way indentation is done.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: pole on the imaginary axis </SUBJECT>
        <MESSAGE>To be able to analyze systems with poles on the imaginary axis, the Nyquist Contour can be modified to avoid passing through the point 0 + j&#969;. One way to do it is to construct a semicircular arc with radius  around 0 + j&#969;, that starts at 0 + j(&#969; &#8722; r) and travels anticlockwise to 0 + j(&#969; + r). Such a modification implies that the phasor G(s) travels along an arc of infinite radius by &#8722; l&#960;, where l is the multiplicity of the pole on the imaginary axis.</MESSAGE>
        <SUBJECT>Re: pole on the imaginary axis </SUBJECT>
        <MESSAGE>Please see my earlier post on this. I would want you to think in Z-transform domain. </MESSAGE>
        <SUBJECT>Re: pole on the imaginary axis </SUBJECT>
        <MESSAGE>Open loop pole on imaginary axis means =&amp;gt; something like 2/(s+ 3j)(just an example) &lt;/br&gt;

As far as I know, &lt;b&gt;There is no physical system, whose dynamics can be defined by imaginary numbers&lt;/b&gt; &lt;/br&gt; &lt;/br&gt;

Suppose say, RC Circuit, where we have, first order dynamics some thing like (V/R)/(1+tau*s) here tau is a real number given by RC, right? &lt;/br&gt; &lt;/br&gt;

As far as I know, in open loop, we will be having only real terms, which define physical parameters (not expected to be imaginary). SO there is no question of open loop pole on imaginary axis. &lt;/br&gt; &lt;/br&gt;</MESSAGE>
        <SUBJECT>Re: pole on the imaginary axis </SUBJECT>
        <MESSAGE>While what you say is true, it is possible to have a transfer function of the form 1/(s^2+9). This gives rise to two complex conjugate poles on the imaginary axis. As a result, the question posed is quite valid even in real world. </MESSAGE>
        <SUBJECT>Re: pole on the imaginary axis </SUBJECT>
        <MESSAGE>while selecting the contour C1 for the nyquist plot we use indentation to avoid location of poles on the contour and therefore the criteria of number of encirclements would remain the same </MESSAGE>
        <SUBJECT>Re: pole on the imaginary axis </SUBJECT>
        <MESSAGE>Sorry sir, I missed out that point!</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Motivation for making Nyquist plots</SUBJECT>
        <MESSAGE>Why do we use nyquist plots when there are other simpler (that involve, less visualization) methods like root-locus, bode-plots available ?&lt;br /&gt;&lt;br /&gt;By complexity in visualization I mean, counting the number of encirclements is not an easy task. &lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Motivation for making Nyquist plots</SUBJECT>
        <MESSAGE>on the contrary nyquist plots use polar coordinates and the system of using two plots ie mag and phase as in bode is not required gain and phase margins can easily be calculated and stability criteria can easily be viewed.As all the poles and zeros lie in the unit circle i personally believe that this is more compact and simple. </MESSAGE>
        <SUBJECT>Re: Motivation for making Nyquist plots</SUBJECT>
        <MESSAGE>We can use Nyquist plots in Z domain. Also it is very easy to find stability margins(GM &amp; PM).
Counting encirclements is eazy such that take a phaser from origin towards infinity and count the clockwise encirclements and counterclockwise encirclements and then subtract it.</MESSAGE>
        <SUBJECT>Re: Motivation for making Nyquist plots</SUBJECT>
        <MESSAGE>Let me first address root locus vs. (Bode or Nyquist) plot.&lt;br /&gt;&lt;br /&gt;To draw root locus, you need to know the form of the transfer function: pole, zero location, etc. On the other hand, frequency response plots (Bode and Nyquist) can be drawn from experiments.&lt;br /&gt;&lt;br /&gt;From the above statement, a plant can be modelled using frequency response plots.&lt;br /&gt;&lt;br /&gt;Bode plot and Nyquist plot are equivalent. They contain the same information. Bode's method was the first one to be developed chronologically. But some things were not clear at that time. For example, the general wisdom at that time was that if you decreased the gain, the system would be more stable. But some times, the opposite thing happened: when the gain decreased, the system became unstable in some cases. Nyquist came up with a method to explain this. His method, based on encirclements, was easier to understand. Conditional stability, etc. could be explained more easily with it. Thus, although they contain the same information, Bode and Nyquist plots give different perspectives.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Motivation for making Nyquist plots</SUBJECT>
        <MESSAGE>In my personal opinion, I felt Nyquist plots are simpler than bode plots or root locus where we have to remember and follow certain rules. (This is not some technical answer, but I felt that Nyquist plots are thus useful)</MESSAGE>
        <SUBJECT>Re: Motivation for making Nyquist plots</SUBJECT>
        <MESSAGE>Same doubt. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>contour</SUBJECT>
        <MESSAGE>can we extend the contour c&lt;sub&gt;1&lt;/sub&gt;, so that it all poles &amp;amp; zeros lies within it.&lt;br /&gt;if yes upto what extend we can do so &amp;amp; how&lt;br /&gt;
</MESSAGE>
        <SUBJECT>Re: contour</SUBJECT>
        <MESSAGE>If by covering all poles and zeros, you can come up with a stability result, you can certainly do it.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Unmodelled Delay</SUBJECT>
        <MESSAGE>What is the meaning of 'Handle unmodelled delay' in last slide?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Unmodelled Delay</SUBJECT>
        <MESSAGE>This means that although there could be some delay, the modelling person may ignore it for various reasons, one of them being simplicity. As a result, the assumed model is not quite correct. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 11</SUBJECT>
        <MESSAGE>sir will u please explain the significance of negative N.&lt;br /&gt;because for stability N = no. of open loop unstable pole.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: slide 11</SUBJECT>
        <MESSAGE>N implies that there are encirclements in the opposite direction.&lt;br /&gt;&lt;br /&gt;One has to look for a physical interpretation from the equation Z = N+P. This equation gives Z, the number of closed loop unstable poles. Does Z become negative in your calculation?&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Pole on unit circle</SUBJECT>
        <MESSAGE>In example 7.2 we considered contour C1 so that the pole was inside the unit circle. Will we get the same results if the pole was taken outside the unit circle? </MESSAGE>
        <SUBJECT>Re: Pole on unit circle</SUBJECT>
        <MESSAGE>All of you should really try this out. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>DOF Feedback control</SUBJECT>
        <MESSAGE>Why both disturbance rejection and tracking control are not possible in one DOF controller?
It should be possible because in feedback we are using output signal which has disturbance signal also.</MESSAGE>
        <SUBJECT>Re: DOF Feedback control</SUBJECT>
        <MESSAGE>It is well explained in the book at section 7.1.2 that for 1-DOF  system 

 output y(n) = T(z)R(n)+ S(z)v(n)

where T(z)and S(z) are interdependent and follow the  relation of T+S = 1

Therefore if one [T(z)or S(z)] is specified then the other get fixed by the above relation, therefore we require 2-DOF structure.</MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1404</ID>
    <LECTURE>03 Feb. 07 - Post your doubts here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>unstable poles of signal</SUBJECT>
        <MESSAGE>sir could you please explain the concept of unstable poles of a signal with some examples. </MESSAGE>
        <SUBJECT>Re: unstable poles of signal</SUBJECT>
        <MESSAGE> I have referred to signals, such as step and ramp as unstable. The transfer function of a step signal is $$\dfrac z{z-1}$$. It has a pole at $$z=1$$ and hence called unstable. </MESSAGE>
        <SUBJECT>Re: unstable poles of signal</SUBJECT>
        <MESSAGE> step and ramp signal.</MESSAGE>
        <SUBJECT>Re: unstable poles of signal</SUBJECT>
        <MESSAGE>I think unstable poles of the signal are the ones which cause the signal to rise without any bound.

Say z/z-3 is my input =&gt; in time domain it is 3^n, thus it increases unboundedly. That is what I interpret by unstable pole of a signal</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>pole zero cancellation of signal</SUBJECT>
        <MESSAGE>it is stated in the book that a pole zero cancellation between system and signal is allowed but not between two systems. As the poles of both system and signals are represented in the z domain in similar way how do you differentiate. for example how do you differntiate between the pole of a system at origin and a step input with pole at the origin. </MESSAGE>
        <SUBJECT>Re: pole zero cancellation of signal</SUBJECT>
        <MESSAGE>Suppose that you want to reject the effect of a step signal, which has a pole at $$z=1$$. It cannot be done unless you have a zero at this point.&lt;br /&gt;&lt;br /&gt;What I am saying is that we better know the signal &amp;quot;exactly&amp;quot;, as it is unstable. &lt;br /&gt;&lt;br /&gt;In other words, we do not yet know how to handle &amp;quot;unknown&amp;quot; and &amp;quot;unstable&amp;quot; type of signlals.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: pole zero cancellation of signal</SUBJECT>
        <MESSAGE>we have to design a system such that it can cancel the unstable pole of the signal. for this we must have perfect knowledge of the signal.</MESSAGE>
        <SUBJECT>Re: pole zero cancellation of signal</SUBJECT>
        <MESSAGE>If we look at the problem from the physical point of view a signal is an input to the system. The system acts on this input to provide output. Therefore pole zero cancellation of system and signal is allowed. But one system does not affect another system and therefore such pole zero cancellation cannot be done. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>pole-zero cancellation</SUBJECT>
        <MESSAGE>can we avoid the unstable pole-zero cancellation by incrementing either zero or pole. &lt;br /&gt;e.g.&#160; (z+1) to (z+1.1) or( z+.9)&lt;br /&gt;zero will nullify the effect of pole at some extend.&lt;br /&gt;
</MESSAGE>
        <SUBJECT>Re: pole-zero cancellation</SUBJECT>
        <MESSAGE>Cancellation of unstable pole-zero is not allowed while designing the controller. because system before pole-zero cancellation and after are not same.
Need not to increment or decrement the unstable pole or zero. We have to keep that pair as it is and consider it while designing. </MESSAGE>
        <SUBJECT>Re: pole-zero cancellation</SUBJECT>
        <MESSAGE>design of controller is our hand , we can made some change in pole -zero location without any change in require specification.&lt;br /&gt;&lt;br /&gt;
</MESSAGE>
        <SUBJECT>Re: pole-zero cancellation</SUBJECT>
        <MESSAGE>Thats what I want to say no need to change pole-zero location, consider that pair while designing controller instead look at the unstable pole of the signal and try to cancel it.</MESSAGE>
        <SUBJECT>Re: pole-zero cancellation</SUBJECT>
        <MESSAGE>there is no unstable pole cancellation but in your question z+.9 can be cancelled as it is a stable pole. </MESSAGE>
        <SUBJECT>Re: pole-zero cancellation</SUBJECT>
        <MESSAGE>unstable pole zero cancellation cannot be carried out. </MESSAGE>
        <SUBJECT>Re: pole-zero cancellation</SUBJECT>
        <MESSAGE>Let us consider the case of modifying z+1 as z+1.1. If you really wanted z+1 so as to cancel the pole/zero at the same location, how will modifying it as z+1.1 help? There are other ways to take care of this. We will discuss this in Chapter 9. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Unstable zero of the signal</SUBJECT>
        <MESSAGE>As discussed in slide 3 it is possible to cancel unstable pole of the signal by numerator of controller. Is it possible for unstable zero of the signal. Or unstable pole and unstable zero of the signal at different location?</MESSAGE>
        <SUBJECT>Re: Unstable zero of the signal</SUBJECT>
        <MESSAGE>Unstable pole-zero cancellation has to be avoided as far as possible. &lt;br /&gt;&lt;br /&gt;It may be unavoidable in case of unstable poles that come in external signal. We do not have to worry about the zeros of the signal that are outside the unit circle.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Unstable zero of the signal</SUBJECT>
        <MESSAGE>unstable pole zero cancellation should not be done </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>stable pole-zero cancellation</SUBJECT>
        <MESSAGE>Is it allowed to cancel stable pole-zero of plant and controller?</MESSAGE>
        <SUBJECT>Re: stable pole-zero cancellation</SUBJECT>
        <MESSAGE>Yes, you can cancel a stable pole-zero, it will result in an intermediate state which is either unobservable or uncontrollable, depending on how the blocks are placed. Now a stable pole which is unobservable/uncontrollable can do no harm as it would decay to zero. An unstable pole needs to be observable &lt;span style="font-weight: bold;"&gt;and&lt;/span&gt; controllable in order to stabilize the pole. &lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: stable pole-zero cancellation</SUBJECT>
        <MESSAGE>yes it is allowed infact that is the philosophy used for pole zero cancellation </MESSAGE>
        <SUBJECT>Re: stable pole-zero cancellation</SUBJECT>
        <MESSAGE>Yes this can be done as the effect of these two will cancels out.&lt;br /&gt;&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: stable pole-zero cancellation</SUBJECT>
        <MESSAGE>sometimes after cancellation output may look fine , but we can't guarantee the stability of internal state. they may blow up in between &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;
</MESSAGE>
        <SUBJECT>Re: stable pole-zero cancellation</SUBJECT>
        <MESSAGE>What Jagdish says is incorrect. Stable pole-zero cancellation will not create any difficulty, at least in the long run. As mentioned by others, the effect of cancellation of &amp;quot;approximately&amp;quot; equal factors will die out in the long run. We cannot make this statement in case of unstable pole-zero cancellation. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>unstable pole zero cancellation</SUBJECT>
        <MESSAGE>what is the condition  under which  unstable pole -Zero cancellation is permitted.</MESSAGE>
        <SUBJECT>Re: unstable pole zero cancellation</SUBJECT>
        <MESSAGE>while designing the controller always take care not to have unstable pole zero that of plant. but it is always possible to cancel unstable pole zero of the signal.</MESSAGE>
        <SUBJECT>Re: unstable pole zero cancellation</SUBJECT>
        <MESSAGE>unstable pole zero cancellation is not permitted . </MESSAGE>
        <SUBJECT>Re: unstable pole zero cancellation</SUBJECT>
        <MESSAGE>Cancellation of unstable pole zero states the system as stable and claims that for all input, all internal signals are bounded.However, this is not true. If there are any unstable poles, signal will become unbounded.&lt;br /&gt;So, pole-zero cancellation is not possible in any condition.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: unstable pole zero cancellation</SUBJECT>
        <MESSAGE>i think it is not at all possible.&lt;br /&gt;it arises the question of internal stability&lt;br /&gt;
</MESSAGE>
        <SUBJECT>Re: unstable pole zero cancellation</SUBJECT>
        <MESSAGE>If the input/disturbance signal and the controller have common unstable pole-zero as it is explained in the beginning of the video for tracking and regulation problem. But generally the system is designed as not have any unstable poles are zeros.&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>controller in Z^(-1)</SUBJECT>
        <MESSAGE>What is the reason that all controller algorithms are uses power of Z inverse?</MESSAGE>
        <SUBJECT>Re: controller in Z^(-1)</SUBJECT>
        <MESSAGE>This is because we always consider practical signals as causal systems, which have some time delay, and time delay in form of z^(-k). If we use z^(k) then it will become time advance and non causal.

</MESSAGE>
        <SUBJECT>Re: controller in Z^(-1)</SUBJECT>
        <MESSAGE>This is to do with causality. All controllers with $$Z^{-1}$$ are causal whereas powers of Z will result in a non-causal system(depending on future inputs). I am not sure if that is what you were asking?&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: controller in Z^(-1)</SUBJECT>
        <MESSAGE>because we need a causal system </MESSAGE>
        <SUBJECT>Re: controller in Z^(-1)</SUBJECT>
        <MESSAGE> The answers given by others are correct. In other words, an equation of the form &lt;br /&gt;&lt;br /&gt;u(n) = a(1)*y(n-1) + a(2)*y(n-2) + a(3)*y(n-3) &lt;br /&gt;&lt;br /&gt;can be implemented. If instead, the equation is in terms of future values, can't be implemented.&lt;br /&gt;&lt;br /&gt;We have the benefit of direct conversion of polynomials in $$z^{-1}$$ into time domain only in discrete time systems. This is not so obvious in continuous time systems, when we deal with Laplace Transforms.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: controller in Z^(-1)</SUBJECT>
        <MESSAGE>Z inverse signifies delay, which can be implemented, while Z to power positiveve powers signifies advancement which cannot be practically implemented. </MESSAGE>
        <SUBJECT>Re: controller in Z^(-1)</SUBJECT>
        <MESSAGE>because z&lt;sup&gt;-1&lt;/sup&gt; implies causality.
</MESSAGE>
        <SUBJECT>Re: controller in Z^(-1)</SUBJECT>
        <MESSAGE>because z&lt;sup&gt;-1&lt;/sup&gt; implies causality.
</MESSAGE>
        <SUBJECT>Re: controller in Z^(-1)</SUBJECT>
        <MESSAGE>Z^(-1) implies the system is causal as the causal system predicts only the past (not future). </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Comparison between BIBO and internal stability</SUBJECT>
        <MESSAGE>How can we compare between external stability and internal stability now ? While analyzing external stability don't we consider noise in the intermediate signals as we consider in case of internal stability? If so, then we are assuming that while finding BIBO stability of the system there is no noise disturbance in between then the system. &#160;

</MESSAGE>
        <SUBJECT>Re: Comparison between BIBO and internal stability</SUBJECT>
        <MESSAGE>What ever may be the conditions if for bounded input gives bounded output called as BIBO stability. But in the same case you may not get bounded output at each and every block that means no internal stability. 
</MESSAGE>
        <SUBJECT>Re: Comparison between BIBO and internal stability</SUBJECT>
        <MESSAGE>internal stability means the tf about any point in the system is stable. in BIBO the condition was stable bounded input would give stable bounded output and we would not bother about the internal system </MESSAGE>
        <SUBJECT>Re: Comparison between BIBO and internal stability</SUBJECT>
        <MESSAGE> The first UG control course deals only with external or BIBO stability. It does not worry about intermediate signals.&lt;br /&gt;&lt;br /&gt;If on the other hand, you do worry about the boundedness of internal signals, you are actually taking care of internal stability. It addresses the question at hand.&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>internal stability</SUBJECT>
        <MESSAGE>At the beginning of the lecture, we saw how pole zero cancellation helps in servo/regulation problem. But towards the end, we saw that pole zero cancellation can be messy. So, how is the pole zero cancellation in servo/regulation problem handled? </MESSAGE>
        <SUBJECT>Re: internal stability</SUBJECT>
        <MESSAGE>the pole zero cancellation taking place in the begining of the lecture is using the (LCM) value a which includes ar (ref unstable pole) and av (disturbance unstable pole) and it is pole zero cancellation of signals not between two systems which is the case at the end of lecture when things become messy </MESSAGE>
        <SUBJECT>Re: internal stability</SUBJECT>
        <MESSAGE> The pole zero cancellation in the beginning was between the controller and the signal either reference or disturbance using the least common multiple of unstable poles of the signal. Hence the servo/regulation problem is handled by canceling the unstable pole zero of signal and the controller. &lt;br /&gt;&lt;br /&gt;However the later one is between the unstable pole-zero of the controller and the plant which is dominated by the initial condition. In which we essentially ignoring the dynamics due to initial condition which are unbounded and hence unstable.&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Unstable pole cancellation in Internal Model Principal</SUBJECT>
        <MESSAGE>IMP uses cancellation  of unstable poles of controller with the the unstable poles of input signals.

But ultimately, these end up as zeros of closed loop transfer function. So why is the cancellation okay here?</MESSAGE>
        <SUBJECT>Re: Unstable pole cancellation in Internal Model Principal</SUBJECT>
        <MESSAGE>I have already answered this in another post on unstable pole-zero cancellation. </MESSAGE>
        <SUBJECT>Re: Unstable pole cancellation in Internal Model Principal</SUBJECT>
        <MESSAGE>cancellation of unstable poles of controller with unstable poles of input not understood </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Stability of signal</SUBJECT>
        <MESSAGE>The criteria for stable and unstable poles for systems is clearly defined, atleast in the case of BIBO stability. But how is the stability of a signal defined? </MESSAGE>
        <SUBJECT>Re: Stability of signal</SUBJECT>
        <MESSAGE>energy of signal should be finite.
</MESSAGE>
        <SUBJECT>Re: Stability of signal</SUBJECT>
        <MESSAGE>We only look for the stability of the system and the impact of the signals on the system stability. I don't think we define a stability of a signal as such.&lt;br /&gt;&lt;br /&gt; I am not sure whether i have understood your question properly. But this is how i could interpret. </MESSAGE>
        <SUBJECT>Re: Stability of signal</SUBJECT>
        <MESSAGE>I think step signal has finite energy. &lt;br /&gt;But it is still considered as unstable? </MESSAGE>
        <SUBJECT>Re: Stability of signal</SUBJECT>
        <MESSAGE>My question was that how do you define stability for a signal. When we stay signal has unstable poles what is its physical implication? </MESSAGE>
        <SUBJECT>Re: Stability of signal</SUBJECT>
        <MESSAGE>For any signal we have its z transform, so we can determine its unstable pole zero.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Pole zero cancelation </SUBJECT>
        <MESSAGE>Can u explain me what is its physical implication of the pole zero cancellation or is it only the mathematical manipulation. </MESSAGE>
        <SUBJECT>Re: Pole zero cancelation </SUBJECT>
        <MESSAGE>Poles and zeros come from difference equations, which in turn may come from differential equations. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>pole zero cancellation</SUBJECT>
        <MESSAGE>can you explain with example about the cancellation of unstable pole zero cancellation. </MESSAGE>
        <SUBJECT>Re: pole zero cancellation</SUBJECT>
        <MESSAGE>It is explained in the book.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Slide 14</SUBJECT>
        <MESSAGE>I have some calculation doubt in Slide 14 for x1(k)

U(z) = [ (z+2)/(z+0.5) ] * E(z)
=&amp;gt; (z+0.5)U(z) = (z+2)E(z)
Assuming x1(z) = U(z) - E(z)
=&amp;gt; (z+0.5)*(U(z)-E(z)) = 1.5E(z)
=&amp;gt; (z+0.5)*(x1(z)) = 1.5E(z)
=&amp;gt; x1(k) + 0.5x1(k+1) = 1.5E(k)

But, in slides, it is given as 
x1(k+1) + 0.5x1(k) = 1.5e(k)

Can you help me finding what mistake am I doing?</MESSAGE>
        <SUBJECT>Re: Slide 14</SUBJECT>
        <MESSAGE>Sorry, figured it out!</MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1407</ID>
    <LECTURE>07 Feb. 08 - Post your questions here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>selection of values of v</SUBJECT>
        <MESSAGE>V vector is given by [V0 V1 - Vv] when we take the value of (v=1)V vector should be [V0 V1] in the video lecture there was only one row of F ie [F0 F1 F2] when v=1 is assumed. the question is won't there be problem in vector multiplication unless v=1 means [V0]. </MESSAGE>
        <SUBJECT>Re: selection of values of v</SUBJECT>
        <MESSAGE>in F = [F0 F1 F2], F0,F1 and F2 are vectors. For v=1, see slide 19, each F0-F2 has two elements.&lt;br /&gt;I hope that is what you mean.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: selection of values of v</SUBJECT>
        <MESSAGE>One row of [$$F_0 \quad$$ $$F_1 \quad$$ $$F_2 \quad$$] refer to 2 rows of each F, [1, -5, 4] and [0 1 1], right?
In fact, that is the reason why we are able to multiply, right?
Sorry, I did not get your question clearly.</MESSAGE>
        <SUBJECT>Re: selection of values of v</SUBJECT>
        <MESSAGE>sir has said in the lecture that for v=1 mean only one term and not two,similarly for v=2 there are two terms and not three.</MESSAGE>
        <SUBJECT>Re: selection of values of v</SUBJECT>
        <MESSAGE>I also had same doubt. I assumed that v =1 means one column of vector V.If we consider this then problem is get solved.
</MESSAGE>
        <SUBJECT>Re: selection of values of v</SUBJECT>
        <MESSAGE>Yes true. Sir explained in the video v=1 means only one term. Watch at time 1:10:38. So v=1 is actually V0.</MESSAGE>
        <SUBJECT>Re: selection of values of v</SUBJECT>
        <MESSAGE> Sorry about this confusion. $$v=1$$ refers to one row, as suggested by others. This will also be clear from Example 7.12 on page 293. In view of this, should $$v$$ in Eq. 7.132 on page 292 of the textbood become $$v-1$$? </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>relation of del with decay</SUBJECT>
        <MESSAGE>sir,&lt;br /&gt;please explain how the decay becomes 1/4 when del is 0.5&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: relation of del with decay</SUBJECT>
        <MESSAGE>$$ \delta = 0.5 $$ implies the error amplitude reduced by 0.5 times by the time w changed from $$ \pi $$ to 2$$ \pi $$

So, the error amplitude reduced to $$ (1/4)^{th} \quad $$ of initial amplitude when it returned to the same "phase". That is what I interpreted as 1/4 decay. </MESSAGE>
        <SUBJECT>Re: relation of del with decay</SUBJECT>
        <MESSAGE>Decay rate is defined as ratio of two successive peak or trough .However in the slide 'delta'  is defined between peak and trough. Therefore you have to divide 'delta' by 2.That is how you get decay of 1/4 for 'delta'=0.5.</MESSAGE>
        <SUBJECT>Re: relation of del with decay</SUBJECT>
        <MESSAGE>Decay ratio is with respect to two consecutive overshoots or undershoots.For simplification we consider the half of the path i.e. consecutive undershoot and overshoot, such that we get w = pi and w = 2*pi. So value of decay ratio is always half of the del.</MESSAGE>
        <SUBJECT>Re: relation of del with decay</SUBJECT>
        <MESSAGE>The peak to peak decay rate is constant (ie., follow logarithmic) hence the decay ratio between the successive peak is half of the decay ration b/n peak and the undershoot. &lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: relation of del with decay</SUBJECT>
        <MESSAGE>The answers posted by others similar to what I had in mind while making this statement. </MESSAGE>
        <SUBJECT>Re: relation of del with decay</SUBJECT>
        <MESSAGE>Decay is defined for two consecutive cycles. del is defined for two adjacent peaks or valleys. Therefore Decay = del * del ( 0.25=0.5*0.5 ) </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Aryabhatta's Identity</SUBJECT>
        <MESSAGE>I did not understand few aspects of Aryabhatta's Identity :

1) What is the significance of checking the dependency of rows and removing the last row when we find the rows are dependent

2) What is the significance of those extra zeros obtained in the final solution for v (as seen in the last slide [1 3.25 | 0.75 -3 | &lt;b&gt; 0 0 &lt;/b&gt;]

3) What is the use of this identity in our control theory?</MESSAGE>
        <SUBJECT>Re: Aryabhatta's Identity</SUBJECT>
        <MESSAGE>1.To findout maximal v, such that all combinations of product terms of V*F are used.
2.For multiplication to exists rows of F should match with columns of V (for maximal value of v)</MESSAGE>
        <SUBJECT>Re: Aryabhatta's Identity</SUBJECT>
        <MESSAGE>I think it is used for pole-placement.I am not sure how exactly. </MESSAGE>
        <SUBJECT>Re: Aryabhatta's Identity</SUBJECT>
        <MESSAGE>if&#160; rows are linearly dependent then it's determinat is zero. hence we can't find inverse. it doesn't matter if we remove one of depend row </MESSAGE>
        <SUBJECT>Re: Aryabhatta's Identity</SUBJECT>
        <MESSAGE> Although infinitely many solutions exist to Eq. 7.119 in the textbook, we look for the minimal degree unique solution, as discussed on page 291. This minimal degree solution is obtained using the technique given pages 292-294.&lt;br /&gt;&lt;br /&gt;In the given example, the first five rows are independent. Once you add the sixth row, it becomes an independent set. This is the justification for the method.&lt;br /&gt;&lt;br /&gt;The answers given by others are ok for the last two questions.&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>desired region of w</SUBJECT>
        <MESSAGE>ref slide 6 figure for the desired region of w. shouldn't the undesired region (the region which is not shaded) be bounded between positive x-axis and w=(pie/2Nr). it is not clear for what values of w the undesired region would be negative. </MESSAGE>
        <SUBJECT>Re: desired region of w</SUBJECT>
        <MESSAGE>I think we have to consider the condition of       w&gt;(pie/2Nr) around the +ve x axis thats why the desired shape.</MESSAGE>
        <SUBJECT>Re: desired region of w</SUBJECT>
        <MESSAGE>The assumed cosine error function gives to two poles as in slide 4, which to me not clear directly but it is very clear when u transform to Z-domain. So i think by looking in the Z-domain it should give some idea. I am also not so sure. </MESSAGE>
        <SUBJECT>Re: desired region of w</SUBJECT>
        <MESSAGE>Amit, this happens because cos is an even function. Also recall that if any pole is complex, there should be a conjugate pair as well. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>overdamped system</SUBJECT>
        <MESSAGE>We consider e=row^n*coswn for the underdamped system but how to consider e for overdamped systems.</MESSAGE>
        <SUBJECT>Re: overdamped system</SUBJECT>
        <MESSAGE> I believe that if you take out the cos term, we would get the over-damped system. Put $$\rho = r^{n}$$ where $$r &amp;lt; 1$$. &lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: overdamped system</SUBJECT>
        <MESSAGE>What Prasanna says is correct. If we remove the cosine term, the oscillations will go away.&lt;br /&gt;&lt;br /&gt;We have considered only oscillatory inputs as we wanted to make use of concepts, such as rise time.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: overdamped system</SUBJECT>
        <MESSAGE>for overdamped system row may be greater than 1.we may or may not have oscillation&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: overdamped system</SUBJECT>
        <MESSAGE>e for overdamped system will not have the cosine term and also we select the remaining terms such that as n tends to infinity the error remains finite although it may be small </MESSAGE>
        <SUBJECT>Re: overdamped system</SUBJECT>
        <MESSAGE>As given in the book, for overdamped systems we define rise time as time taken for the response to go from 10% to 90% of the final value.
  Simillarly, error may be defined as the difference between the actual response and desired response after a certain threshold value of time or samples.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Defination of Fall time</SUBJECT>
        <MESSAGE>According to definition of fall time, it is the time taken to cover for the system to cover 10% to 90% of the value, but we are using e=0, this is understandable for underdamped systems. But what about overdamped systems, we cannot use e=0, we would never get a finite solution? How are such systems dealt with? </MESSAGE>
        <SUBJECT>Re: Defination of Fall time</SUBJECT>
        <MESSAGE>As mentioned in a previous post, I have not defined the rise time or fall time for overdamped systems. Presumably it will be something like 10% to 90% rise. We will make use of the definition of the underdamped system to design control systems. </MESSAGE>
        <SUBJECT>Re: Defination of Fall time</SUBJECT>
        <MESSAGE>I think in such cases we can assume e = delta, which is very small and tends to zero as n tends to infinity </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Condition for unique solution - Aryabhatta's Identity</SUBJECT>
        <MESSAGE>The necessary condition for a solution to exist is that the GCD of D and N should divide C
  But soon after,you mentioned that for a unique solution, D and N should be coprime.
 Doesnt this condition violate the above given necessary condition for a solution to exist?</MESSAGE>
        <SUBJECT>Re: Condition for unique solution - Aryabhatta's Identity</SUBJECT>
        <MESSAGE>Here we want GCD of D and N (not LCM)so even though they are co prime there exist GCD and so both the conditions are required and no violation occurs.  </MESSAGE>
        <SUBJECT>Re: Condition for unique solution - Aryabhatta's Identity</SUBJECT>
        <MESSAGE>If D and N are co prime their GCD will be 1 which divides C, therefore there is no violation </MESSAGE>
        <SUBJECT>Re: Condition for unique solution - Aryabhatta's Identity</SUBJECT>
        <MESSAGE>But GCD 1 is meaningless. All numbers have 1 as factor and so it wouldnt make sense to say that only if D and N divide C will a solution exist - because 1 will always be a factor.</MESSAGE>
        <SUBJECT>Re: Condition for unique solution - Aryabhatta's Identity</SUBJECT>
        <MESSAGE>how can coprime numbers have a GCD other than 1?
check this page: http://en.wikipedia.org/wiki/Coprime</MESSAGE>
        <SUBJECT>Re: Condition for unique solution - Aryabhatta's Identity</SUBJECT>
        <MESSAGE>For D and N to be coprime the C=1 ,whereas in other case C has non unity value  satisfying the relation

X(z)D(z)+Y(z)N(z)=C(z)</MESSAGE>
        <SUBJECT>Re: Condition for unique solution - Aryabhatta's Identity</SUBJECT>
        <MESSAGE>There is no inconsistency between the two statements. The GCD of D and N should divide C. Suppose that D and N have a common factor x. Then, C should have x as one of its factors. &lt;br /&gt;&lt;br /&gt;Equivalently, if D and N are coprime, they have a common factor of 1. But 1 will always divide C. Thus, we can find a solution to Aryabhatta's identity, without imposing any condition on C.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>undamped,critical damped</SUBJECT>
        <MESSAGE>sir, what analysis we had done in this lecture is only related to underdamped system. what if system is critically damped(no overshoot)or undamped(constant oscillation).&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: undamped,critical damped</SUBJECT>
        <MESSAGE>We have not defined everything parallel to a continuous time system. Only definitions required for subsequent use are created. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>D, N and C in Aryabhatta's identity</SUBJECT>
        <MESSAGE>In the examples given in the book we are directly given D, N and C. What do these polynomials represent with respect to the system? </MESSAGE>
        <SUBJECT>Re: D, N and C in Aryabhatta's identity</SUBJECT>
        <MESSAGE>N= represent the numerator of transfer function
D= denominator of transfer function
C= The GCD of numerator and denominator.</MESSAGE>
        <SUBJECT>Re: D, N and C in Aryabhatta's identity</SUBJECT>
        <MESSAGE>There are many examples of this in Chapter 9. For example, you may wish to see Equations 9.14 and 9.18. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Initial error</SUBJECT>
        <MESSAGE>What if the error doesn't starts from 1, i.e the initial conditions are non-zero?&lt;br /&gt;Will the expression for e(n) change in this case?&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Initial error</SUBJECT>
        <MESSAGE>In that case we can put a scake factor, say K, so the error equation will become 

 e(n) = K*(rho)^n*cos(wn)

</MESSAGE>
        <SUBJECT>Re: Initial error</SUBJECT>
        <MESSAGE>Why would you want to do this? Naturally, a nonzero e will make the situation more complicated.&lt;br /&gt;&lt;br /&gt;When we want to discuss what will happen to tracking of a step, would we not want to come to a steady state first and then try? I am doing the same thing.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Removing last row - Aryabhatta's Identity</SUBJECT>
        <MESSAGE>I'm not able to understand how we remove the last row only when the rows turn out to be linearly dependent. When we increase v from 2 to 3, the scriptF matrix gets two new rows i.e. those two rows belong together. So how can we just remove one row. Should we not remove both? 
  
Mathematically im able to understand that its being done to remove the singularity, so that we can take its inverse. But im not able to understand how it solves the equation. Because, when we remove only one row, we remove only the coefficients of N(z), while retaining the coefficients of D(z). 
</MESSAGE>
        <SUBJECT>Re: Removing last row - Aryabhatta's Identity</SUBJECT>
        <MESSAGE>If you remove both, the answer will not be correct - you would have missed out important information - see the discussion on top of the page 295. &lt;br /&gt;&lt;br /&gt;While solving Eq. 7.134, we do not worry about from where script C and script F come. We need to keep the maximal independent rows and work with them. In this case, there are 5.&lt;br /&gt; </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1415</ID>
    <LECTURE>10 Feb. 09 - Post your questions here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>Sampling Time</SUBJECT>
        <MESSAGE>While finding ZOH equivalence of the system response and later converting into discrete time, we introduce $$ T_s $$ So the resulting discrete time transfer function depends on $$ T_s $$. For example in slide 6, we have $$G(z) = \dfrac {T_s}{(z-1)} $$ So, when a step input is given to a transfer function, the output depends on $$ T_s $$. But, this is invalid, right? </MESSAGE>
        <SUBJECT>Re: Sampling Time</SUBJECT>
        <MESSAGE>Ts is the approximation its a constant,we can say that G(Z) is Ts times one over z minus one.</MESSAGE>
        <SUBJECT>Re: Sampling Time</SUBJECT>
        <MESSAGE>If you see the slide 6, you will just see that, $$y_s(nT_s) = nT_s $$
It is true for what ever sampling time we take. And taking its Z transform, gives us $$ Y_s(z) = \dfrac {T_sz}{(z-1)^2} $$ and thus, the transfer function becomes $$ \dfrac{T_s}{(z-1)} $$
We never took $$ T_s $$ constant anywhere, right?
So, the output should vary with $$ T_s $$ , which is not correct, right?</MESSAGE>
        <SUBJECT>Re: Sampling Time</SUBJECT>
        <MESSAGE>But selection of sampling time is in our hand.</MESSAGE>
        <SUBJECT>Re: Sampling Time</SUBJECT>
        <MESSAGE>What I mean to say is just by changing my sampling time, how is the output changing?</MESSAGE>
        <SUBJECT>Re: Sampling Time</SUBJECT>
        <MESSAGE> i think it is ZOH eqvivalent of a plant with tf 1/s in s domain and we are trying to approximate it in discrete time domain.we can select a sampling time but once selected it cannot change.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Sampling Time</SUBJECT>
        <MESSAGE>It is not invalid. Ts affects the output</MESSAGE>
        <SUBJECT>Re: Sampling Time</SUBJECT>
        <MESSAGE> The answer that I gave earlier (both in wiki and also in the class) regarding scale factor is not relevant to this question.&lt;br /&gt;&lt;br /&gt;The fact that the output is a function of time is brought out by Ts. This can be checked by substituting with real numbers.&lt;br /&gt;&lt;br /&gt;We choose a Ts at the beginning of discretisation. After that, it can be treated as constant.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>(Z-1) term in Integral and Derivative mode</SUBJECT>
        <MESSAGE>For derivative mode we dont want (Z+1) term in denominator but what about (z-1) term in both Integral and Derivative mode?</MESSAGE>
        <SUBJECT>Re: (Z-1) term in Integral and Derivative mode</SUBJECT>
        <MESSAGE>Yes, pole at z=1 is fine, but at z=-1 is not ok. It is because, the latter results in wild oscillations. </MESSAGE>
        <SUBJECT>Re: (Z-1) term in Integral and Derivative mode</SUBJECT>
        <MESSAGE>i have the same doubt because in previous classes we said that z=1 we will not consider unstable in fact it is marginally stable and we know that stable system all poles lie in the unit circle </MESSAGE>
        <SUBJECT>Re: (Z-1) term in Integral and Derivative mode</SUBJECT>
        <MESSAGE>(z-1) appears in both but we are only concerned with its appearance in the denominator. only in integral mode it appears in denominator.

(z-1) &lt;-&gt;  (1)^n  which is not oscillating and so its ok to have it in the denominator. Having (z+1) will lead to large oscillations as (z+1) &lt;-&gt;  (-1)^n</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>ZOH equivalent and Discrete Integration</SUBJECT>
        <MESSAGE>From slide 6 and 14 we can see that we get the same transfer function for 1/s.&lt;br /&gt;The diagram in slide 10 indicates 1st order hold.&lt;br /&gt;Does this mean that ZOH and 1st order hold forward difference are the same?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: ZOH equivalent and Discrete Integration</SUBJECT>
        <MESSAGE>They turn out to be the same for 1/s. This need not happen for other transfer functions. For example, calculate the forward difference approximation for the transfer function in Slide 8. </MESSAGE>
        <SUBJECT>Re: ZOH equivalent and Discrete Integration</SUBJECT>
        <MESSAGE>no ZOH and 1st order hold are not same in first order the polynomial is of order greater than zero and thus the difference equation also would be different when compared to ZOH which is an approximation using polynomial of order zero </MESSAGE>
        <SUBJECT>Re: ZOH equivalent and Discrete Integration</SUBJECT>
        <MESSAGE>In slide 14 we tried to discretizing the Integration by different approximations (Trapezoidal rule, backward difference or forward difference etc.) Its not a first order hold.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Page 305, example 8.5</SUBJECT>
        <MESSAGE> How does multiplication by $$ z^-^1 $$ account for $$ e^-^(^T^s^)^s $$ ? </MESSAGE>
        <SUBJECT>Re: Page 305, example 8.5</SUBJECT>
        <MESSAGE>i think the ans lies in the fact that z=e^sh which is a way to map s into z. </MESSAGE>
        <SUBJECT>Re: Page 305, example 8.5</SUBJECT>
        <MESSAGE>Taking inverse Z transform $$ z^{-1}*y(z) $$, we get     $$ y( n )= Z^{-1}(z^{-1}*y(z)) = y'(n-1) $$ (where y' is the output when $$ z^{-1} $$ is not multiplied) , which implies the output is delayed by 1 time sample.

Similarly, in continuous domain, multiplying $$ e^{-(T_s)s} $$ to the transfer function and taking the inverse laplace transform of the output shows us a shift of $$T_s$$ units which can be interpreted as a delay of $$ T_s $$ units, and hence forth they both are equivalent</MESSAGE>
        <SUBJECT>Re: Page 305, example 8.5</SUBJECT>
        <MESSAGE>To simplify the problem we inserted additional term of  e^(Ts)so we have to pulled it out. Ts is sampling time to remove the delay of one sampling time we multiply it by z inverse.</MESSAGE>
        <SUBJECT>Re: Page 305, example 8.5</SUBJECT>
        <MESSAGE>Swaroop's answer seems to be pretty good. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>approximating controllers</SUBJECT>
        <MESSAGE>forward difference, backward difference and tustin's approximation all use the fact that the controller is given in continuous time domain. what difference it makes if i take the continuous time output and discretise it instead of discretising at the controller. </MESSAGE>
        <SUBJECT>Re: approximating controllers</SUBJECT>
        <MESSAGE>The first one would imply that you work in the continuous time domain. That is, you do all the calculations in the continuous time and finally, at the time of implementation, discretise.&lt;br /&gt;&lt;br /&gt;The second option suggests that you work in the discrete time domain, which is the approach we have taken in this course.&lt;br /&gt;&lt;br /&gt;As I mentioned earlier, there are pros and cons for each approach.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: approximating controllers</SUBJECT>
        <MESSAGE>Mathematicaly it is ok but to implement electronic controller we need to sample the input i.e. discretize it so we need to implement discrete controller.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>triangular approximation</SUBJECT>
        <MESSAGE>what is triangular approximation is it different from trapezoidal approximation </MESSAGE>
        <SUBJECT>Re: triangular approximation</SUBJECT>
        <MESSAGE>First order hold equivalent is often called triangular approximation. For example, see http://web.cecs.pdx.edu/~tymerski/ece452/6.pdf&lt;br /&gt;&lt;br /&gt;Ramp response equivalent turns out to be the same as first order hold equivalent.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: triangular approximation</SUBJECT>
        <MESSAGE>In trapezoidal approx. we try to fit given area under the curve as trapezoid so we use the formula as Area = Height(Base1+Base2)/2
 and in triangular approx. we try to fit given area as triangle and use Area = (Base * height)/2</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>pole at z=-1</SUBJECT>
        <MESSAGE>it is not clear as to how the pole at z=-1 produces oscilations. won't the pole at z=1 would also produce sustained oscillation after in all tustin's approx stable continuous-time sys are transformed into stable sampled systems. </MESSAGE>
        <SUBJECT>Re: pole at z=-1</SUBJECT>
        <MESSAGE> Recall that the time domain response of $$\frac z{z-a}$$ is $$a^n$$. So, for $$a=1$$, the response is $$1^n=1$$. For $$a=-1$$, the response is $$(-1)^n$$, which is wildly oscillatory. The two are not the same. </MESSAGE>
        <SUBJECT>Re: pole at z=-1</SUBJECT>
        <MESSAGE>(-1)^n has +ve values for even n and-ve values for odd n.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>implementation of fwd difference controller</SUBJECT>
        <MESSAGE>it is not understood why the fwd difference integral controller cannot be implemented </MESSAGE>
        <SUBJECT>Re: implementation of fwd difference controller</SUBJECT>
        <MESSAGE>Sorry, this question is not clear. Did I make this statement anywhere? </MESSAGE>
        <SUBJECT>Re: implementation of fwd difference controller</SUBJECT>
        <MESSAGE>fwd difference integral controller is not a problem  the problem is with fwd difference derivative controller such that output requires future values of the input which is not realizable.</MESSAGE>
        <SUBJECT>Re: implementation of fwd difference controller</SUBJECT>
        <MESSAGE>Yes, forward difference approximation to derivative mode will give $$z-1$$, which involves prediction and hence cannot be implemented. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 30 error constant</SUBJECT>
        <MESSAGE>in slide 30 are we considering velocity error constant </MESSAGE>
        <SUBJECT>Re: slide 30 error constant</SUBJECT>
        <MESSAGE>No, it is position error constant. Recall that the position, velocity and acceleration error constants are obtained respectively by step, ramp and parabola. It is position as we have step input here. </MESSAGE>
        <SUBJECT>Re: slide 30 error constant</SUBJECT>
        <MESSAGE>Kv is consider for ramp input here we used final value theorem.but if we consider backward difference formula for s to z it seems to be like formula for Kv.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>derivative term in feedback</SUBJECT>
        <MESSAGE>sir u told derivative term in simple PID may amplify noise. then why to go for derivative in feedback loop in 2-DOF. &lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: derivative term in feedback</SUBJECT>
        <MESSAGE>in feedback the output signal is used which is already of high power and the derivative tf has high power signal as input and low power as output so we donot need amplification but in feed forward it is other way round and thus we need amplification </MESSAGE>
        <SUBJECT>Re: derivative term in feedback</SUBJECT>
        <MESSAGE>derivative mode decreases oscillations and improve stability also to reject disturbance we keep Sc/Rc in feedback. To reduce the effect of noise we use filtered derivative with N.</MESSAGE>
        <SUBJECT>Re: derivative term in feedback</SUBJECT>
        <MESSAGE>&#160;but my question is why to use pure derivative in feedback loop (in 2-DOF)when it will amplify the noise..
</MESSAGE>
        <SUBJECT>Re: derivative term in feedback</SUBJECT>
        <MESSAGE>What Prafulla says is quite close. Even though derivative mode amplifies noise, we would like to use it in order to reduce the oscillations and to increase the stability. In order to minimise the effects of noise, we filter out the noise first and then apply the derivative action. </MESSAGE>
        <SUBJECT>Re: derivative term in feedback</SUBJECT>
        <MESSAGE>We some times need rate of change of that particular quantity and when you don't have the sensor to measure the rate directly, we would need a Derivative in feedback path.

For example, if a satellite is tracking some pitch angle, in some particular cases, we would need pitch rate of the satellite. This is usually obtained by gyro feedback, but if the gyros have lots of bias, then we would implement the derivative in feedback instead of taking gyro output.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>condition for offset free tracking with itegral</SUBJECT>
        <MESSAGE>Sir i could not understand the last two condition for offset free tracking.
1   Tc = Sc(1)
2   Tc(1)=Sc(1)</MESSAGE>
        <SUBJECT>Re: condition for offset free tracking with itegral</SUBJECT>
        <MESSAGE> Tc equals Sc only at z equals one. </MESSAGE>
        <SUBJECT>Re: condition for offset free tracking with itegral</SUBJECT>
        <MESSAGE>Even I could not understand the implication of 1st condition. Is it that Tc is constant all the time?</MESSAGE>
        <SUBJECT>Re: condition for offset free tracking with itegral</SUBJECT>
        <MESSAGE>means at steady state Tc = Sc </MESSAGE>
        <SUBJECT>Re: condition for offset free tracking with itegral</SUBJECT>
        <MESSAGE> Yes, Tc=Sc(1) means that Tc is a constant and is equal to the steady state value of Sc. The second condition means that the steady state values of the two expressions are equal.&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>discrete TF of PID </SUBJECT>
        <MESSAGE>To get discrete TF of PID i.e. Gc(Z) can we substitute for s in Gc(s) using the value obtained by backward difference formula?</MESSAGE>
        <SUBJECT>Re: discrete TF of PID </SUBJECT>
        <MESSAGE>i think no. because pid parameters are different for different tf. while converting from conti. to discrete we made some approximation. &amp;amp; also we need to compensate the tf in discrete .
</MESSAGE>
        <SUBJECT>Re: discrete TF of PID </SUBJECT>
        <MESSAGE>i think we convert it to time domain first then substitute t=Tsn. </MESSAGE>
        <SUBJECT>Re: discrete TF of PID </SUBJECT>
        <MESSAGE>Yes, you may substitute. In all of the area based approximations, one directly substitutes one of the three formulae. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>mapping of pole zero</SUBJECT>
        <MESSAGE>can we directly map pole/zero of continuous tf to&#160; pole/zero of discrete tf
</MESSAGE>
        <SUBJECT>Re: mapping of pole zero</SUBJECT>
        <MESSAGE>Yes, it is possible. This is covered in the conventional discrete time control books. The following link also gives this information: http://web.cecs.pdx.edu/~tymerski/ece452/6.pdf </MESSAGE>
        <SUBJECT>Re: mapping of pole zero</SUBJECT>
        <MESSAGE>yes by substituting z=e^sh where h is arbitrary </MESSAGE>
        <SUBJECT>Re: mapping of pole zero</SUBJECT>
        <MESSAGE>Yes, we can directly map pole/zero of continuous tf to pole/zero of discrete tf. there are various methods for it.&lt;br /&gt;ex: Impulse invariance method: z=e^(s*T) where T is sampling time&lt;br /&gt;&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Value of N?</SUBJECT>
        <MESSAGE>By whom the value of N is given i.e designer or end user? And what is the criteria for deciding larger value of N in&#160; PID controller ?&lt;br /&gt;
</MESSAGE>
        <SUBJECT>Re: Value of N?</SUBJECT>
        <MESSAGE>The end user does not give N. It is generally given by the designer. Some times, the choice of N is mandated by the organisations as their local guideline. </MESSAGE>
        <SUBJECT>Re: Value of N?</SUBJECT>
        <MESSAGE>The value of N is chosen large enough so as to nullify the effect of adding that extra pole to the system, but adding this pole helps us in limiting the cut-off frequency of the low pass filter which is what exactly we are using in the transfer function block

$$ \dfrac {\tau_ds}{1+(\tau_ds/N)} = (\tau_d*s)* \dfrac {1}{1 + (\tau_ds/N)} $$

The second half of the equation on RHS is nothing but the transfer function of low pass filter whose cut off frequency is proportional to N.

Larger the N, larger is the cut off frequency, but smaller it is, the larger is the effect of adding that extra pole on the system dynamics. Thus there is a trade off.

Here, if there was some noise, due to its differentiation, the noise gets amplified, once this is sent through the low pass filter, this gets de - amplified. That is why we are choosing this extra term in PID controller

As far as I know, choice of N is left to the designer.</MESSAGE>
        <SUBJECT>Re: Value of N?</SUBJECT>
        <MESSAGE>the value of N would be chosen by the designer </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Instability due to large gain - PID</SUBJECT>
        <MESSAGE>While discussing tuning of PID controller you mentioned that increasing the gain will cause instability. The system will become very sensitive to input but I am not able to understand why it will become unstable
   Also, if the input is bounded, shouldnt the output be necissarily bounded from BIBO stability condition?</MESSAGE>
        <SUBJECT>Re: Instability due to large gain - PID</SUBJECT>
        <MESSAGE> In continuous time systems, there are systems that are stable for all positive gains. For example, the system $$G(s)=\dfrac 1{s+1}$$ is stable for all $$K&amp;gt;0$$ - the root locus goes to $$-\infty$$ in LHP. The pole lies in LHP, it is always stable.&lt;br /&gt;&lt;br /&gt;The situation is quite different in discrete time systems. For a large enough $$K$$, the root locus plot of an open loop stable system, such as $$G(z)=\dfrac 1{z-0.5}$$ necessarily leaves the unit circle, making the system unstable.&lt;br /&gt;&lt;br /&gt;I am confused by the last statement of yours. If the closed loop system is BIBO stable the output will be bounded. Otherwise, the output will not be bounded.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Instability due to large gain - PID</SUBJECT>
        <MESSAGE>Say we are just using a proportional controller.
$$ u( n ) = K*e_k( n ) $$
Physically, it can be interpreted as the large correction that you are giving to the system by amplifying the $$ e_k $$ and thus, after some value of gain, the correction is so large the input to the plant keeps increasing and at some point of time goes, without bound.

In other words, you can take as, suppose you are tracking a step signal, due to increase in K, the oscillations and their amplitude increases, and thus, error also increases. As time passes, this $$ u_k $$ goes so high that the system is no longer stable.

Although the input signal to (system + controller) is stable, input to the plant jumps up, thus making the system unstable. </MESSAGE>
        <SUBJECT>Re: Instability due to large gain - PID</SUBJECT>
        <MESSAGE> this is the principle on which root locus is based as proportional gain increases you will see root locus going from LHS to RHS ie why we say that for some value of K the sys will become unstable however exception are there when the locus remain on RHS in that the system will not become unstable irrespective of the increase in gain&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>integral mode vs derivative mode</SUBJECT>
        <MESSAGE>How is it that we are able to find z-transform of $$\frac{1}{s}$$ but not for $$s$$. Essentially I am asking, how do we decide whether to use TUSTIN's approximation or not? </MESSAGE>
        <SUBJECT>Re: integral mode vs derivative mode</SUBJECT>
        <MESSAGE>As I mentioned in the video, there is no theory to suggest which approximation is the best. Given this suggestion, the rule of thumb is to not accept any approximation that leads to difficulty. In this case, as Tustin's approximation leads to unacceptable oscillations, we avoid it. &lt;br /&gt;&lt;br /&gt;The guideline &amp;quot;Not to use Tustin's approximation for derivative mode&amp;quot; seems to be a correct one. I am not sure whether we have such guidelines for other situations and other approximations.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: integral mode vs derivative mode</SUBJECT>
        <MESSAGE>Exact derivative can not be implemented in the discrete domain, approximation by trapezoidal formula will lead to unstable pole thats why we try to avoid it and go for backward difference formula.</MESSAGE>
        <SUBJECT>Re: integral mode vs derivative mode</SUBJECT>
        <MESSAGE>if using integrator then tustin's approx and if using derivative then backward diff approx </MESSAGE>
        <SUBJECT>Re: integral mode vs derivative mode</SUBJECT>
        <MESSAGE>Physically, what I interpret is - 
We have seen step response of integrator $$ 1/s$$ and $$ 1/s^2 $$ and so on. But in the case of derivative, step response doesn't hold good as we always get the output to be zero, for it being a constant signal.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Integral Windup</SUBJECT>
        <MESSAGE>will controller in digital mode also have similar problems as in contimous mode, viz integral windup, offset or even hysteresis in some cases?</MESSAGE>
        <SUBJECT>Re: Integral Windup</SUBJECT>
        <MESSAGE>Yes, all these problems are there. We will discuss both offset and integral windup in this course. </MESSAGE>
        <SUBJECT>Re: Integral Windup</SUBJECT>
        <MESSAGE>checking ans&lt;br /&gt;&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Ziegler Nichols Tuning method</SUBJECT>
        <MESSAGE>sir will u explain in frequency response test on the system,it is necessary to determine all the model parameters to apply Z-N tuning. </MESSAGE>
        <SUBJECT>Re: Ziegler Nichols Tuning method</SUBJECT>
        <MESSAGE>I do not understand your question. Basically, Ziegler-Nichols reaction curve method is supposed to be experimental. You do not need a model of the system to carry this experiment out or to arrive at tuning parameters.&lt;br /&gt;&lt;br /&gt;Is this what you mean by frequency response? &lt;br /&gt;&lt;br /&gt;I don't see any connection between frequency response and Ziegler-Nichols tuning.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Ziegler Nichols Tuning method</SUBJECT>
        <MESSAGE>No, we dont need any model parameters for Z-N, we just give step input and check o/p. </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1419</ID>
    <LECTURE>14 Feb. 10 - Post your questions here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>setpoint kick</SUBJECT>
        <MESSAGE>sir will you please explain difference between all three types of kicks. &lt;br /&gt;is it true that, proportional kick + derivative kick implies setpoint kick.&lt;br /&gt;because&#160; proportional &amp;amp; derivative term will generate the control signal only when there is change in reference or disturbance occur.&lt;br /&gt;&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: setpoint kick</SUBJECT>
        <MESSAGE>Setpoint kick is a generic term. It includes two types of kicks: proportional kick and derivative kick. As the name &amp;quot;setpoint&amp;quot; implies that this deals with only sudden changes in the reference signal. </MESSAGE>
        <SUBJECT>Re: setpoint kick</SUBJECT>
        <MESSAGE>yes it true that, proportional kick + derivative kick implies setpoint kick.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Derivative to lead</SUBJECT>
        <MESSAGE>In page 308, it is mentioned that derivative cannot be implemented and therefore it is converted to lead term. Why is it so? </MESSAGE>
        <SUBJECT>Re: Derivative to lead</SUBJECT>
        <MESSAGE>How will you implement $$G(s)=1+s$$? </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Bumpless transfer</SUBJECT>
        <MESSAGE>Sir, could u please explain how the discrete formulation of PID helps in bump less transfer from manual to auto mode&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Bumpless transfer</SUBJECT>
        <MESSAGE> Not the discrete form, but the difference form. In this, the controller calculates $$\Delta u(k)$$ and passes on this value to the end control element. What is implemented is the &amp;quot;old value&amp;quot; + $$\Delta u(k)$$. Thus, only the relative value $$\Delta u(k)$$ is passed. This can work well even if there is any confusion about the &amp;quot;old value&amp;quot;! This &amp;quot;confusion&amp;quot; or &amp;quot;mismatch&amp;quot; in values can occur if there is any communication gap between the device that actually &amp;quot;implements&amp;quot; the control law and the algorithm that &amp;quot;calculates&amp;quot; the control law.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Bumpless transfer</SUBJECT>
        <MESSAGE>Its not a discrete formulation it is based on difference of current and previous such that while change over from auto to manual controller knows both the conditions i.e. in auto as well as manual, so the transfer is bumpless.   </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Use of filter</SUBJECT>
        <MESSAGE>What is the reason that it is difficult to implement PID controller in its usual form? Why do we need to use a filter? </MESSAGE>
        <SUBJECT>Re: Use of filter</SUBJECT>
        <MESSAGE>The answer is same as the one I gave for another question. Please tell me how you will implement, without ANY approximation, a controller of the form $$G(s)=1+2s$$? </MESSAGE>
        <SUBJECT>Re: Use of filter</SUBJECT>
        <MESSAGE>D part in PID causes amplification of noise , so we use derivative along with filter. another reason is that PI-D and I-PD structures are practically better and easier to implement, without increasing the overall design effort.
</MESSAGE>
        <SUBJECT>Re: Use of filter</SUBJECT>
        <MESSAGE> If we do not use filter a noise is get introduced at higher frequencies. So to limit the noise we introduce a filter in derivative term such that at higher frequencies derivative term becomes a constant i.e. N.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Integral and derivative approximation</SUBJECT>
        <MESSAGE>Its not clear how one can use bilinear approximation for 1/s(Integral term) and backward difference approximation for s (derivative term ) in the same equation.</MESSAGE>
        <SUBJECT>Re: Integral and derivative approximation</SUBJECT>
        <MESSAGE>Why not? These are all approximations. Such variations are widely used in industry successfully. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Problem with unstable zero</SUBJECT>
        <MESSAGE>How can an unstable zero affect the system? </MESSAGE>
        <SUBJECT>Re: Problem with unstable zero</SUBJECT>
        <MESSAGE>Essentially, these zeros may not be changed. As a result, you cannot change the performance of the closed loop &amp;quot;arbitrarily&amp;quot;. It will become clear when we discuss pole placement. </MESSAGE>
        <SUBJECT>Re: Problem with unstable zero</SUBJECT>
        <MESSAGE>If we take a feedback and calculate a loop TF the unstable zeros of the original TF are present in the loop TF.So even in feedback original TF zeros can not be eliminated.</MESSAGE>
        <SUBJECT>Re: Problem with unstable zero</SUBJECT>
        <MESSAGE>I think there is some damping that these zeros bring into the system</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Bumpless control law</SUBJECT>
        <MESSAGE>Sir, can you please explain what is bumpless control law physically mean? What is the meaning of - ''a plant is experiencing a bump'' when there is mismatch in control levels at previous and current time instants?&#160;

</MESSAGE>
        <SUBJECT>Re: Bumpless control law</SUBJECT>
        <MESSAGE>I gave the following answer to Amit's question:&lt;br /&gt;&lt;br /&gt;
&lt;div class="posting"&gt; Not the discrete form, but the difference form. In this, the controller calculates $$\Delta u(k)$$ and passes on this value to the end control element. What is implemented is the &amp;quot;old value&amp;quot; + $$\Delta u(k)$$. Thus, only the relative value $$\Delta u(k)$$ is passed. This can work well even if there is any confusion about the &amp;quot;old value&amp;quot;! This &amp;quot;confusion&amp;quot; or &amp;quot;mismatch&amp;quot; in values can occur if there is any communication gap between the device that actually &amp;quot;implements&amp;quot; the control law and the algorithm that &amp;quot;calculates&amp;quot; the control law.&lt;br /&gt; &lt;/div&gt;&lt;br /&gt;So physically, it means that there could be a mismatch between the actual $$u(k-1)$$ i.e. old, value and what the controller thinks it is.&lt;br /&gt;&lt;br /&gt;If I am not mistaken, I have given an example with numbers in the video. Have you seen the video?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Bumpless control law</SUBJECT>
        <MESSAGE>When changing a controller from manual to auto or auto to manual, if controller does not remember the output in previous mode sudden bump (step change)is observed in the controller output to avoid this we design a control law such that previous output is also considered while changeover from auto to manual or wise versa. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Effect of Numerator on the design</SUBJECT>
        <MESSAGE> In the procedure followed in the lecture, I did not understand why we were not getting rise time&amp;gt;0.15 sec when it was designed for 0.15 sec. I mean, I did not understand the explanation given regarding the numerator zeros. Can you please explain it a bit more clearer?&lt;br /&gt;&lt;br /&gt;Did it mean we taking T = 1 is not a correct thing to do?&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;By the way, why does ZOH have a delay of an extra 0.5 sample? I mean why only 0.5 why not more than that / less than that?&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>delay in the simulation</SUBJECT>
        <MESSAGE>I could not understand how delay shows up in the simulation. Is it the negative part of the input, the not being able to satisfy the rise time condition, none of them or both ? </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 20</SUBJECT>
        <MESSAGE>sir in slide 2o its says that bumpless property is lost on introduction in filtering action is their any chance to retrive this control action again.&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>value of N in slide 8</SUBJECT>
        <MESSAGE>&lt;div style="text-align: left;"&gt;Sir, you said that N is a large number, of the order of 100,but for different systems how to decide value of N or it just trial and error? &lt;/div&gt;</MESSAGE>
        <SUBJECT>Re: value of N in slide 8</SUBJECT>
        <MESSAGE>Settling time divided by the sampling time will be a good estimate. </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1423</ID>
    <LECTURE>17 Feb. 11 - Post your questions here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>Suitable value of T1</SUBJECT>
        <MESSAGE>What are the suitable values of T1 other than one such that still it is 2 DOF controller? </MESSAGE>
        <SUBJECT>Re: Suitable value of T1</SUBJECT>
        <MESSAGE>any value other than S1, also in 2DOF we talked of having the derivative in the feedback path and integral in the feedforward path so i think that could also be the reason for prefering 1 as a value of T1 </MESSAGE>
        <SUBJECT>Re: Suitable value of T1</SUBJECT>
        <MESSAGE>It is possibly to modify T1 so as to follow different reference signals also, although we have tracked only step changes.&lt;br /&gt;&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>non minimum phase system</SUBJECT>
        <MESSAGE>why a system with zero outside the unit circle is called non min phase, infact what is meant by min phase. </MESSAGE>
        <SUBJECT>Re: non minimum phase system</SUBJECT>
        <MESSAGE>min phase systems are the ones in which the zero is stable ie they lie on the left side of s-plane and inside the unit circle in z-plane.they are called min phase because in bode plot they give min phase in the phase vs freq plot. </MESSAGE>
        <SUBJECT>Re: non minimum phase system</SUBJECT>
        <MESSAGE> The minimum phase system has its energy concentrated near the start of the impulse response. </MESSAGE>
        <SUBJECT>Re: non minimum phase system</SUBJECT>
        <MESSAGE>This answer is ok. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>control effort</SUBJECT>
        <MESSAGE>the controller designed is a two dof controler how do we see the control effort in the controller ie how do we get the graph of control effort. </MESSAGE>
        <SUBJECT>Re: control effort</SUBJECT>
        <MESSAGE>i think that it could be the step response of the controller minus the plant </MESSAGE>
        <SUBJECT>Re: control effort</SUBJECT>
        <MESSAGE> Find the transfer function between the control effort u and the reference signal r. Plot this as a function of n. &lt;br /&gt;&lt;br /&gt;In live simulations, plot u, as it is calculated, as a function of n.&lt;br /&gt;&lt;br /&gt;Possibly you want to know what u is, as there are two components. The answer is the following: take u to be the input to the plant. It is the sum of two terms: one in the forward path and the other in the reverse path.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: control effort</SUBJECT>
        <MESSAGE> feed back path rejects disturbance and feed forward path track the reference signal. &lt;br /&gt;To get a graph we have to consider TF between R and U and also between Y and U.&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>delay due to zoh</SUBJECT>
        <MESSAGE>it is not understood as to what delay we are referring to when we say that the rise time specification is not met. also when we change w and row how is this problem addressed </MESSAGE>
        <SUBJECT>Re: delay due to zoh</SUBJECT>
        <MESSAGE>in the first controller the rise time specification of 0.15sec is not met. there are no of reasons given in the video lecture. bad zero is one of them. also some time delay occurs when zoh is executed because the zoh holds the last value for some time till fresh value arrives. this delay is approx half sampling time. when we increase w and decrease row then the system becomes faster and we get a sharp controller </MESSAGE>
        <SUBJECT>Re: delay due to zoh</SUBJECT>
        <MESSAGE>In the second control design (i.e. rise time = 10), the pole is closer to the origin and hence the error goes to zero faster. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Effect of Delay on response</SUBJECT>
        <MESSAGE>Sir, I could not understand the effect of delay on response. Does it show up as the negative part of the input or as the not matching of the rise time or contributes to both and how ?&lt;br /&gt;&lt;br /&gt;Recalling : In the case of controller design/ system modeling, due to delay we need to remember extra(past) information. </MESSAGE>
        <SUBJECT>Re: Effect of Delay on response</SUBJECT>
        <MESSAGE> The answer to this question lies in equation 9.7 on page 330. Please note that the delay part of the plant is not a part of these calculations. &lt;br /&gt;&lt;br /&gt;So, in Example 9.3 on page 331, our first design should help produce a rise in 15+1=16 samples. Unfortunately, however, we see that it is about 22+. This discrepancy between 16 and 22+ is because of (i) bad zeros, and (ii) not getting the error transfer function equal to the Z-transform of $$\rho^n \cos{\omega n}$$.&lt;br /&gt;&lt;br /&gt;In view of the above, I have not even bothered to talk about the delay term of 1. In problems with longer delays, we will have to consider it.&lt;br /&gt;&lt;br /&gt;The initial negative response is due to nonminimum phase response.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Effect of Delay on response</SUBJECT>
        <MESSAGE>i think the effect of delay on response would make starting of the input more positive as shown in the control effort graph </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Effect of numerator in the design</SUBJECT>
        <MESSAGE>In the procedure followed in the lecture, I did not understand why we were not getting rise time&gt;0.15 sec when it was designed for 0.15 sec. I mean, I did not understand the explanation given regarding the numerator zeros. Can you please explain it a bit more clearer?

Did it mean we taking T = 1 is not a correct thing to do?



By the way, why does ZOH have a delay of an extra 0.5 sample? I mean why only 0.5 why not more than that / less than that?</MESSAGE>
        <SUBJECT>Re: Effect of numerator in the design</SUBJECT>
        <MESSAGE> The answer to the first question is the following:&lt;br /&gt;&lt;br /&gt;I want you do the following calculation. Find the error transfer function, i.e., the transfer function between the error and the reference signal for the controller derived in pages 329-331 in the book. Take the inverse Z-transform of it. Does it come out to be Eq. 7.109 on page 285? That is, do you get $$\rho^n \cos{\omega n}$$. &lt;br /&gt;&lt;br /&gt;The answer to the second question is the following:&lt;br /&gt;&lt;br /&gt;The continuous time transfer function of zero order hold can be given by $$G(s) = \dfrac {1-e^{-T_ss}}s$$. What are the magnitude and phase of this transfer function? Work completely in continuous time domain.&lt;br /&gt;&lt;br /&gt;By the way, why should we do this analysis in continuous time domain?&lt;br /&gt;&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Introduction of gamma</SUBJECT>
        <MESSAGE>In open loop transfer function G(z), z^(-k) is added. Is this the reason for introduction of gamma with (Tc/Rc) expression or there is some other reason for introduction of gamma?

</MESSAGE>
        <SUBJECT>Re: Introduction of gamma</SUBJECT>
        <MESSAGE>No, gamma is added to make the steady state &amp;quot;gain&amp;quot; correct. Gamma is a scalar, i.e., a constant number. </MESSAGE>
        <SUBJECT>Re: Introduction of gamma</SUBJECT>
        <MESSAGE> after reading your question i am also in doubt </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Delay term in Transfer Function</SUBJECT>
        <MESSAGE>In the lecture, G(z) was written as z^-k B(z)/A(z)
Whats the significance of taking the delay out of the expression and writing it separately?</MESSAGE>
        <SUBJECT>Re: Delay term in Transfer Function</SUBJECT>
        <MESSAGE> $$z^{-k}$$ will appear in the closed loop transfer function also. We also know that the closed loop system will have delay that is at least equal to that of the open loop system. This can be handled easily if we keep the delay term separately.&lt;br /&gt;&lt;br /&gt;Moreover, if we do this, Aryabhatta's identity will become simpler to start with. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>2 DOF pole placement</SUBJECT>
        <MESSAGE>why should we take open loop system with some delay for 2dof pole placement controller </MESSAGE>
        <SUBJECT>Re: 2 DOF pole placement</SUBJECT>
        <MESSAGE>There will be a minimum of one delay in all sampled systems. So the closed loop system should also have at least one delay. If we try to remove this delay also in the closed loop system, there will be difficulties. It is that the plant will not even respond in time. If we really want to achieve it, we need a noncausal controller. This is explained in detail in Chapter 7 of the book. </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1434</ID>
    <LECTURE>28 Feb. 12 - Post your questions here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>Anti Wind up controller</SUBJECT>
        <MESSAGE>In the section 9.7 of the book it mentioned that to handle the integral wind up the obvious way is to compare 'U' and 'Usat' and when  a difference occurs,hold U at Usat.

since U will be either less or more than 'Usat' normally.Then why are we holding 'U' at 'Usat'  even when 'U' is less than 'Usat'.</MESSAGE>
        <SUBJECT>Re: Anti Wind up controller</SUBJECT>
        <MESSAGE>When within the limits U and Usat are same.When limits are exceeded there is a difference in U and Usat so to handle integral windup hold U at Usat. </MESSAGE>
        <SUBJECT>Re: Anti Wind up controller</SUBJECT>
        <MESSAGE>What the book means is the following:&lt;br /&gt;&lt;br /&gt;When U and Usat are different, it means that there is a saturation problem. As a result, the required input cannot be applied.&lt;br /&gt;&lt;br /&gt;Because the required control effort cannot be applied, there could be an offset.&lt;br /&gt;&lt;br /&gt;The offset is the result of the inability to apply the required control effort. Thus, the usual procedure of increasing the integral effort should not be done.&lt;br /&gt;&lt;br /&gt;If instead, the integral effort is increased, not only will the offset problem not solved, but it will worsen the situation - i.e. there will be a wind up of the integral mode.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Bad Zeros of original Transfer function</SUBJECT>
        <MESSAGE>Sir if bad zeros can't be changed by the feedback controller, is there any alternative way to get rid off them. </MESSAGE>
        <SUBJECT>Re: Bad Zeros of original Transfer function</SUBJECT>
        <MESSAGE>Controller does not design to change bad zeros of the plant but to work controller correctly we need to define bad zeros accurately such that no problem occurs in perturbations of initial conditions. </MESSAGE>
        <SUBJECT>Re: Bad Zeros of original Transfer function</SUBJECT>
        <MESSAGE> Control theory/technology does not have a solution to this problem.&lt;br /&gt;&lt;br /&gt;The only solution is to re-design the plant, so as to change the location of the zero.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>R1 inside loop</SUBJECT>
        <MESSAGE>If R1 may contains factor outside unit circle how it allowed to cancel even though consider inside the loop? </MESSAGE>
        <SUBJECT>Re: R1 inside loop</SUBJECT>
        <MESSAGE>This question is not clear. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Change in initial conditions</SUBJECT>
        <MESSAGE>How Gamma changes if initial condition changes? </MESSAGE>
        <SUBJECT>Re: Change in initial conditions</SUBJECT>
        <MESSAGE>Gamma has nothing to do with the initial conditions. &lt;br /&gt;&lt;br /&gt;Gamma is chosen so as to make the steady state gain correct.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Change in initial conditions</SUBJECT>
        <MESSAGE>$$\gamma = \dfrac{\phi_{cl}(1)}{B_r(1)}$$ and initial conditions do not affect the value of $$\phi_{cl}(1)$$ or $$B_r(1)$$ as the former is governed by the desired response and the latter is governed by the open loop system transfer function, which I think is not affected by initial conditions (assuming that the initial conditions do not make the system unstable in open loop)&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Antiwindup Controller</SUBJECT>
        <MESSAGE>How is perturbation in gain taken care in AWC? </MESSAGE>
        <SUBJECT>Re: Antiwindup Controller</SUBJECT>
        <MESSAGE>The question is not clear. </MESSAGE>
        <SUBJECT>Re: Antiwindup Controller</SUBJECT>
        <MESSAGE>In two DOF controller we use Rc= B^g*Delta*R1 for perturbation, In Antiwindup controller why not used F-E=Delta PRc. </MESSAGE>
        <SUBJECT>Re: Antiwindup Controller</SUBJECT>
        <MESSAGE>If AWC has $$\Delta$$ term involved in it, I think the controller has to take care of the gain perturbation. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Gain Perturbation</SUBJECT>
        <MESSAGE>We have seen that the output of a plant in state space form as $$y = Cx + D$$&lt;br /&gt;In the gain perturbation, we have seen that C = [1 0 0] is perturbed to C = [1.1 0 0] or C = [0.9 0 0]. What exactly in the system transfer function blocks are we changing to account for this perturbation. I might be missing a very simply point, but unable to figure out what it is.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Gain Perturbation</SUBJECT>
        <MESSAGE>The transfer function is given by $$G(z) = C(zI-A)^{-1}B$$. As a result, the gain of the plant is proportional to C. So, if C changes by $$+10\%$$, the open loop gain will also change by the same amount. Similarly for negative change. </MESSAGE>
        <SUBJECT>Re: Gain Perturbation</SUBJECT>
        <MESSAGE> Then, in that case, if initially, the DC Gain of the system is $$K$$ then, we have $$\gamma = \dfrac{\phi_{cl}(1)}{K\times K_1}$$ (were $$K_1$$ is some constant such that $$K K_1 = B_r(1)$$&lt;br /&gt;&lt;br /&gt;Now, due to some reason, the D.C. gain is changed to ,say $$K'$$, then, we could have simply modified our $$\gamma$$ right?&lt;br /&gt;&lt;br /&gt;Even our transient response (overshoot and rise time, etc) aren't affected by changing $$\gamma$$, as they are taken care in $$\phi_{cl}$$&lt;br /&gt;&lt;br /&gt;This $$\gamma$$ could have been tuned in order to account for that 10% change in DC Gain, right?&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Slide 4 : Cancellation of A^b and R_1</SUBJECT>
        <MESSAGE>Sir, I did not understand the logic given to justify the cancellation of A&lt;sup&gt;b&lt;/sup&gt; ?&lt;br /&gt;&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Slide 4 : Cancellation of A^b and R_1</SUBJECT>
        <MESSAGE> The $$A^b$$ that comes in Slide 4 is because of the same term. In other words, suppose I perturb it to $$A^b_1$$, ALL $$A^b$$ terms will change to $$A^b_1$$. As all the occurrences of $$A^b$$ come from the same physical source, there will be no mismatch between them. Thus, there is no issue in cancelling it.&lt;br /&gt;&lt;br /&gt;If on the other hand, it comes from two different sources, there could be a mismatch and hence cancellation will create problems.&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Unstable Controller </SUBJECT>
        <MESSAGE>In the lecture you have suggested that the controller could be bad. How is that possible when we designing using model matching? Is it that we are unable to get good approximations of  $$G(z)$$ (the Plant)?</MESSAGE>
        <SUBJECT>Re: Unstable Controller </SUBJECT>
        <MESSAGE>No, while designing the controller, we canceled the zeros of $$R_c(z)$$ not taking into the note that they may be unstable zeroes. This gets reflected in solution of Aryabhatta's Identity. This the reason why we get a bad controller although we used model matching. &lt;br /&gt;&lt;br /&gt;This is similar to - &amp;quot;We cancel every possible pole with the corresponding zero and finally design a controller and say that we have done model matching.&amp;quot;&lt;br /&gt;&lt;br /&gt;Theoretically, these are valid if we are just concerned with the final output. Even in the case of unstable controller, we see that the input oscillates at that high frequency, due to which the hardware undergoes wear and tear. This is implementation issue, but theoretically, we can accept this controller (only if we are concerned about final output stability)&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Unstable Controller </SUBJECT>
        <MESSAGE>Please note that there is no guarantee at all that the controller by itself is stable. The objective of controller design is mainly to make the overall system stable.&lt;br /&gt;&lt;br /&gt;Stabilising the closed loop with stable controllers only could be difficult problem for some systesm.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>About pole placement</SUBJECT>
        <MESSAGE>We have seen how to get $$\phi _{cl}$$ in the desired analysis. But the underlying assumption is that it is a second order t/f. While model matching do we need to take care of that? In other words, do we assume or make sure that the denominator of closed loop t/f is a second order polynomial? </MESSAGE>
        <SUBJECT>Re: About pole placement</SUBJECT>
        <MESSAGE>Systems that can be approximated as a second order, in closed loop, can be handled through this approach. </MESSAGE>
        <SUBJECT>Re: About pole placement</SUBJECT>
        <MESSAGE>I think there would be discrepancy in the results, but taking the conditionseven more strictly (like rise time specification is taken to be &amp;lt;2 s although the requirement is 3s) would result in meeting the required specifications.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: About pole placement</SUBJECT>
        <MESSAGE>I think the dominant behavior should be of second order </MESSAGE>
        <SUBJECT>Re: About pole placement</SUBJECT>
        <MESSAGE>. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Slide 14</SUBJECT>
        <MESSAGE> In the slide 14 of the lecture, we see that the perturbation is given in C by $$\pm$$10% from its previous value, and we finally end up getting same steady state values with the newly developed controller.&lt;br /&gt;&lt;br /&gt;
&lt;ol&gt;
  &lt;li&gt;But, for a particular rise time and overshoot conditions, my $$\phi_{cl}$$ is fixed. (Because, $$\phi_{cl} = z^2-2z\rho\cos(\omega) + {\rho}^2$$). But in the outputs, we see that the overshoot has changed. Why is this happening? &lt;br /&gt; &lt;/li&gt;
  &lt;li&gt;Why do we need to introduce $$\Delta$$ just because there is a change in D.C. Gain of the plant? I mean how is it changing the order of the system that demands this improvement?&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt; </MESSAGE>
        <SUBJECT>Re: Slide 14</SUBJECT>
        <MESSAGE>&lt;ol&gt; 
  &lt;li&gt;To get the same rise time and overshoot conditions, you need to get the overall transfer function correct - it should be equal to the Z-transform of $$\rho^n\cos{\omega n}$$. I told you that we do not get it with our controller design, although, the denominator is chosen to be the same. That is, there is a change in the numerator. Presence of nonminimum phase zeros create further difficulties. That is the reason for mismatch.&lt;/li&gt; 
  &lt;li&gt;In including $$\Delta$$, we incorporate the internal model principle. Namely, if the unstable part of the exogeneous signal is chosen as a part of the controller, the signal gets removed.&lt;br /&gt;&lt;/li&gt; 
&lt;/ol&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Slide 11</SUBJECT>
        <MESSAGE>we are taking alpha(z)=LCM of R(z) and V(z), but in some cases, if pole changes slightly, LCM may change drastically. wont it have drastic effect on design? </MESSAGE>
        <SUBJECT>Re: Slide 11</SUBJECT>
        <MESSAGE>This is the reason why I already explained in the class that we do not yet have theories to handle &amp;quot;unstable&amp;quot;, &amp;quot;unknown&amp;quot; systems. If stable, we can handle unknown systems. If unstable, we need to know it exactly.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>myc2d</SUBJECT>
        <MESSAGE>In the myc2d code, why are time delays not allowed? </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide12  Step disturbance</SUBJECT>
        <MESSAGE>Z transform of unit step function is z/(z-1), then why to take step disturbance (Delta) as (1 - z^-1) why not 1/ (1 - z^-1)? </MESSAGE>
        <SUBJECT>Re: slide12  Step disturbance</SUBJECT>
        <MESSAGE> $$\Delta$$ is not step disturbance. It is defined as $$1-z^{-1}$$. For example, $$\Delta u(k) = (1-z^{-1})u(k)$$, which in turn is equal to $$u(k) - u(k-1)$$. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Integrator windup</SUBJECT>
        <MESSAGE>Sir, please explain the condition when the integrator windup occurs? </MESSAGE>
        <SUBJECT>Re: Integrator windup</SUBJECT>
        <MESSAGE>I explained this with an example in the class. Let me repeat it now. Suppose that a plant has to be cooled to some temperature and that we want to send 2.2 litres of coolant per minute. Let us assume that the maximum flow rate available is 2 litres per minute. Because we do not cool the system sufficiently, the temperature will reach a value different from what is required.&lt;br /&gt;&lt;br /&gt;If we have integral mode, it will think that the control effort, namely 2.2, is not enough. It will increase it further, say to 3, then 4, etc. Suppose that go up to 4. The actual coolant rate used, however, is only 2 litres, as this is the maximum capacity.&lt;br /&gt;&lt;br /&gt;Suppose that at some time in the future, we want to HEAT the system. The coolant flow rate has to be decreased. In this case, the controller will start decrementing from a value of 4. It will take some time to come below 2. The coolant valve will do nothing (i.e. it will be fully open), so long as it is above 2. Only after the required control effort comes down to a value below 2, will the control valve start closing. During the intervening period (i.e. the time required to bring down the value from 4 to 2), we would have cooled the system at the maximum possible rate, when we should have heated!&lt;br /&gt;&lt;br /&gt;One solution to this problem is to compare the control law with the actual value used. If the actual value used is different from the required control law, disable the integral mode. We presented an alternate approach in the video and the book.&lt;br /&gt; </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1437</ID>
    <LECTURE>7 March 13 - Post your questions here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>Fractional time delay</SUBJECT>
        <MESSAGE>We have seen that every system has a minimum delay of 1 sample and hence $$k \geq 1$$. Now, let us suppose that the sampling time is 0.1 seconds and the delay in the system is 0.15 seconds i.e., delay is 1.5 times the sampling time. Now, is this going to be accounted as a delay of 0.2 seconds only?</MESSAGE>
        <SUBJECT>Re: Fractional time delay</SUBJECT>
        <MESSAGE>Probably yes.&lt;br /&gt;since the o/p will be sampled only after every 0.1 seconds, change in o/p will not be detected till 0.2 seconds&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Fractional time delay</SUBJECT>
        <MESSAGE>Yes </MESSAGE>
        <SUBJECT>Re: Fractional time delay</SUBJECT>
        <MESSAGE>You will take the next higher integral number as the time delay. The extra time delay introduced will be converted into a rational function. Please see example 8.5 on page 305. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Smith's Predictor</SUBJECT>
        <MESSAGE>We have seen that, in Smith's predictor, we find the estimate of $$y( n ) = z^{-k+1} \frac {B_d( z )}{A( z )} u( n) $$ and introduced a minimum delay of 1 sample in the plant.

But, why is it that we &lt;b&gt;need&lt;/b&gt; to include this one sample delay in the plane. Why can't we develop our Smith's predictor like $$\^y( n ) = \left[(1-z^{-k_m})\frac{B_{m}(z)}{A_{m}(z)}u(z)\right ] + z^{-k} \frac{B(z)}{A(z)}u( n ) $$ </MESSAGE>
        <SUBJECT>Re: Smith's Predictor</SUBJECT>
        <MESSAGE> Mathematicaly it looks like simple but input does not have instantaneous effect, out-put will have a nonzero delay at least one sample delay. </MESSAGE>
        <SUBJECT>Re: Smith's Predictor</SUBJECT>
        <MESSAGE>But I always can find my $$B_m$$ and $$A_m$$ for this purpose mathematically, right? Isn't the delay even more compensated by this change?</MESSAGE>
        <SUBJECT>Re: Smith's Predictor</SUBJECT>
        <MESSAGE> In the $$ \^y( n ) $$ proposed by you, in the case of exact knowledge the output becomes 1, and not the minimum delay estimate. The objective of smith predictor is to remove the effects of any delay larger than one&lt;br /&gt;&lt;pre&gt; &lt;/pre&gt; </MESSAGE>
        <SUBJECT>Re: Smith's Predictor</SUBJECT>
        <MESSAGE>We do this to avoid algebraic loops. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>IMC</SUBJECT>
        <MESSAGE>If the plant is of nonminimum phase i.e.&lt;br /&gt;&#160;G= (1- z&lt;sup&gt;-1&lt;/sup&gt;2)/(1- z&lt;sup&gt;-1&lt;/sup&gt;0.5), then&#160; candidate for G&lt;sub&gt;q&lt;/sub&gt; is having pole -zero cancellation&lt;br /&gt;[z -.5/z -.5].&lt;br /&gt;how to overcome this problem ?&#160;&#160;
</MESSAGE>
        <SUBJECT>Re: IMC</SUBJECT>
        <MESSAGE>Trying to post the answer, led me to the same doubt!</MESSAGE>
        <SUBJECT>Re: IMC</SUBJECT>
        <MESSAGE>I don't see any problem in this cancellation. The pole and zero both are stable, aren't they? Are you confusing with continuous time? In discrete time, a pole inside unit circle is stable! </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 15</SUBJECT>
        <MESSAGE>In slide 15, y=0&#160; for G=G&lt;sub&gt;p&lt;/sub&gt;. What will be noise if plant model mismatch ,will it remain constant ?&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: slide 15</SUBJECT>
        <MESSAGE>In slide 15 y is not zero for G=G&lt;sub&gt;p,insteed Y= u *Gp + &#353;&lt;br /&gt;If the plant model mismatch y tilda is different than &lt;/sub&gt;&#353; alone. </MESSAGE>
        <SUBJECT>Re: slide 15</SUBJECT>
        <MESSAGE>i mean y turn out to be zero, since&#160; noise coming to external world cancel the noise that we will get just before summing point.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: slide 15</SUBJECT>
        <MESSAGE>Sorry, I did not what do you mean by plant-model mismatch when $$G = G_p$$.
As far as I know, when $$G = G_p$$, then there is no plant-model mismatch.

But, suppose there is a plant model mismatch and there is noise, then the total error signal will be due to both - that noise and the mismatch between the plant and model, i.e., $$ \xi = \xi_{\text{noise}} + (G_p - G)u(z) $$</MESSAGE>
        <SUBJECT>Re: slide 15</SUBJECT>
        <MESSAGE>Noise $$\xi$$ and the plant-model mismatch are independent of each other. For example, any one of these two or both can be nonzero. &lt;br /&gt;&lt;br /&gt;So, if there is no plant model mismatch, $$\tilde \xi=\xi$$, which could be zero or nonzero.&lt;br /&gt;&lt;br /&gt;In view of this, I don't understand your questions.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: slide 15</SUBJECT>
        <MESSAGE>$$ y $$ will not be equal to zero, $$ y-\~y $$ will be equal to zero. Noise is independent of plant model mismatch </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>difference between S0, R0, T0 and Sc, Rc,Tc</SUBJECT>
        <MESSAGE>What is the difference between S0, R0, T0 and Sc, Rc,Tc ? </MESSAGE>
        <SUBJECT>Re: difference between S0, R0, T0 and Sc, Rc,Tc</SUBJECT>
        <MESSAGE>S0, R0, T0 represent the controller for delay free plant , while Sc, Rc,Tc may be for general case.&#160;
</MESSAGE>
        <SUBJECT>Re: difference between S0, R0, T0 and Sc, Rc,Tc</SUBJECT>
        <MESSAGE>Yes, what Jagdish says is correct. This is clear from the last line of slide 8 and the discussion in Slide 9. </MESSAGE>
        <SUBJECT>Re: difference between S0, R0, T0 and Sc, Rc,Tc</SUBJECT>
        <MESSAGE>S0, R0 and T0 are Sc, Rc and Tc when the delay is reduced to the minimum value of 1 (pg 382 in the book) </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 20</SUBJECT>
        <MESSAGE>what is meant by non-Hurwitz factors?&lt;br /&gt;Also, I couldn't understand what manipulations are done in slide 20.&lt;br /&gt;&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: slide 20</SUBJECT>
        <MESSAGE>in slide 20 we are finding candidate for G&lt;sub&gt;q&lt;/sub&gt; when plant is nonminimum phase.&lt;br /&gt;by multiply the polynomial with highest negative degree of z you will get G&lt;sub&gt;q.&lt;/sub&gt;&lt;br /&gt;
</MESSAGE>
        <SUBJECT>Re: slide 20</SUBJECT>
        <MESSAGE>A factor that has a zero outside the unit circle is called a non-Hurwitz factor. In the given example, $$1-2z^{-1}$$ has a zero at 2, which is outside the unit circle. As a result, this factor is known as the non-Hurwitz factor.&lt;br /&gt;&lt;br /&gt;Reciprocal polynomials are obtained by reversing the coefficients. For example, 1 and $$-2$$ are coefficients of constant and $$z^{-1}$$ respectively, in the given factor. In the reciprocal polynomial, they become the coefficients of $$z^{-1}$$ and constant, respectively.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Control law of smith predictor</SUBJECT>
        <MESSAGE>There is a miss match between the control law given in the slide no-10 and the book (Equation-10.8).
The equation in the slide seems to be correct.

Pl clarify.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>algebraic loop</SUBJECT>
        <MESSAGE>How the algebraic loop is created in the feedback loop?</MESSAGE>
        <SUBJECT>Re: algebraic loop</SUBJECT>
        <MESSAGE>If there is a delay, the calculation can proceed in forward path, taking the value from the feedback path. If not, all the elements have to be solved SIMULTANEOUSLY. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Equation 10.4 and 10.8</SUBJECT>
        <MESSAGE>We defined in Eq(10.4) Bd as Bd(z) = z^-1 * B(z); so the equation G(z) should become G(z) = z^-(k+1)*(Bd(z)/A(z)); but it is mentioned as G(z) = z^-(k-1)* Bd(z)/A(z)); 

Also the eq.10.8, from the figure 10.2 in the book it comes out to be R0*u = gama*T0*r - S0*y_hat; but it is given differently. 

I think i am doing some calculation mistake please clarify. </MESSAGE>
        <SUBJECT>Re: Equation 10.4 and 10.8</SUBJECT>
        <MESSAGE> Eq. 10.4 is $$z^{-(k-1)}\frac{B_d(z)}{A(z)} = z^{-k+1}\frac{B_d(z)}{A(z)} = z^{-k}\frac{B(z)}{A(z)}$$. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>u1 and u2</SUBJECT>
        <MESSAGE>What is the reason for selecting the extra inputs u1 and u2? </MESSAGE>
        <SUBJECT>Re: u1 and u2</SUBJECT>
        <MESSAGE>Internal stability requires that the system should be stable from input injected at every point to any other point. It turns out that only two independent inputs are required. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Objective of IMC</SUBJECT>
        <MESSAGE>It is mentioned in the slides that the objective of IMC is to reduce summation of error squared. What specification demands reduction of summation of error squared? </MESSAGE>
        <SUBJECT>Re: Objective of IMC</SUBJECT>
        <MESSAGE>The three design rules given in slides 19-21 help achieve the objective of minimising the summation of error squared, given in slide 18. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>what is an algebric loop</SUBJECT>
        <MESSAGE>ref page 383 of the book para just below the graphs. it says that if the delay is compensated then algebric loop is created in the feedback loop causing difficulties during simulation. what is meant by algebric loop </MESSAGE>
        <SUBJECT>Re: what is an algebric loop</SUBJECT>
        <MESSAGE>Same doubt was posted by Sulakshan, in the same thread. Let me give my answer again:&lt;br /&gt;&lt;br /&gt;
&lt;table cellspacing="0" class="forumpost" style="color: rgb(0, 51, 204);"&gt;&lt;tbody&gt;
  &lt;tr&gt;
    &lt;tr&gt;
      &lt;td class="content"&gt;
        &lt;div class="posting"&gt;If there is a delay, the calculation can proceed in forward path, taking the value from the feedback path. If not, all the elements have to be solved SIMULTANEOUSLY. &lt;/div&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tr&gt;&lt;/tbody&gt;
&lt;/table&gt;&lt;br /&gt;To put it another way, this results in implicit equations (unknown being a function of itself) that require analytical solution, in case of feedback loops. The usual method of calculating the next value using the current value does not work.&lt;br /&gt;&lt;br /&gt;I did a web search using the phrase &amp;quot;algebraic loop&amp;quot; and got the following hits:&lt;br /&gt;&lt;br /&gt;http://www.20sim.com/webhelp/editor/compiling/algebraicloops.htm&lt;br /&gt;&lt;br /&gt;http://www.nd.edu/~dtl/cheg258/notes/doc/tec7.1.html&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>smith predictor</SUBJECT>
        <MESSAGE>Can We implement smith predictor for noisy systems? </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1441</ID>
    <LECTURE>15 March 14. Post your doubts here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>Value of coefficient bo</SUBJECT>
        <MESSAGE>Values of constant terms of A, B, C are not zero also Constant terms of A and C are one, what if the constant term of B i.e. b0 is one? you are talking about some gain bo/1 at steady state but its not clear to me. </MESSAGE>
        <SUBJECT>Re: Value of coefficient bo</SUBJECT>
        <MESSAGE>$$\dfrac{b_0}{a_0}$$ is the steady state gain of the plant, in general. As $$a_0$$ is zero here, the steady state gain is just $$b_0$$. The plant need not always have steady state gain as 1 (example, you may consider our SBHS Plant). If the steady state gain of the plane is also 1, then, $$b_0 = 1$$.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Value of coefficient bo</SUBJECT>
        <MESSAGE>The question is not clear. What slide are you talking about? What is your question? </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>minimum variance controller</SUBJECT>
        <MESSAGE>in class we have design MVC when input is zero i.e. for regulation(y has to maintain at zero).&lt;br /&gt;suppose the plant is settle at some non-zero value and noise enter at this moment(here y has to maintain at some value). then how to design controller ? &lt;br /&gt;
</MESSAGE>
        <SUBJECT>Re: minimum variance controller</SUBJECT>
        <MESSAGE>Y may maintain at any value (decided by setpoint)there is not constraint on Y. In MVC we are equating ^y(n + k|n) = zero to obtain the controller. </MESSAGE>
        <SUBJECT>Re: minimum variance controller</SUBJECT>
        <MESSAGE>It is possible to accommodate tracking also. It is not considered in the lecture.&lt;br /&gt;&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>difference bet MVC and GMVC</SUBJECT>
        <MESSAGE>what is the difference bet MVC and GMVC. we say that u is constrained in GMVC isn't the u constrained in MVC if not then how does the saturation of control takes place. i am confused. </MESSAGE>
        <SUBJECT>Re: difference bet MVC and GMVC</SUBJECT>
        <MESSAGE>Take the example of a valve with a large span. MVC could result in large flow rates, swings, etc. GMVC will result in smaller flow rates, essentially, a constrained one. </MESSAGE>
        <SUBJECT>Re: difference bet MVC and GMVC</SUBJECT>
        <MESSAGE>Unbounded control effort can result from MVC. Approximate solution to this problem is GMVC. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>ARIMAX Model</SUBJECT>
        <MESSAGE>&lt;p&gt;In ARIMAX model, we introduce $$\Delta$$, does it in other words mean that, w are introducing a low pass filter in series?&lt;/p&gt;</MESSAGE>
        <SUBJECT>Re: ARIMAX Model</SUBJECT>
        <MESSAGE>$$\Delta$$ takes care of the fact that the noise appears in the form of random STEPS. One way to accommodate this is to work with differences in input $$u$$ and output $$y$$. </MESSAGE>
        <SUBJECT>Re: ARIMAX Model</SUBJECT>
        <MESSAGE>I believe that moving average and integrator perform similar operation, I think integrator is used here for normalization.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Saturation of U</SUBJECT>
        <MESSAGE>Why control effort of MVC gets saturated ? What are the conditions in which it gets saturated?</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>ARIMAX</SUBJECT>
        <MESSAGE>Can we say that $$\delta$$ and Moving average term are performing similar operation?</MESSAGE>
        <SUBJECT>Re: ARIMAX</SUBJECT>
        <MESSAGE>Which $$\delta$$ are you talking about? In what slide is this coming? </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>monic polynomial A,C</SUBJECT>
        <MESSAGE>sir it is not clear to me why polynomial A,C are consider monic &amp;amp; polynomial B is not monic. </MESSAGE>
        <SUBJECT>Re: monic polynomial A,C</SUBJECT>
        <MESSAGE> If the steady state gain between u and y is 1, then B can also be monic. To account for the steady state gain not being 1, we allow B to be non-monic. Then what happens to the gain between $$\xi$$ and y. The answer is that in case the gain is not 1, we can absorb it into the variance of $$\xi$$ and take the polynomial C to be monic. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Prediction Error Models</SUBJECT>
        <MESSAGE>How to choose accurate Prediction Error Model for a particular plant is this a problem of control or identification? </MESSAGE>
        <SUBJECT>Re: Prediction Error Models</SUBJECT>
        <MESSAGE>We have not discussed this in detail. A lot of information on this is available in Chapter 6 of the book. </MESSAGE>
        <SUBJECT>Re: Prediction Error Models</SUBJECT>
        <MESSAGE>I think it is a problem related to identification </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1450</ID>
    <LECTURE>18 March.  15 - Post your doubts here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>Performance of an MVC</SUBJECT>
        <MESSAGE>Sir, This is with reference to the the explanation you gave at time 10mins on the minimum variance control.&lt;br /&gt;&lt;br /&gt;I have the following doubts:&lt;br /&gt;&lt;br /&gt;1. Shouldn't the output be identically equal to the reference value if we are using MVC.&lt;br /&gt;&lt;br /&gt;2. You said that if the output dips too low, it will have to rise high to maintain an average, but I feel that should not happen as we are dealing with squares of differences.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Performance of an MVC</SUBJECT>
        <MESSAGE>1. In MVC, we are bringing the output to exactly to the reference value and not after that. And moreover, we are taking the future values of $$\xi$$ to be zero as an &lt;span style="font-weight: bold;"&gt;estimate&lt;/span&gt;, but it is not. May be that effect is incorporated in the output.&lt;br /&gt;2. Sir was referring to the variance and mean of the output, in general. It has got nothing to do with our MVC. What sir meant was, suppose our output once went to -10 volts (say) and the reference point is 0V. So, if the mean of the output is 0 volts, to maintain this mean, the output becomes +10V or so.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Performance of an MVC</SUBJECT>
        <MESSAGE>The best we can achieve with respect to noise rejection is to obtain white noise. &lt;br /&gt;&lt;br /&gt;I don't understand the second part of your question.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>row in slide 8</SUBJECT>
        <MESSAGE>Row is a tuning parameter, is there any criteria to determine value of row ? </MESSAGE>
        <SUBJECT>Re: row in slide 8</SUBJECT>
        <MESSAGE> I explained the role of rho ($$\rho$$) in the last class: Design a controller with some rho. If this controller results in large manipulated effort ($$u$$), increase rho. If on the other hand, the control effort can be increased, one can decrease $$\rho$$ so as to decrease the error. </MESSAGE>
        <SUBJECT>Re: row in slide 8</SUBJECT>
        <MESSAGE>$$ \rho $$ is the weight given to control effort. Range of control effort values decides the value of $$ \rho $$ </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>rho- slide8</SUBJECT>
        <MESSAGE>is rho in slide 10 is varying ?&lt;br /&gt;because after some n we need small change in u(n) .&lt;br /&gt;how to find rho ?&lt;br /&gt;
</MESSAGE>
        <SUBJECT>Re: rho- slide8</SUBJECT>
        <MESSAGE>No, $$\rho$$ is usually a constant and may be dynamically varied (if required). I think, $$\rho$$ usually is chosen so as to limit the control effort (in ARMAX model) or change in the control effort (in ARIMAX and ARIX model)&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: rho- slide8</SUBJECT>
        <MESSAGE>$$\rho$$ is a tuning parameter. In another post, I explained the procedure for adjusting it. In my lecture, I have chosen a constant $$\rho$$. It can vary, however. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Noise Estimate</SUBJECT>
        <MESSAGE>Usually in a system, there is more noise in the beginning, since the turning on of one components in a system introduces noise in other blocks as well. This noise usually decreases later.&lt;br /&gt;So, how can we estimate future noise based on (previous) mean?&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Noise Estimate</SUBJECT>
        <MESSAGE> For this estimation of future noise, I think we can do the following procedure when the mean and variance are known :&lt;br /&gt;$${\sigma}^2 = \dfrac{1}{N}\sum_{i=0}^N{{(x-\mu)}}^2$$ where $$\mu$$ is the mean.&lt;br /&gt;&lt;br /&gt;From the above formula, we can take $$x( n )$$ to be an unknown and substitute previous values in the above formula and solve for $$x( n )$$.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Noise Estimate</SUBJECT>
        <MESSAGE>The estimate of a zero mean white noise that is yet to occur is zero.&lt;br /&gt;&lt;br /&gt;A noise term of the past is measurable as the difference between what the model predicts and the actual value. The model helps arrive at this value.&lt;br /&gt;&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Generalized Minimum Variance Control</SUBJECT>
        <MESSAGE>How is the  control  of input 'U' and its variance  is being done in the GMVC through the 'rho' function.It is not understood.</MESSAGE>
        <SUBJECT>Re: Generalized Minimum Variance Control</SUBJECT>
        <MESSAGE> In our objective function to minimize the variance in output, we have additional terms corresponding to the control law, $$\rho {\Delta u( n )}^2 + \rho {\Delta u( n +1 )}^2 \rho {\Delta u( n+2 )}^2 ..... $$. This $$\rho$$ is the weight that is associated to the control input. A large value of $$\rho$$ denotes, small change in u is required, because when we differentiate the objective function and equate it to zero, we get something like $$\Delta u( n ) = \dfrac{-1}{\rho} * (\text{something}) $$. So, a large value of $$\rho$$ denotes small change in the control effort. The &lt;span style="font-weight: bold;"&gt;changes&lt;/span&gt; in u account for the variance in the control effort.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Generalized Minimum Variance Control</SUBJECT>
        <MESSAGE> I think $$ \rho $$ is the weight given to control effort in the performance index </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Minimum Variance Control</SUBJECT>
        <MESSAGE> In MVC, we usually take future noise $$\xi( n +j )$$ to be 0. From the previous trend of the white noise, i.e., from the variance and mean, we can &lt;span style="font-weight: bold;"&gt;predict&lt;/span&gt; the future values of noise and we can add into the estimate so that we can get a better control law. I understand this involves more computation, but isn't this a better method to implement MVC?&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Minimum Variance Control</SUBJECT>
        <MESSAGE>By the very definition of white noise, it cannot be predicted. As a result, your approach cannot be implemented. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>difference bet GMVC and GPC</SUBJECT>
        <MESSAGE>can we say that the difference between GMVC and GPC is that GMVC has u as constraint and GPC has delta u as constraint as delta u equal to zero&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: difference bet GMVC and GPC</SUBJECT>
        <MESSAGE>No, this is NOT the difference between them. GMVC for any model that has integrated noise will also have a constraint on $$\Delta u$$.&lt;br /&gt;&lt;br /&gt;The difference is that the objective function of GMVC has terms at ONE time instant only. The GPC, on the other hand, minimises the SUM of terms at MANY time points.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Optimization index</SUBJECT>
        <MESSAGE>How is optimization index minimized by calculating the expression of &lt;span style="text-decoration: underline; font-weight: bold;"&gt;y&lt;/span&gt;&lt;span style="font-weight: bold;"&gt;^&lt;/span&gt;?&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Optimization index</SUBJECT>
        <MESSAGE>Calculation of $$\hat y$$ is the first step. This helps split the estimate into two types of terms: terms that involve past and those that have to do with the future, i.e. the measurements yet to be made. This approach is explained in the next lecture. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>output follows the ref from n+k onwards slide 9</SUBJECT>
        <MESSAGE>in slide 9 you have mentioned that we want the o/p to follow referance (n+K) onwards and not just at k. in MVC we use estimate y(n+k/n)=0 so does this means that here also o/p to follow input n+k onwards. </MESSAGE>
        <SUBJECT>Re: output follows the ref from n+k onwards slide 9</SUBJECT>
        <MESSAGE>No, in the previous lecture, we just did it for that instant, i.e., only at $${\text{n+k}}^{\text{th}}$$ instant. </MESSAGE>
        <SUBJECT>Re: output follows the ref from n+k onwards slide 9</SUBJECT>
        <MESSAGE>no </MESSAGE>
        <SUBJECT>Re: output follows the ref from n+k onwards slide 9</SUBJECT>
        <MESSAGE>The answer given by Swaroop is correct. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Splitting noise </SUBJECT>
        <MESSAGE>It is not understood how are we splitting noise into present and future components.&lt;br /&gt;Please clarify.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Splitting noise </SUBJECT>
        <MESSAGE> The moving average part of the output $$\dfrac{C( z )}{A( z )}$$, on performing long division gives us some $$E_j( z )$$ and $$z^{-j}F_j( z )$$. &lt;br /&gt;$$E_j( z ) = e_0 + e_1z^{-1} + .....+e_{j-1}z^{j-1} $$ and similarly, $$F_j( z ) = f_0 + f_1z^{-1} + ..... $$. &lt;br /&gt;So, $$E_j( z ) \xi( n+j ) = e_0 \xi( n+j ) + e_1 \xi( n+j-1) +....$$ which are the future components. &lt;br /&gt;The other half, i.e., $$z^{-j} F_j( z ) \xi(n+j) = f_0 \xi(n-1) + ....$$ which are the past components. This was explained in the previous lecture too.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Splitting noise </SUBJECT>
        <MESSAGE>if we split the noise into past and future terms, we can put for future terms as zero and obtain the error model.&lt;br /&gt;&lt;br /&gt;
</MESSAGE>
        <SUBJECT>Re: Splitting noise </SUBJECT>
        <MESSAGE>yeah i know, but how these two are considered as future and past components??&lt;br /&gt;i am unable to visualize. can u tell me bit graphically or any other way.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Splitting noise </SUBJECT>
        <MESSAGE> Let us say j is 2, and n is 3, i.e., we are at 3rd sample. &lt;br /&gt;The first half of the sum gives us, $$e_0 \xi ( 5 ) + e_1 \xi ( 4 ) $$ and the other term will have $$f_0 \xi(3) + f_1 \xi(2)...$$ and this $$\xi(3) , \xi(2) ...$$ and so on are current and past terms (since we are at 3rd sample) while $$\xi(4) $$ and $$\xi(5)$$ are future noise terms.&lt;br /&gt;I guess this makes it clear. &lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Splitting noise </SUBJECT>
        <MESSAGE> Consider $$\frac C A = \frac{1+c_1z^{-1}+c_2z^{-2}+\cdots}{1+a_1z^{-1}+a_2z^{-2}+\cdots}$$. It is easy to follow that term due to $$c_1$$ refer to the past, because of the $$z^{-1}$$ term. Similarly, due to $$c_$$ and so on.&lt;br /&gt;&lt;br /&gt;At the same time, the terms due to $$a_1$$ will lead to future terms, because of the presence of $$z^{-1}$$ in the denominator. Similarly, due to $$a_2$$ and so on.&lt;br /&gt;&lt;br /&gt;So, what happens to the fraction? Can we split this into past and future? This is not obvious from the given form, as some terms lead to the past, while some others lead to the future. The approach that we followed clearly separates the past from the future.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 8</SUBJECT>
        <MESSAGE> sir it is not understood here In slide 8 how can we determine the row.&lt;br /&gt;&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: slide 8</SUBJECT>
        <MESSAGE>We are not estimating $$\rho$$ at all. $$\rho$$ has to be specified by the user. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Control effort and minimum variance</SUBJECT>
        <MESSAGE>in the video, in the discussion on why variance should be minimum, you said that its desirable to keep variance low as that would reduce the control effort to keep the output about the mean. Therefore, shouldbt MVC be the most efficient i.e. consuming least control effort? 
   Later in the lecture you mentioned that this controller has best performance but also needs larger effort. I'm a bit confused.</MESSAGE>
        <SUBJECT>Re: Control effort and minimum variance</SUBJECT>
        <MESSAGE> We want to maintain the OUTPUT about the mean. How do we achieve this: through MANIPULATED effort. If the output has to reach the required value at the shortest time, naturally, this effort will be large. </MESSAGE>
        <SUBJECT>Re: Control effort and minimum variance</SUBJECT>
        <MESSAGE>But if we use a slower controller, the output would take more time to reach the mean, and therfore less effort. However, the variance from the mean will also increase due to the larger amount of time available to drift. So we will need to apply the control effort for a longer period of time. So wont the effects cancel out?</MESSAGE>
        <SUBJECT>Re: Control effort and minimum variance</SUBJECT>
        <MESSAGE> As an extreme example, a minimum variance controller may require the application of 1 Mega Watt power for a nanosecond to change the temperature of water in a beaker by $$0.1^\circ C$$. A normal controller may want a more reasonable value of 100 watts to be applied over a period of 5 seconds. Does this answer your doubt? </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Minimization</SUBJECT>
        <MESSAGE> In slide 8 differentiation w.r.t $$ u $$ is done and equated to zero. &lt;br /&gt;In slide 11 are we differentiating w.r.t $$ \Delta u $$ for minimization?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Minimization</SUBJECT>
        <MESSAGE>That is correct. If $$u$$ is the variable, we minimise with respect to it. Similarly for $$\Delta u$$. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>PID tuning through GMVC</SUBJECT>
        <MESSAGE>sir could you pl explain as to why row is not included in the min index in equation 11.72 on page 424. also i have not understood the last term in the equation P(1)r(n) why is it included. also how this equation is of the form given in equation 11.67 </MESSAGE>
        <SUBJECT>Re: PID tuning through GMVC</SUBJECT>
        <MESSAGE> $$\rho$$ is not specified here. If we specify some $$\rho$$, minimise the objective function, obtain a control law, we will arrive at some closed loop transfer function. In this approach, however, $$\phi_{cl}$$ is specified. This can be thought of as having come from some $$\rho$$, which is not of interest in this approach.&lt;br /&gt;&lt;br /&gt;The term $$P(1)r(k)$$ is motivated by equation 8.51 on page 319, as explained in the derivation.&lt;br /&gt;&lt;br /&gt;Finally, minimisation of Eq. 11.67 results in an algebraic equation 11.69. Eq. 11.75 is a generalisation of Eq. 11.69.&lt;br /&gt;&lt;br /&gt;Please notice that the discussion on 11.3.3 is just an example. It is not a general theory. &lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 15 operator E</SUBJECT>
        <MESSAGE>$$E$$ denotes expectation, what exactly this means? </MESSAGE>
        <SUBJECT>Re: slide 15 operator E</SUBJECT>
        <MESSAGE>This is a short form for saying &amp;quot;calculate the expected value of the random variable&amp;quot; </MESSAGE>
        <SUBJECT>Re: slide 15 operator E</SUBJECT>
        <MESSAGE> expectation is the average of all possible values that random variable can take.&lt;br /&gt;&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Value of gamma?</SUBJECT>
        <MESSAGE>How to find value for gamma in gamma(r(n+k))? </MESSAGE>
        <SUBJECT>Re: Value of gamma?</SUBJECT>
        <MESSAGE>Please solve problem on slide 24 in lecture 14.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>GMVC</SUBJECT>
        <MESSAGE>sir in designing an GMVC suppose the noise term is random step ,will the output will have finite variance when system is in stable. </MESSAGE>
        <SUBJECT>Re: GMVC</SUBJECT>
        <MESSAGE>If random steps are permitted, we will be minimising the changes in u. The variance of the output can be bounded by an appropriate choice of u. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>MVC</SUBJECT>
        <MESSAGE>sir how can we implement MVC with PID controller. </MESSAGE>
        <SUBJECT>Re: MVC</SUBJECT>
        <MESSAGE>As it may result in very large control effort, the MVC law is never implemented in practice. It is only used as a benchmark. As it is never used, there is not much work (at least I don't know) on implementing it as PID. </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1451</ID>
    <LECTURE>21 March.  16 - Post your doubts here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>implementing first row</SUBJECT>
        <MESSAGE>why are we only implementing first row?&lt;br /&gt;for every next instance we have to recalculate the deltau(n). will it not increases computation( when we the deltau(n) for next instance) ?&lt;br /&gt;
</MESSAGE>
        <SUBJECT>Re: implementing first row</SUBJECT>
        <MESSAGE>Yes, it will increase the computation.&lt;br /&gt;&lt;br /&gt;But it will also take care of changes in the model, if any. This is one of the reasons why this method is popular.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: implementing first row</SUBJECT>
        <MESSAGE>I think we need to evaluate control the control law at each step, and of course it increases computational cost. In few cases, the control effort might turn out to be some algebraic function (or something similar which can be found using pattern identification, etc) which can be implemented with out even evaluating the control effort at each step.</MESSAGE>
        <SUBJECT>Re: implementing first row</SUBJECT>
        <MESSAGE>Nowadays the computing power is not an issue at all. Remember that the MPC approaches are popular in slow industries: power plants, refineries and chemical industry. As a result, the sampling time is reasonably large, sufficient to do the computations. </MESSAGE>
        <SUBJECT>Re: implementing first row</SUBJECT>
        <MESSAGE> I think there is no scalar equation to calculate u( n ). Therefore we need to carry out matrix multiplications but only implement the first row </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Tunning Parmeters N1,N2(Ny)  and Nu</SUBJECT>
        <MESSAGE>
Question 1
1. In the book on page 443 it mentioned we minimise error from n+k+N1 to n+k+N2, where N2&gt;N1 and 
Nu&lt;N2-N1. In the slide  and video lecture we have studies regarding only Ny and Nu.
2 It  is  mentioned that N1 is typically chosen as 0. I want to ask under what condition N1 is non Zero? 

Doubt 2
On page 454  and Section 12.3 of book the  last term of equation  regarding Y^ seem to be  misprint.It should be b(k+1) instead of b(k)?</MESSAGE>
        <SUBJECT>Re: Tunning Parmeters N1,N2(Ny)  and Nu</SUBJECT>
        <MESSAGE>So, what is the question? </MESSAGE>
        <SUBJECT>Re: Tunning Parmeters N1,N2(Ny)  and Nu</SUBJECT>
        <MESSAGE>  i think there was some problem due to which question did not appear earlier.

My question was that you have mentioned in the  book that N1 is generally chosen to be Zero, so what happen in those cases where N1 not Zero.what is the need of N1,N2 and why  not Ny only .Is  Ny  not solving the same purpose.
</MESSAGE>
        <SUBJECT>Re: Tunning Parmeters N1,N2(Ny)  and Nu</SUBJECT>
        <MESSAGE>N1 specifies the time when the minimisation should begin. This gives an additional flexibility to the control designer. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Bias Term</SUBJECT>
        <MESSAGE>I am confused regarding the bias term in the DMC Modelling. Say, we are implementing k-step prediction model. The bias at $${\test{k+1}}^{th}$$ instant is r(k+1) - $$\^{y}$$(k+1). Are we going to use this bias value for b(k+2), b(k+3) so on or evaluate in each step?</MESSAGE>
        <SUBJECT>Re: Bias Term</SUBJECT>
        <MESSAGE> Yes, choose the same value for ALL future time instants. The main reason is that you do not know the future noise values. In view of this, the easiest approach is to keep use the b that you KNOW. This simplicity in approach has made this method popular in industry.&lt;br /&gt;&lt;br /&gt;The receding horizon approach, i.e. using only the top row and recalculating every step, is to some extent expected to correct for the above mentioned approximation of keeping b constant.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Bias Term</SUBJECT>
        <MESSAGE> I think bias at (k+1)&lt;sup&gt;th&lt;/sup&gt; instant is y(k+1)-$$ \^ y $$ and not r(k+1)-$$ \^ y $$.&lt;br /&gt;I think it is mentioned in the lecture that the bias at the beginning is used as constant over the horizon so b(k)=b(k+1)=....&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Bias Term</SUBJECT>
        <MESSAGE>Yes, this is the bias term, not what Swaroop mentioned. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Interpretation of "e" being zero </SUBJECT>
        <MESSAGE>If all the elements of &amp;quot;e&amp;quot; are zero, then will it not become MVC / GMVC depending on J ?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Interpretation of "e" being zero </SUBJECT>
        <MESSAGE>There are two major differences:&lt;br /&gt;&lt;br /&gt;
&lt;ol&gt;
  &lt;li&gt;&amp;quot;Measured&amp;quot; data are used in model predictive control to arrive at the control low - this is NOT the case in MVC/GMVC&lt;/li&gt;
  &lt;li&gt;This is done at EVERY step&lt;/li&gt;
&lt;/ol&gt;Because of these differences, the MPC is quite different from MVC/GMVC.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Slide7 Gamma with r</SUBJECT>
        <MESSAGE>As in MVC why Gamma is not considered with r here? </MESSAGE>
        <SUBJECT>Re: Slide7 Gamma with r</SUBJECT>
        <MESSAGE> In MPC, you can EXPLICITLY specify the required r value at EVERY instant. So, the fact that r needs to change only gradually can be easily incorporated. For example, one method to specify r in MPC is $$r(n+k) = (1-\alpha^k)y_{sp}$$, where $$\alpha$$ is a convenient factor in the range 0 to 1. $$y_{sp}$$ is the constant setpoint that needs to be reached eventually. Thus, the setpoint specification is a lot more general in MPC.&lt;br /&gt;&lt;br /&gt;You cannot do this in MVC or GMVC, where you can specify r at only ONE instant, namely at n+k. This is the need to include $$\gamma$$ in MVC/GMVC. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>least square solution to the problem</SUBJECT>
        <MESSAGE>sir in least square solution to the problem the u is equal to del u, del u(n+1) ....til del u(n+Nu) is this Nu same as N </MESSAGE>
        <SUBJECT>Re: least square solution to the problem</SUBJECT>
        <MESSAGE>The generalisation of the horizon $$N$$ as control horizon $$N_u$$ and prediction horizon $$N_y$$ is explained in the answer to your other question.&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>is there error in slide 6</SUBJECT>
        <MESSAGE>in slide 6 the control effort terms the last term is row(del u^2(n+N))^2. sir i think that u^2 is an error also i checked it in the book it should be row(del u(n+N))^2 </MESSAGE>
        <SUBJECT>Re: is there error in slide 6</SUBJECT>
        <MESSAGE>In Eq. 12.4 on page 438, I have used only one N. Later, I generalised it so that there will be separate horizons, Nu and Ny. This is explained in page 442, above example 12.3. The slide corresponds to the generalised situation. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>reason of introducing e not clear</SUBJECT>
        <MESSAGE>sir in the video lecture you had mentioned that if G is tall ie there are more number of equations than unknown we need to introduce e. firstly how is this related to least square? &lt;br /&gt;secondly in the previous lecture we had solved G where it was a square matrix. in that case will we introduce e if G is a square matrix?&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: reason of introducing e not clear</SUBJECT>
        <MESSAGE>In Ax=b, if A is tall, say 5 rows and 3 columns, can we find x so that this equation is exactly satisfied? It is impossible to satisfy this equation almost always.&lt;br /&gt;&lt;br /&gt;We modify this equation as Ax=b+e, where we would want e be zero, but cannot achieve it. Instead, we can minimise $$\sum_i e(i)^2$$. Thus, solving a tall system can conveniently be posed as a least squares problem.&lt;br /&gt;&lt;br /&gt;In real life problems, we will never have a square G. We will have many more data points than the number of parameters.&lt;br /&gt;&lt;br /&gt;About G being square in the last class. See the comment written next to slide 18. It clearly says that the matrix will not be square, in general.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: reason of introducing e not clear</SUBJECT>
        <MESSAGE>We know that error e = y - r. &lt;br /&gt;I think the same equation is written as y-r-e=0 </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Bias Term</SUBJECT>
        <MESSAGE>On what factors does the bias term depends? will it be different at different instants?&lt;br /&gt;and how is it different from error?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Bias Term</SUBJECT>
        <MESSAGE>Bias is supposed to account for modelling inaccuracies and measurement noise. It could vary with time. As it shows the mismatch between the model prediction and the actual value, the bias can also be thought of as the error. The word bias is possibly introduced to distinguish it from the error in tracking the setpoint. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Using the e term in GPC</SUBJECT>
        <MESSAGE>It is not clearly understood why the e term is used?(In slide no 7) </MESSAGE>
        <SUBJECT>Re: Using the e term in GPC</SUBJECT>
        <MESSAGE>This is the only way we can handle nonsquare systems. I have given a detailed answer to Amit's question on the same issue. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>e in slide 7</SUBJECT>
        <MESSAGE>why are we minimizing the e ?&#160;
</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Implementation of u(k) only</SUBJECT>
        <MESSAGE> It was explained in the lecture that values of u at (n+1), (n+2)...(n+N) are calculated only for the purpose of matrix multiplication. In that case we should select N to be minimum, say to form a 2 x 2 matrix and perform the calculations. But it is also mentioned in the lecture that N is of the order of 50. Why are we increasing the number of computations instead of using minimum computations? </MESSAGE>
        <SUBJECT>Re: Implementation of u(k) only</SUBJECT>
        <MESSAGE>The horizons are not selected from the computation point of view. Although computational angle should not be forgotten, important things are issues, such as settling time, time over which control action has to be applied, etc. These considerations usually result in long horizons, such as 50 in slow plants. As I mentioned in another post, even low cost CPUs are now capable of doing fast calculations. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>DMC modeling </SUBJECT>
        <MESSAGE>&lt;br /&gt;The DMC modeling explained in the slide 28 is not clear. Please clarify.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: DMC modeling </SUBJECT>
        <MESSAGE>It is difficult to answer such a general question. It is easier if you have a specific question.&lt;br /&gt;&lt;br /&gt;I suggest that you listen to the video once again also read the book and come back with specific questions.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 27</SUBJECT>
        <MESSAGE>sir it was given that&lt;br /&gt; y&lt;sup&gt;^&lt;/sup&gt;(k + 1) = y&lt;sub&gt;x&lt;/sub&gt;(k + 1) + s(1)delta.u(k) + b(k + 1)&lt;br /&gt;how do we write s(1)deltau(k) term?&lt;br /&gt;&lt;br /&gt;
&lt;div style="text-align: right;"&gt; &lt;/div&gt;</MESSAGE>
        <SUBJECT>Re: slide 27</SUBJECT>
        <MESSAGE>The question is not clear. Please explain. </MESSAGE>
        <SUBJECT>Re: slide 27</SUBJECT>
        <MESSAGE>we got &lt;br /&gt;y^(k + 1) = y&lt;sub&gt;x&lt;/sub&gt;(k + 1) + s(1)delta_u(k) + b(k + 1)&lt;br /&gt;^y(k + 2) = y&lt;sub&gt;x&lt;/sub&gt;(k + 2) + s(2)delta_u(k) + s(1)delta_u(k + 1)+b(k + 2)&lt;br /&gt;&lt;br /&gt;1.did we got second term in above equations from y(n)=s(n)*delta_u(n).&lt;br /&gt;2.i am confused why didn't you include s(0) term ,it is 1(slide 27)&lt;br /&gt;&lt;br /&gt;&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: slide 27</SUBJECT>
        <MESSAGE>
&lt;ol&gt;
  &lt;li&gt;Look at equation 3.38 on page 53. This derivation explains how the $$s\Delta u$$ product comes.&lt;/li&gt;
  &lt;li&gt;What is the meaning of s(0)? This means that response of the system at instant k for an input also at the same instant k, is zero. Is this reasonable? That is if you excite a system with some input will the system respond with ZERO delay or with some nonzero delay? If there is some delay, will there be at least one unit delay in discrete time systems? What happens to s(0) then?&lt;/li&gt;
&lt;/ol&gt;Of course, b is the bias term.&lt;br /&gt; </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1455</ID>
    <LECTURE>28 March. 17 - Post your doubts here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>Variable v (offset) in slide 5</SUBJECT>
        <MESSAGE>in slide no.5 the expression for u(k) has a variable v. In the book you have said that this is an offset. I'm not able to understand its utility. is it used to compensate for some error/tolerance in the control law or is it an additional variable to allow tweaking later?</MESSAGE>
        <SUBJECT>Re: Variable v (offset) in slide 5</SUBJECT>
        <MESSAGE>v is probably used as a setpoint. </MESSAGE>
        <SUBJECT>Re: Variable v (offset) in slide 5</SUBJECT>
        <MESSAGE>I think it is the error in estimation of state .</MESSAGE>
        <SUBJECT>Re: Variable v (offset) in slide 5</SUBJECT>
        <MESSAGE>I think v(k) is input to controller, while u(k) is output of controller acting input to system.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Variable v (offset) in slide 5</SUBJECT>
        <MESSAGE> sir i have the same doubt as to why we are introducing an offset in the control law. i do not agree with the ans given above because.&lt;br /&gt;&lt;br /&gt;set point is required as input to the plant and not to the controller in the feedback &lt;br /&gt;further this is the control law to be used in the feedback and has nothing to do with estimator&lt;br /&gt;&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Variable v (offset) in slide 5</SUBJECT>
        <MESSAGE>We can think of v as the &amp;quot;bias&amp;quot; or the nominal value of u, that is calculated through some other method. &lt;br /&gt;&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Variable v (offset) in slide 5</SUBJECT>
        <MESSAGE>I thought it was some noise in measurement.
Control law = Gain * state. Measurement of that state might have some noise. I may be wrong though</MESSAGE>
        <SUBJECT>Re: Variable v (offset) in slide 5</SUBJECT>
        <MESSAGE>You can also think of v as a generalisation of all these factors: bias/offset, noise, etc. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>controller canonical form</SUBJECT>
        <MESSAGE>why to use controller canonical form ?&lt;br /&gt;except that we can get charecterictic equation just by observation &lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: controller canonical form</SUBJECT>
        <MESSAGE>A controller canonical form assures that all the states of the system are controllable. This in-turn applies that we can straight away use that state feedback to stabilize the system. If any state of the system is not controllable then there is nothing that we can do to stabilize that state, unless that state is stable by itself. </MESSAGE>
        <SUBJECT>Re: controller canonical form</SUBJECT>
        <MESSAGE>If a system can be written in Controller canonical form, it indicates that the given system is controllable and we can place the poles of that system at the desired location.&lt;br /&gt;Rank of controllability matrix is similar method.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: controller canonical form</SUBJECT>
        <MESSAGE> reason is it is easy to get the characteristic equation but more so because we can controll all the states in the controller canonical form. this is in spite of B having all zeros and 1 in the first row, because the A has all the coeficients which are nothing but coupled differential equations.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: controller canonical form</SUBJECT>
        <MESSAGE>The answers given by others are also ok. &lt;br /&gt;&lt;br /&gt;A study of controller canonical form is useful to calculate the control law also for systems that are NOT in in this form, as explained in Slide 19.&lt;br /&gt;&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>ackermann's formula</SUBJECT>
        <MESSAGE>can we modify ackermann's formula for the system having one or more state unavailable for measurement (by state estimation).</MESSAGE>
        <SUBJECT>Re: ackermann's formula</SUBJECT>
        <MESSAGE>Yes, we can. Such an estimator is called observer. It tries to estimate the states of the model using just the output. </MESSAGE>
        <SUBJECT>Re: ackermann's formula</SUBJECT>
        <MESSAGE>i think it is possible to use state estimator if the states of system are not available for measurement.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: ackermann's formula</SUBJECT>
        <MESSAGE>Yes, we can modify formula for the system to measurement, here it estimate the states of the model using output. </MESSAGE>
        <SUBJECT>Re: ackermann's formula</SUBJECT>
        <MESSAGE>yes we can modify ackermann's fomula for the system by state estimation using Observer matrix provide observer matrix is not singular. </MESSAGE>
        <SUBJECT>Re: ackermann's formula</SUBJECT>
        <MESSAGE>Others have already answered this question. Use of observers is covered in the next class. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 12  premultiplication by (en)T</SUBJECT>
        <MESSAGE>What is the purpose of premultiplication by e&lt;sub&gt;n&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt; with the powers of A?&lt;br /&gt;&lt;sub&gt;&lt;br /&gt;&lt;/sub&gt; </MESSAGE>
        <SUBJECT>Re: slide 12  premultiplication by (en)T</SUBJECT>
        <MESSAGE>e&lt;sub&gt;n&lt;/sub&gt;&lt;sup&gt;T &lt;/sup&gt;is a unit vector with 1 in the nth column. to obtain experession for the powers of A we multiply it with e&lt;sub&gt;n&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt; which eliminates A and only unit vector with 1 in the n-1 column remains.&lt;br /&gt;&lt;br /&gt;the requirement of doing all this is that we want to show that when both A and b are in the canonical form then K is given by K=e&lt;sub&gt;n&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt; * alpha_c(A).&lt;br /&gt;&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: slide 12  premultiplication by (en)T</SUBJECT>
        <MESSAGE> In slides 11 and 13, we derived the desired control law in a closed form. It is observed that if we premultiply by $$e_{n}^T$$, we arrive at the desired equation easily. So, we do this. </MESSAGE>
        <SUBJECT>Re: slide 12  premultiplication by (en)T</SUBJECT>
        <MESSAGE>
&lt;p&gt;In evaluating the value of $$ \alpha_c ( A ) $$ we would need to multiply $$ e_{n}^{T} $$ with powers of A&lt;/p&gt;
&lt;p&gt;(&lt;span class="edited"&gt;Edited by &lt;a href="http://moodle.iitb.ac.in/user/view.php?id=8266&amp;course=1557"&gt;Moudgalya Kannan. &lt;/a&gt; - original submission Monday, 28 March 2011, 12:28 PM&lt;/span&gt;)&lt;/p&gt;</MESSAGE>
        <SUBJECT>Re: slide 12  premultiplication by (en)T</SUBJECT>
        <MESSAGE>in slide 13, when we premultiply alpha_c(A) by en_T, the powers of A disappear on the RHS, making calculations easy. This is the use of premultiplication by en_T</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>State feedback in GPC </SUBJECT>
        <MESSAGE>In most of the systems we cannot properly model the matrix A. So we use GPC, GMVC etc. Can the concept of state feedback be extended to such models? (It is noted that such models do not have a concept of an intermediate state, but we can always develop models which can do that.)&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: State feedback in GPC </SUBJECT>
        <MESSAGE>&lt;div style="text-align: left;"&gt;i think the drawback of the feedback controller in state space using gain matrix is that it is not robust (though they are accurate). where as in GMVC we are talking in general about optimization. so i am not sure but in my view the concept of state feedback cannot be extended to such models. &lt;/div&gt;</MESSAGE>
        <SUBJECT>Re: State feedback in GPC </SUBJECT>
        <MESSAGE>Yes, it is possible. In fact, switching between transfer function approach and state feedback approach helps us understand better. We will be doing this by comparing the pole placement control law through state feedback and transfer function approaches. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Slide 5</SUBJECT>
        <MESSAGE>Please clarify in slide 5 how are we getting the expression u(k) = -K x(k) + v(x). And what is v? </MESSAGE>
        <SUBJECT>Re: Slide 5</SUBJECT>
        <MESSAGE>In this what we are doing is feeding the state feedback multiplied by K and any offset if any in the in measurement of state. </MESSAGE>
        <SUBJECT>Re: Slide 5</SUBJECT>
        <MESSAGE>I think v(k) is input to controller, while u(k) is output of controller acting input to system.&lt;br /&gt;&lt;br /&gt;so the controller acts as one block and original system as another block. Both blocks connected gives new system with desired characteristic polynomial, to which we give input as v(k).&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Slide 5</SUBJECT>
        <MESSAGE> the expression u(k) = -K x(k) is the controller to be implemented in the feedback provided we have all the states as the input.latter we need to find K which is a gain matrix. the inclusion of the v part i am also not clear&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Slide 5</SUBJECT>
        <MESSAGE>we are trying to implement a controller which will have a feedback based on the state of the process. And so the term -Kx(k) is basically the state vector multiplied by a gain. The term v is mentioned as an offset term in the book. </MESSAGE>
        <SUBJECT>Re: Slide 5</SUBJECT>
        <MESSAGE> u(k) is control law to be implemented in feedback, if all the input states are measurable. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>multiplying en_T with c_bar</SUBJECT>
        <MESSAGE>it is clear that (en_transpose * A_bar) gives you the last row ie (en-1_transpose) because A_bar is in controller canonical form. using the same analogy it is not clear as to why (en_transpose *C_bar) is equal to (en_transpose) here also C_bar is in the controller canonical form.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: multiplying en_T with c_bar</SUBJECT>
        <MESSAGE>&lt;span style="color: rgb(255, 0, 0);"&gt;I have said this many times. Let me repeat again. Please specify the slide that you are referring to do. I have to spend quite a bit of time trying to guess the slide that you may have in mind. This comment is applicable to all of you and not only for today's class but also for future classes.&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;Can you please calculate C_bar and tell me what it looks like? What does the last row of C_bar look like?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: multiplying en_T with c_bar</SUBJECT>
        <MESSAGE>Multiplying with (e&lt;sub&gt;n&lt;/sub&gt;)&lt;sup&gt;T &lt;/sup&gt; to any matrix gives the last row of that matrix, here in case of C_bar if you solve for C_bar last row is looks like (e&lt;sub&gt;n&lt;/sub&gt;)&lt;sup&gt;T &lt;/sup&gt; . </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>state feedback</SUBJECT>
        <MESSAGE>First doubt, In the state feedback ,are we feeding all the state or only those which can measured.

Second ,then what about those state which cannot be measured and  also if they  happen to be uncontrollable.</MESSAGE>
        <SUBJECT>Re: state feedback</SUBJECT>
        <MESSAGE> In Slide 3, it is assumed that all states are measured..&lt;br /&gt;&lt;br /&gt;Also we are doing check for controlability by writing system in controller canonical form. If a system cannot be written in that form, it has at-least one state that is not controllable.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: state feedback</SUBJECT>
        <MESSAGE> now the answere depends as to which part of the video lecture or slide you are referring to.&lt;br /&gt; in the first part we assume that the A and b are in the controller canonical form and also we have all the state as feedback .&lt;br /&gt;in the last part we show what if A and b are not in controller canonical form &lt;br /&gt;if we do not have all the state as feedback we estimate them using observer&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: state feedback</SUBJECT>
        <MESSAGE>In this lecture, we assume that all states are measured. The case of not measuring all the states is covered in the next class. </MESSAGE>
        <SUBJECT>Re: state feedback</SUBJECT>
        <MESSAGE>in state feedback all state should be measurable.&lt;br /&gt;we can state observer for those state which are not measurable.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Model</SUBJECT>
        <MESSAGE>usually we write SS model as &lt;br /&gt;x(k+1)= Ax(k) + b u(k)&lt;br /&gt;&lt;br /&gt;what is extra term X0 Del(k+1) indicate?&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Model</SUBJECT>
        <MESSAGE>this term X0 Del(k+1) include to help us take z-transform of the state space equation. because z-transform is defined form limit -inf to +inf but the state space model is not defined for n&amp;lt;0 hence the introduction of the last term. </MESSAGE>
        <SUBJECT>Re: Model</SUBJECT>
        <MESSAGE>Its is the initial state if x </MESSAGE>
        <SUBJECT>Re: Model</SUBJECT>
        <MESSAGE>I can agree x0 is initial state, but why is it multiplied with del(k&lt;span style="font-weight: bold;"&gt;+&lt;/span&gt;1)?&lt;br /&gt;&lt;br /&gt;what does future impulse function has to do with it?&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Model</SUBJECT>
        <MESSAGE>If initial condition is non zero we have to consider this extra term. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Matrix M?</SUBJECT>
        <MESSAGE>How to get value of matrix 'M' mathematically, although it is not used? </MESSAGE>
        <SUBJECT>Re: Matrix M?</SUBJECT>
        <MESSAGE>M is a matrix used in matrix algebra for similarity transformation and it can be calculated mathematically&lt;br /&gt;&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Matrix M?</SUBJECT>
        <MESSAGE>M=C*W&lt;br /&gt;&lt;br /&gt;where C=[B AB A^2*B ....... (A^(n-1))*B ]&lt;br /&gt;&lt;br /&gt;and matrix W=&lt;br /&gt;&lt;br /&gt;a.n-1 a.n-2 ...... a.1 1&lt;br /&gt;a.n-2 a.n-3 ...... 1 0&lt;br /&gt; . . . .&lt;br /&gt; . . . .&lt;br /&gt; . . . .&lt;br /&gt; . . . .&lt;br /&gt;a.1 1 ........ 0 0&lt;br /&gt; 1 0 ........ 0 0&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Reference: Discrete Time Control System (2nd edition), Ogata, Page 396.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Matrix M?</SUBJECT>
        <MESSAGE>As explained in the video, matrix M need not be calculated at all. If you really want to calculate (possibly to get a feel for what it looks like, etc.), you can use the last equation in Slide 18. </MESSAGE>
        <SUBJECT>Re: Matrix M?</SUBJECT>
        <MESSAGE> to find the entries of M we need to first calculate the eigen values of [sI-A].&lt;br /&gt;after that find corresponding eigen vectors(let say v&lt;sub&gt;1&lt;/sub&gt; v&lt;sub&gt;2 &lt;/sub&gt;v&lt;sub&gt;3&lt;/sub&gt;) for each eigen values ,then&lt;br /&gt;M=[v&lt;sub&gt;1&lt;/sub&gt; v&lt;sub&gt;2 &lt;/sub&gt;v&lt;sub&gt;3&lt;/sub&gt;]&lt;br /&gt;&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Ackermann&#8217;s Formula</SUBJECT>
        <MESSAGE>please clarify in ackermann&#8217;s formula why we use the using the premultiplication by e&lt;sub&gt;n&lt;/sub&gt;&lt;sup&gt;T&lt;/sup&gt; with the powers A. </MESSAGE>
        <SUBJECT>Re: Ackermann&#8217;s Formula</SUBJECT>
        <MESSAGE>I gave the following answer, to the post made by Prafulla:&lt;br /&gt;&lt;br /&gt;
&lt;table cellspacing="0" class="forumpost"&gt;&lt;tbody&gt;
  &lt;tr class="header"&gt;
    &lt;td class="topic"&gt;&lt;br /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td class="left side"&gt;&lt;br /&gt;
    &lt;/td&gt;
    &lt;td class="content"&gt;
      &lt;div class="posting"&gt; In slides 11 and 13, we derived the desired control law in a closed form. It is observed that if we premultiply by &lt;a onclick="function onclick(event) { return openpopup("/filter/tex/displaytex.php?e_%7Bn%7D%5ET", "popup", "menubar=0,location=0,scrollbars,resizable,width=300,height=240", 0); }" href="../../filter/tex/displaytex.php?e_%7Bn%7D%5ET" title="TeX" target="popup"&gt;&lt;img src="../../filter/tex/pix.php/8af654bb706be1ad24db5a1f41c86b45.png" alt="e_{n}^T" title="e_{n}^T" class="texrender" /&gt;&lt;/a&gt;, we arrive at the desired equation easily. So, we do this. &lt;/div&gt;
    &lt;/td&gt;
  &lt;/tr&gt;&lt;/tbody&gt;
&lt;/table&gt;&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 14 using M</SUBJECT>
        <MESSAGE>does using M affect the characteristic equation of the closed loop system </MESSAGE>
        <SUBJECT>Re: slide 14 using M</SUBJECT>
        <MESSAGE>No it does not affect.pl refer slide 17.</MESSAGE>
        <SUBJECT>Re: slide 14 using M</SUBJECT>
        <MESSAGE>M is not actually introduced in practical system. It is just used to represent a given system in controllable canonical form. So the characteristic equation of the closed loop system will remain same.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: slide 14 using M</SUBJECT>
        <MESSAGE>The answer by Surinder Kumar is correct. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>alternate methods for finding K</SUBJECT>
        <MESSAGE>are there other methods for finding gain matrix K than ackermann's formula </MESSAGE>
        <SUBJECT>Re: alternate methods for finding K</SUBJECT>
        <MESSAGE> there are total 4 methods to find K, however, Ackerman's method is simplest.&lt;br /&gt;&lt;br /&gt;Other methods are given in Discrete Time Control System (2nd edition), Ogata, Page 412. </MESSAGE>
        <SUBJECT>Re: alternate methods for finding K</SUBJECT>
        <MESSAGE>there are 3 methods including ackermann's formula.&lt;br /&gt;method 1:&lt;br /&gt;find the charecteristic equation for I sI-A I&lt;br /&gt;and then compare the coefficient of desired characteristic equation.&lt;br /&gt;K = [subtraction of respective coefficint]M&lt;sup&gt;-1&lt;/sup&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;method 2:&lt;br /&gt;let K=[k&lt;sub&gt;1 &lt;/sub&gt;k&lt;sub&gt;2 &lt;/sub&gt;k&lt;sub&gt;3&lt;/sub&gt;]&lt;br /&gt;and equate I sI - A + BK I with the desired characteristic equation&lt;br /&gt;&lt;br /&gt;method 3: ackermann's formula&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Finding K</SUBJECT>
        <MESSAGE>We have seen that $$ K = e_{n}^{T} \alpha_e ( A ) $$. This involves evaluating the higher order terms of A like $$ A^2, A^3, .... $$ Isn't this a computationally costly process. Do we have any better methods for this?</MESSAGE>
        <SUBJECT>Re: Finding K</SUBJECT>
        <MESSAGE>there are total 4 methods to find K, however, Ackerman's method is simplest.&lt;br /&gt;&lt;br /&gt;Other methods are given in Discrete Time Control System (2nd edition), Ogata, Page 412 </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>PID Controller</SUBJECT>
        <MESSAGE>We have seen in our control law, we took gains K. Is it like, if we wish to implement a PID controller, we would keep changing these gains ($$ K_1, K_2, ...$$) for every time step?</MESSAGE>
        <SUBJECT>Re: PID Controller</SUBJECT>
        <MESSAGE> i think no,changing K in PID will not have affect on eigen value.&lt;br /&gt;&lt;br /&gt;&lt;a href="http://en.wikipedia.org/wiki/Closed-loop_pole" title="Closed-loop pole"&gt;&lt;/a&gt; </MESSAGE>
        <SUBJECT>Re: PID Controller</SUBJECT>
        <MESSAGE>No! What I meant was, during the implementation of PID Controller, we have Kp, Kd and Ki. In previous lectures, we have seen that,

Control Law = (Kp* error)  +  (Kd * derivative of the error)  +  (Ki * error * Ts)

Here we just considered K as our gain.
So, during our implementation, are we going to update K like

K = Kp + (Kd*derivative of state at that instant/state at that instant) + (Ki*Ts) ?</MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1456</ID>
    <LECTURE>31 March. 18 - Post your doubts here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>slide 18</SUBJECT>
        <MESSAGE>sir will you please explain block diagram in slide 18. </MESSAGE>
        <SUBJECT>Re: slide 18</SUBJECT>
        <MESSAGE> Let us start from the top left hand corner block that represents the plant, and go clockwise. The plant gives the output as $$x(k)$$. The sensor measures only $$y(k)$$. The estimator has two inputs, namely, $$y(k)$$ and $$u(k)$$. The output from the estimator is an estimate of the state, denoted as $$\overline x(k)$$. &lt;br /&gt;&lt;br /&gt;The control law requires the complete state information, $$x(k)$$. Unfortunately, the states are not available, but an estimate of them, namely $$\overline x(k)$$, is available. So, the control law uses $$\overline x(k)$$, in the place of $$x(k)$$. &lt;br /&gt;&lt;br /&gt;The system enclosed by dotted lines takes $$y(k)$$ as its input and $$u(k)$$ as the output, just as a conventional controller does. The transfer function between $$y(k)$$ and $$u(k)$$ is then the transfer function of an equivalent conventional controller.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: slide 18</SUBJECT>
        <MESSAGE>in slide 18, plant is to be controlled. Originally control law &amp;quot;-K&amp;quot; was used to control it. control law block took state values from the output of the system and law &amp;quot;-K x(k)&amp;quot; was given to input as feedback.&lt;br /&gt;However, if the states are not available directly, we are using an estimator in feedback, just before the control law block, which takes the values from u(k) and y(k) and gives x_bar(k) to control law block.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: slide 18</SUBJECT>
        <MESSAGE>the diagram will be clear if we look at the equation of estimated state from slide 28 </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Existance of M matrix </SUBJECT>
        <MESSAGE>Sir, is it correct to say that the only condition required for M to exist, is the non-singularity of C.&lt;br /&gt;&lt;br /&gt;If so, I did not understand what does the non-singularity of C stand for. &lt;br /&gt;(I am looking for a physical interpretation, for example: when solving linear equations the singularity of the A in Ax = b means that not enough information is available.) &lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Existance of M matrix </SUBJECT>
        <MESSAGE>Yes, it is correct to say that the only condition required for M to exist, is the non-singularity of C.&lt;br /&gt;&lt;br /&gt;Reason:&lt;br /&gt;&lt;br /&gt;if rank C &amp;lt; n&lt;br /&gt;i.e.&lt;br /&gt;&lt;br /&gt;rank [ b Ab (A^2)b........] &amp;lt; n&lt;br /&gt;&lt;br /&gt;vectors b, Ab, (A^2)b cannot span the n dimensional space, i.e. atleast for one state, we cannot find unbounded control signals u(0), u(k), u(k+1), etc&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Existance of M matrix </SUBJECT>
        <MESSAGE>C is controllability matrix.&lt;br /&gt; controllability describes the ability of an external input to move the internal state of a system from any initial state to any other final state in a finite time interval.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Existance of M matrix </SUBJECT>
        <MESSAGE>Yes, that is what I mean: when the control effort u is a scalar, as we have now, nonsingularity of $$\cal C$$ is the necessary and sufficient condition to reach any other part of the state space.&lt;br /&gt;&lt;br /&gt;In other words, when $$\cal C$$ is nonsingular, we can reach any point in the state space. If it is singular, there will be some points in the state space that we cannot reach.&lt;br /&gt;&lt;br /&gt;Mathematically to be correct, however, we should not use the word &amp;quot;singularity&amp;quot;, as this is applicable only to square systems. Whatever we have discussed is applicable also for nonsquare systems that result when the input u can be a vector of more than one component. In this case, we can use the word &amp;quot;rank&amp;quot;, as opposed to singularity. When the $$\cal C$$ has full rank, we can reach any point and otherwise, cannot.&lt;br /&gt;&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Existance of M matrix </SUBJECT>
        <MESSAGE>yes, its correct because here C is controlability matrix. here if C is nonsingular, we can reach any point in the state space. If it is singular, we cannot reach some points in the state space . </MESSAGE>
        <SUBJECT>Re: Existance of M matrix </SUBJECT>
        <MESSAGE>I have a similar doubt!</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 18</SUBJECT>
        <MESSAGE> sir in block diagram what is X(k). Is this a control law then here all the states are available to estimate. </MESSAGE>
        <SUBJECT>Re: slide 18</SUBJECT>
        <MESSAGE>It is not X(k) - no capital letter - it is x(k). It denotes the state. Please see the detailed reply that I have given to the question of Jagdish, where he has asked me to explain slide 18. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Order of observer</SUBJECT>
        <MESSAGE>what is meant by order of the observe? </MESSAGE>
        <SUBJECT>Re: Order of observer</SUBJECT>
        <MESSAGE>we can say that order of observer implies how many states are we measuring.&lt;br /&gt;Full order observer reconstructs all the states , while minimum order observers reconstruct only those states that are not measured.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: Order of observer</SUBJECT>
        <MESSAGE>In which slide? </MESSAGE>
        <SUBJECT>Re: Order of observer</SUBJECT>
        <MESSAGE>The answer by Jagdish is correct. The number of states reconstructed also shows up the degree of the characteristic polynomial of the observer/estimator. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Estimator design</SUBJECT>
        <MESSAGE>Why the first approach to the estimator design is unsuccessful? </MESSAGE>
        <SUBJECT>Re: Estimator design</SUBJECT>
        <MESSAGE>Its like an open loop estimator, so the errors might crop up. </MESSAGE>
        <SUBJECT>Re: Estimator design</SUBJECT>
        <MESSAGE>Yes, the answer given by Prasanna is correct. This estimator is improved by giving a feedback of the error. </MESSAGE>
        <SUBJECT>Re: Estimator design</SUBJECT>
        <MESSAGE>Because error dynamics governed by eigenvalues of A only so if eigenvalues are outside unit circle error goes to infinity. </MESSAGE>
        <SUBJECT>Re: Estimator design</SUBJECT>
        <MESSAGE>Probably because error dynamics are governed by eigenvalues of A only. if outside unit circle, error will go to infinity.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Estimator design</SUBJECT>
        <MESSAGE>Because the error dynamics depended only on the eigen values of A </MESSAGE>
        <SUBJECT>Re: Estimator design</SUBJECT>
        <MESSAGE>Because the error keeps diverging if the plant is unstable in open loop</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Meaning of observer</SUBJECT>
        <MESSAGE>&lt;span style="font-weight: bold;"&gt;I have doubt about the physical meaning of observability. As far as I understand, its the property which couples the output of the system y to all the states. In other words if I see a change in any of the states, I will see a change in y. Is that right?&lt;br /&gt;&lt;/span&gt; </MESSAGE>
        <SUBJECT>Re: Meaning of observer</SUBJECT>
        <MESSAGE>No, the word observer denotes a mathematical device that helps &amp;quot;observe&amp;quot; the states. The observer helps &amp;quot;reconstruct&amp;quot; states that are asymptotically correct. We use the reconstructed states in the place of states, when all the states are not measured. </MESSAGE>
        <SUBJECT>Re: Meaning of observer</SUBJECT>
        <MESSAGE> if the system is observable, the current state can be determined in finite time using only the outputs. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Controllability and Matrix b</SUBJECT>
        <MESSAGE>I have 2 doubts :

1)  Is it always that, if my matrix C is non - singular, my system is uncontrollable? If so, how do I prove it mathematically?


2)  In one case, when we took b = [0 1], we got the system is controllable, but when b = [1 0], it wasn't. What exactly are we changing by changing b?</MESSAGE>
        <SUBJECT>Re: Controllability and Matrix b</SUBJECT>
        <MESSAGE>&lt;ol&gt; 
  &lt;li&gt;It can be proved mathematically. Please see the book, &amp;quot;Linear optimal control systems&amp;quot; by H. Kwakernaak and R. Sivan.&lt;/li&gt; 
  &lt;li&gt;when we use $$b = \begin{bmatrix}0 &amp;amp; 1 \end{bmatrix}$$, we use the second state for control, while $$b = \begin{bmatrix}1 &amp;amp; 0 \end{bmatrix}$$ says that we are using the first state for control.&lt;br /&gt;&lt;/li&gt; 
&lt;/ol&gt; </MESSAGE>
        <SUBJECT>Re: Controllability and Matrix b</SUBJECT>
        <MESSAGE> 1) If C is non singular, M will cease to exist&lt;br /&gt;2) Controllability is governed by both A and b. In the example referred to A is such that changing b from [0 1] to [1 0] makes it not controllable&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 26 alpha e</SUBJECT>
        <MESSAGE>What is the difference between (alpha)&lt;sub&gt;c &lt;/sub&gt;and (alpha)&lt;sub&gt;e &lt;/sub&gt;? and how to calculate (alpha)&lt;sub&gt;e &lt;/sub&gt;? </MESSAGE>
        <SUBJECT>Re: slide 26 alpha e</SUBJECT>
        <MESSAGE>$$\alpha$$ stands for the desired characteristic polynomial. The subscript c denotes controller and e stands for the estimator. &lt;br /&gt;&lt;br /&gt;Recall that given rise time, overshoot, etc., we found the desired characteristic polynomial in transfer function based pole placement design. This is one way to arrive at the desired $$\alpha$$. One can also directly specify the roots of the characteristic polynomial. &lt;br /&gt;&lt;br /&gt;The observer should respond faster the controller. This is another fact that is used to come up with $$\alpha$$.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: slide 26 alpha e</SUBJECT>
        <MESSAGE>$$\alpha_C( A ) $$ is found by substituting matrix A in place of z, which is obtained by finding the closed loop characteristic polynomial with the required eigen value locations, where is $$\alpha_e( A )$$ corresponds to characteristic polynomial obtained by the required eigen value location for $$L_p$$.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>ackermann's fomula </SUBJECT>
        <MESSAGE>sir how can we modify ackermann's fomula for the system by state estimation using Observer matrix . </MESSAGE>
        <SUBJECT>Re: ackermann's fomula </SUBJECT>
        <MESSAGE>You have to bring the estimation problem to the same format as the regulation problem, i.e. unknowns in identical location, etc. This is achieved by the transpose operation. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Effect of K matrix on controllability </SUBJECT>
        <MESSAGE>Regarding controllabilty, suppose we alter the values of A in slide 14.


Suppose we take A = [0 2;0 3]  b = [0 1] and K1 = 0 K2 = 1

In this case C is non singular and so the system should be controllable. However, the state of x1 will depend only on x2. Isnt it possible that x1 becomes unbounded as the state of x1 is never fed back.</MESSAGE>
        <SUBJECT>Re: Effect of K matrix on controllability </SUBJECT>
        <MESSAGE>x1 depends on x2, but x2 depends on u since b=[0 1], therefore both the states are affected by the control effort </MESSAGE>
        <SUBJECT>Re: Effect of K matrix on controllability </SUBJECT>
        <MESSAGE>In other words, the use of $$u$$ helps control $$x_2$$. Now, $$x_1$$ gets regulated by $$x_2$$. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Physical meaning of M </SUBJECT>
        <MESSAGE>Is there any physical meaning for M matrix or its only implication is to find the gain matrix?&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Physical meaning of M </SUBJECT>
        <MESSAGE>M is a similarity transformation matrix. It helps look at the vectors in a particular angle, etc. This is a standard tool in linear algebra. Any textbook in linear algebra will explain similarity transformation. A good textbook is &amp;quot;Linear algebra and its applications&amp;quot; by Gilbert Strang, available in Indian Edition. </MESSAGE>
        <SUBJECT>Re: Physical meaning of M </SUBJECT>
        <MESSAGE>M can be interpreted as the transformation matrix from non CC form to CC form.</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Observer &amp; Predictive control</SUBJECT>
        <MESSAGE>In both observer and predictive control we are estimating the states i.e we are getting $$ \^ x $$ . Is there any similarity in between them? </MESSAGE>
        <SUBJECT>Re: Observer &amp; Predictive control</SUBJECT>
        <MESSAGE> The symbol $$\hat .$$ is used to denote estimates. &lt;br /&gt;&lt;br /&gt;In predictive control, we estimate the output, while in the observer, we estimate the states.&lt;br /&gt;&lt;br /&gt;The observer is deterministic. As predictive control works with random signals, the underlying signal is also random. In other words, here $$\hat x$$ is an estimate of a random variable. There is also the difference of using a receding horizon approach in predictive control, but not in observers. Thus, there are differences.&lt;br /&gt;&lt;br /&gt;When it is posed as the minimisation of the expected value of some random signals, the observer becomes Kalman filter or estimator. Even this does not have receding horizon approach.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt; </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1459</ID>
    <LECTURE>7 April. 19- Post your doubts here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>slide 11 dimensions of matrix A</SUBJECT>
        <MESSAGE>If A is 2*2 matrix we can split A into [Aaa Aab,Aba Abb], what if dimensions are different than 2*2(for ex. 3*3)? </MESSAGE>
        <SUBJECT>Re: slide 11 dimensions of matrix A</SUBJECT>
        <MESSAGE>A is not a simple 2x2 matrix. It is a 2x2 BLOCK matrix. In other words, every one of its entries, namely $$A_{aa}$$, $$A_{ab}$$, $$A_{ba}$$ and $$A_{bb}$$, itself is a matrix. The dimensions of these entries can be different, depending on the problem. Thus A can always be a 2x2 block matrix.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: slide 11 dimensions of matrix A</SUBJECT>
        <MESSAGE>Aaa Aab,Aba Abb are not scalers. they are matrices itself. Their dimension depends upon number of known states and number of estimated states. </MESSAGE>
        <SUBJECT>Re: slide 11 dimensions of matrix A</SUBJECT>
        <MESSAGE> whatever may be the dimension of A we can split it into [Aaa Aab,Aba Abb],only the dimension of Aaa,Aab,Aba,Abb will change according to no. of measured and unmeasured state.&lt;br /&gt;&lt;br /&gt;suppose that state x&lt;sub&gt;1 &lt;/sub&gt;,x&lt;sub&gt;2 &lt;/sub&gt;are measured&lt;br /&gt;then dimension of Aaa,Aab,Aba,Abb are &lt;br /&gt;Aaa=2 X 2&lt;br /&gt;Aab=2 x 1&lt;br /&gt;Aba=1 x 2&lt;br /&gt;Abb 1 x 1&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Deadbeat</SUBJECT>
        <MESSAGE>What is deadbeat estimator? </MESSAGE>
        <SUBJECT>Re: Deadbeat</SUBJECT>
        <MESSAGE>This is the fastest estimator possible. It has all its eigenvalues at the origin. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 12</SUBJECT>
        <MESSAGE>sir let say matrix A is 3 x 3 and state x&lt;sub&gt;1 &lt;/sub&gt;,x&lt;sub&gt;2 &lt;/sub&gt;are measured&lt;br /&gt;then dimension of Aaa,Aab,Aba,Abb are &lt;br /&gt;Aaa=2 X 2&lt;br /&gt;Aab=2 x 1&lt;br /&gt;Aba=1 x 2&lt;br /&gt;Abb 1 x 1&lt;br /&gt; &lt;br /&gt;&lt;br /&gt;if analysis is right then how can we write &lt;br /&gt;Aab = C ?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: slide 12</SUBJECT>
        <MESSAGE>I am not saying that $$A_{ab}=C$$. I am simply comparing the blue equation with the output equation of the full order estimator, given by $$y = Cx$$ and identifying SIMILAR terms. </MESSAGE>
        <SUBJECT>Re: slide 12</SUBJECT>
        <MESSAGE>but sir still i am not getting.&lt;br /&gt;you had replace Aab with C in last equation on slide 13.&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: slide 12</SUBJECT>
        <MESSAGE>one more doubt sir how can we multiply L&lt;sub&gt;p&lt;/sub&gt; with C </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>doubt on page 506 in the book</SUBJECT>
        <MESSAGE>On page 506, para below equation 14.57. it is not undrstood how we have to deal with larger dimension system if we are not measuring the state of the system </MESSAGE>
        <SUBJECT>Re: doubt on page 506 in the book</SUBJECT>
        <MESSAGE>If we measure all the states, we will get a proportional controller (order 0) using the formula $$u = -Kx(k)$$. If we estimate even one state, we will get a dynamic controller, see Slide 27 - this is a first order controller. Thus, the order of the controller goes up when we estimate a state. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>matrix multiplication of Lp and C in slide 9</SUBJECT>
        <MESSAGE>it is not clear how is the matrix multiplication taking place in slide 9 between Lp and c as both are column matix shouldn't the c be c transpose. </MESSAGE>
        <SUBJECT>Re: matrix multiplication of Lp and C in slide 9</SUBJECT>
        <MESSAGE>I have made a mistake in this slide. Can you please find it out - all that you have to do is to identify the dimensions of each of these entries from the previous slides. </MESSAGE>
        <SUBJECT>Re: matrix multiplication of Lp and C in slide 9</SUBJECT>
        <MESSAGE>c is usually a row matrix.&lt;br /&gt;Its probably a mistake in representation of output matrix c.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: matrix multiplication of Lp and C in slide 9</SUBJECT>
        <MESSAGE>C is a row matrix as can be seen in slide 7. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Reduced order estimator</SUBJECT>
        <MESSAGE>What is the basis to compare the equation containing Aaa,Aab,Aba,Abb with the state and output equations as it is explained in slide 12 and 13. </MESSAGE>
        <SUBJECT>Re: Reduced order estimator</SUBJECT>
        <MESSAGE>Analogy is an easy method. It is possible to derive the same through more rigorous, but tedious, methods. </MESSAGE>
        <SUBJECT>Re: Reduced order estimator</SUBJECT>
        <MESSAGE>The equations are similar in structure, hence the terms can be compared </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Order of controller</SUBJECT>
        <MESSAGE>Sir it has  been mentioned in the lecture that there is a difference in the order of controller we get from state space approach and polynomial approach. 
Pl amplify it further . I have understood it completely.</MESSAGE>
        <SUBJECT>Re: Order of controller</SUBJECT>
        <MESSAGE>Did I say this in connection with the full order observer and polynomial approach? If so, the reason is obvious. The polynomial approach is equivalent to a reduced order estimator. </MESSAGE>
        <SUBJECT>Re: Order of controller</SUBJECT>
        <MESSAGE>Sir it has been mentioned in the lecture that there is a difference in the order of controller we get from state space approach and polynomial approach. 

Pl amplify it further .I haven't understood it completely.</MESSAGE>
        <SUBJECT>Re: Order of controller</SUBJECT>
        <MESSAGE> Polynomial approach gives results same as reduced order estimator as shown in the example at the end of the lecture&lt;br /&gt;</MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Initial Guess</SUBJECT>
        <MESSAGE>The estimator needs an initial guess. Can we just give any value to the estimator?</MESSAGE>
        <SUBJECT>Re: Initial Guess</SUBJECT>
        <MESSAGE>I suppose estimator doesn't need any initial guess. it estimates the value based upon known parameters only.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Initial Guess</SUBJECT>
        <MESSAGE>You need to guess the initial state, not the estimator. Not measuring all the states is equivalent to not knowing the initial state exactly. </MESSAGE>
        <SUBJECT>Re: Initial Guess</SUBJECT>
        <MESSAGE>No initial guess is required </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 13</SUBJECT>
        <MESSAGE>What is the difference between x bar of (k+1) and x hat of (k+1)? </MESSAGE>
        <SUBJECT>Re: slide 13</SUBJECT>
        <MESSAGE>I suppose there is no difference. </MESSAGE>
        <SUBJECT>Re: slide 13</SUBJECT>
        <MESSAGE>$$\overline x$$ is the FULL order estimator. $$\hat x$$ is the REDUCED order estimator. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Magnetically suspended ball</SUBJECT>
        <MESSAGE>The magnetically suspended ball has an A matrix which is 3x3, but its t/f comes out as a second order. This is due to some pole zero cancellation. It completely depends on A matrix. However in the video, some other explanation was given.This was not clearly understood.&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Magnetically suspended ball</SUBJECT>
        <MESSAGE>In the magnetically suspended ball one state (out of three) is being measured therefore the other two need to be estimated, therefore second order </MESSAGE>
        <SUBJECT>Re: Magnetically suspended ball</SUBJECT>
        <MESSAGE>The answer by Vivek is correct. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 12</SUBJECT>
        <MESSAGE>1.sir i couldn't understand this reduced order estimatorin this slide.&lt;br /&gt;&lt;br /&gt;2. I slide 13 what is x hat (k + 1).&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: slide 12</SUBJECT>
        <MESSAGE>&lt;ol&gt; 
  &lt;li&gt;What is not clear?&lt;/li&gt; 
  &lt;li&gt;It is the reduced order estimator. It gives an estimate of unmeasured states. &lt;br /&gt;&lt;/li&gt; 
&lt;/ol&gt; </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
  <DISCUSSION>
    <ID>1461</ID>
    <LECTURE>11 April. 20 - Post your doubts here</LECTURE>
    <POSTS>
      <POST>
        <SUBJECT>slide 4 Implementaion of PID</SUBJECT>
        <MESSAGE>Can we implement PID control law u(k) = [Kp Ki Kd]X(k)? </MESSAGE>
        <SUBJECT>Re: slide 4 Implementaion of PID</SUBJECT>
        <MESSAGE>In the slide, I have shown how to implement a PI control law. It should be possible to implement a PID control law as well. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 10  value of N</SUBJECT>
        <MESSAGE>What is the criteria or method to decide exact value of N? </MESSAGE>
        <SUBJECT>Re: slide 10  value of N</SUBJECT>
        <MESSAGE>N should be chosen large. Any larger value should not change the results much. Settling time of the plant is the first guess. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 36 expression for J'</SUBJECT>
        <MESSAGE>How to arrive at third step from second not clear?&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: slide 36 expression for J'</SUBJECT>
        <MESSAGE>If you expand the summation and add, the intermediate terms cancel each other. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>two boundary problem slide 15</SUBJECT>
        <MESSAGE>What is the Two Point Boundary Value Problem? </MESSAGE>
        <SUBJECT>Re: two boundary problem slide 15</SUBJECT>
        <MESSAGE>This is usually a second order problem that requires two conditions to solve. If both are specified at one end of the interval, we call it an initial value problem (IVP). The IVPs are easier to solve than a boundary value problem (BVP). &lt;br /&gt;&lt;br /&gt;The BVPs have two conditions specified at two ends of the interval. These problems are usually solved by trial and error: make a guess of the second condition at the beginning of an interval and solve the system. When you reach the end of the interval, check if the second given condition matches the calculated value. If not, make a new guess and repeat.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>lagrange multiplier</SUBJECT>
        <MESSAGE>Sir could you pl explain as to why we choose lagrange multiplier as lamda(k+1) and not lamda(k) </MESSAGE>
        <SUBJECT>Re: lagrange multiplier</SUBJECT>
        <MESSAGE>It makes the notation simpler. This choice results in $$\lambda(N)=Q_1x(N)$$. The change that you have suggested will result in a slightly different equation. That's all. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 27 LQR formulation</SUBJECT>
        <MESSAGE>sir, could you please explain the partial of J' w r t x </MESSAGE>
        <SUBJECT>Re: slide 27 LQR formulation</SUBJECT>
        <MESSAGE>Please see the appendix in the book. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>behavior of sys with LQR</SUBJECT>
        <MESSAGE>sir &lt;br /&gt;could you pl explain what could be the behaviour of the system with controller designed using LQR optimization and how is it different from pole placement controller&lt;br /&gt; </MESSAGE>
        <SUBJECT>Re: behavior of sys with LQR</SUBJECT>
        <MESSAGE> In the LQR method, we need not give the pole locations. This may be difficult to do. On the other hand, it may be easier to specify the weighting matrices $$Q_1$$ and $$Q_2$$. &lt;br /&gt;&lt;br /&gt;This method also gives a method of tuning: if any component of a state is much larger than acceptable value, make the corresponding component of the weighting factor larger. A similar thing can be done when any component of the control effort becomes larger.&lt;br /&gt;&lt;br /&gt;In pole placement, the pole locations have to be specified exactly. It may not be obvious to choose them. Recall that in the transfer function based approach to pole placement also, we did not specify the pole locations directly. We indirectly specified them through performance requirements.&lt;br /&gt;&lt;br /&gt;Finally, it is not clear how to choose the pole locations as a tuning parameter.&lt;br /&gt;&lt;br /&gt;Nevertheless, the two methods are equivalent in the sense that for every LQR formulation, there is an equivalent pole placement problem and vice versa.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>LQR and noise</SUBJECT>
        <MESSAGE>can a LQR optimization based controller can take care of noise and if it is yes will it be included in the term multiplied by lagrange multiplier </MESSAGE>
        <SUBJECT>Re: LQR and noise</SUBJECT>
        <MESSAGE>This becomes an LQG controller. This involves Kalman filter, that estimates a state, while minimising the expected value of some random variable. The combination of Kalman filter and state feedback controller results in LQG controller. Chapter 13 derives this in transfer function setting. </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Linearity at all sampling instants</SUBJECT>
        <MESSAGE>In sec 14.42 of the book the concept of linearity at all sampling instants is not understood</MESSAGE>
        <SUBJECT>Re: Linearity at all sampling instants</SUBJECT>
        <MESSAGE> This refers to $$\lambda(N)=Q_1x(N)$$, where, $$N$$ was arbitrarily chosen. As a result, such an equation is guessed for EVERY sampling instant. In other words, we do not have $$x^2(k)$$ and $$\sqrt{x(k+1)}$$, etc. Linearity refers to the power of $$x$$ being 1.&lt;br /&gt;&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Doubt in equation 14.70</SUBJECT>
        <MESSAGE>In the book on pg 509, equation 14.74. it is not understood how $$\lambda(N+1)=0$$ satisfies equation 14.70</MESSAGE>
        <SUBJECT>Re: Doubt in equation 14.70</SUBJECT>
        <MESSAGE>This is based on the assumption that $$u$$ is zero at that instant. The logic is that if $$u$$ is not zero, then there will be changes in $$x$$. In which case, we would have chosen $$N$$ much larger. &lt;br /&gt;&lt;br /&gt;$$N$$ is chosen large enough to make $$x$$ zero. As a result, $$u$$ is zero. If $$u$$ is not zero, $$x$$ will not be zero.&lt;br /&gt;&lt;br /&gt;This suggests a way to choose $$N$$.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>Dead Beat Controller</SUBJECT>
        <MESSAGE>In the lecture video (at 45 mins from the start) it is mentioned that, for continyous time system, the result is obtained in no time, but for discrete time systems, it depends on the dimension of x, i.e., if we have 3 states, it takes 3 times the sampling time. This is not clearly understood why. Is it due to the computational time requirement, or what?&lt;br /&gt;</MESSAGE>
        <SUBJECT>Re: Dead Beat Controller</SUBJECT>
        <MESSAGE>This is due to discretisation. The mathematical systems come out that way.&lt;br /&gt;&lt;br /&gt;But note that as the sampling interval can be made very small, a few multiples of the sampling interval can still be small. In that sense, you do not lose much time while discretising.&lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>setpoint tracking</SUBJECT>
        <MESSAGE>It is not understood how does set point tracking work </MESSAGE>
        <SUBJECT>Re: setpoint tracking</SUBJECT>
        <MESSAGE>The error between the setpoint and the actual value, i.e., $$e(k)=r-Cx(k)$$, is made small. This is done through $$x_I(k)$$, which keeps a sum of $$e(k)$$. Thus, $$x_I$$ is like an integral or sum of past errors. In the pole placement problem, we attempt to make $$x$$ zero, or small at the least. &lt;br /&gt; </MESSAGE>
      </POST>
      <POST>
        <SUBJECT>slide 38 value of A^(-T)</SUBJECT>
        <MESSAGE>How to find the value of A^(-T) to find steady state solution of LQR? </MESSAGE>
        <SUBJECT>Re: slide 38 value of A^(-T)</SUBJECT>
        <MESSAGE>$$A^{-T}$$ is the same as $$(A^{-1})T$$ or $$(A^T)^{-1}$$, which can easily be checked. A good reference for this topic is Linear Algebra and its Applications by Gilbert Strang, which is available in Indian edition. </MESSAGE>
      </POST>
    </POSTS>
  </DISCUSSION>
</DISCUSSIONS>
